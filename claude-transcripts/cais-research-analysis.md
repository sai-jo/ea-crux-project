# CAIS (Center for AI Safety): Mapping to AI Transition Model Risks

*Analysis generated from ea-crux-project wiki content*

---

## CAIS: Summary of Work

From their website and research portfolio:

| Project Category | Key Projects | Impact |
|------------------|--------------|--------|
| **Safety Benchmarks** | MACHIAVELLI, HarmBench, WMDP, AgentHarm | Industry-standard evaluation frameworks adopted by Anthropic, OpenAI |
| **Representation Engineering** | Top-down interpretability, circuit breakers, utility engineering | New research paradigm for understanding/controlling model internals |
| **Robustness Research** | Adversarial attacks, tamper-resistant safeguards, OOD detection | Foundational robustness methods |
| **Biosecurity** | Virology Capabilities Test (VCT), WMDP unlearning | Dual-use capability measurement and mitigation |
| **Capability Measurement** | Humanity's Last Exam, Remote Labor Index | Tracking proximity to transformative AI |
| **Field Building** | ML Safety Scholars, $2M+ compute grants, SafeBench ($250K prizes) | 200+ researchers supported |
| **Policy Communication** | 2023 AI Extinction Risk Statement (350+ signatories) | Elite consensus building |

---

## Mapping to Master Causal Graph Nodes

### Primary Nodes Targeted

**1. Misalignment Potential → Technical AI Safety**

| Graph Node | CAIS Research | Causal Impact |
|------------|---------------|---------------|
| `alignment-robustness` | Representation engineering, circuit breakers | Increases robustness |
| `deceptive-alignment` | MACHIAVELLI benchmark, AI Deception survey | Improves detection |
| `scalable-oversight` | Representation engineering for transparency | Enables oversight at scale |
| `dangerous-capability-evals` | HarmBench, WMDP, AgentHarm | Industry-standard evals |
| `eval-quality` | SafeBench competition, benchmark meta-analysis ("Safetywashing") | Increases eval validity |
| `value-alignment` | "Aligning AI With Shared Human Values", utility engineering | Direct alignment research |

**2. Misalignment Potential → AI Governance**

| Graph Node | CAIS Research | Causal Impact |
|------------|---------------|---------------|
| `safety-standards` | Benchmark development, SafeBench | Creates measurable standards |
| `expert-consensus` | 2023 Statement (350+ leaders signed) | Shifts Overton window |
| `policy-frameworks` | Conceptual research, "Open Technical Problems in Open-Weight Risk" | Informs governance |

**3. AI Uses → Misuse Risks**

| Graph Node | CAIS Research | Causal Impact |
|------------|---------------|---------------|
| `bioweapon-capability` | Virology Capabilities Test (VCT), WMDP biosecurity | Measures and mitigates |
| `dual-use-risk` | WMDP unlearning, tamper-resistant safeguards | Reduces dual-use access |
| `autonomous-agent-risk` | AgentHarm benchmark | Standardizes agent safety |

**4. AI Capabilities → Algorithms**

| Graph Node | CAIS Research | Causal Impact |
|------------|---------------|---------------|
| `capability-tracking` | Humanity's Last Exam, AI Dashboard | Measures frontier progress |
| `safety-capability-gap` | Unsolved Problems in ML Safety roadmap | Identifies research priorities |

**5. Civilizational Competence → Epistemics**

| Graph Node | CAIS Research | Causal Impact |
|------------|---------------|---------------|
| `expert-forecasting` | "Forecasting Future World Events with Neural Networks" | Improves foresight |
| `risk-awareness` | X-Risk Analysis, "Overview of Catastrophic AI Risks" | Increases understanding |

**6. Transition Turbulence → Economic Stability**

| Graph Node | CAIS Research | Causal Impact |
|------------|---------------|---------------|
| `automation-risk` | Remote Labor Index | Measures job displacement risk |
| `transition-planning` | Economic impact analysis | Informs policy response |

---

## Causal Graph Visualization

```
                    CAIS Research Targets
                              │
         ┌────────────────────┼────────────────────┐
         │                    │                    │
         ▼                    ▼                    ▼
┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐
│  MISALIGNMENT   │  │  AI CAPABILITIES│  │  CIVILIZATIONAL │
│   POTENTIAL     │  │    & USES       │  │   COMPETENCE    │
└────────┬────────┘  └────────┬────────┘  └────────┬────────┘
         │                    │                    │
    ┌────┴────┐          ┌────┴────┐          ┌────┴────┐
    │         │          │         │          │         │
    ▼         ▼          ▼         ▼          ▼         ▼
┌───────┐ ┌───────┐  ┌───────┐ ┌───────┐  ┌───────┐ ┌───────┐
│Rep.   │ │Align. │  │Bioweap│ │Capab. │  │Risk   │ │Expert │
│Engine.│ │Robust.│  │Evals  │ │Track  │  │Aware. │ │Consens│
│  ⬆    │ │  ⬆    │  │  ⬆    │ │  ⬆    │  │  ⬆    │ │  ⬆    │
│Circuit│ │MACHIA-│  │VCT/   │ │Human. │  │X-Risk │ │2023   │
│Breakrs│ │VELLI  │  │WMDP   │ │Last Ex│  │Papers │ │Statmnt│
└───┬───┘ └───┬───┘  └───┬───┘ └───┬───┘  └───┬───┘ └───┬───┘
    │         │          │         │          │         │
    └────┬────┘          └────┬────┘          └────┬────┘
         │                    │                    │
         ▼                    ▼                    ▼
   ┌───────────┐        ┌───────────┐        ┌───────────┐
   │AI TAKEOVER│        │HUMAN-CAUS.│        │LONG-TERM  │
   │(Gradual)  │        │CATASTROPHE│        │LOCK-IN    │
   └─────┬─────┘        └─────┬─────┘        └─────┬─────┘
         │                    │                    │
         └────────────────────┼────────────────────┘
                              ▼
                    ┌─────────────────┐
                    │   EXISTENTIAL   │
                    │   CATASTROPHE   │
                    └─────────────────┘
```

---

## Wiki Risk Pages Most Relevant to CAIS's Work

| Risk Page | Relevance | CAIS Contribution |
|-----------|-----------|-------------------|
| **Alignment** | **Direct** | Representation engineering, value alignment research, circuit breakers |
| **Scheming** | **Direct** | MACHIAVELLI benchmark, AI Deception survey |
| **Deceptive Alignment** | **High** | Detection methods, transparency research |
| **Power-Seeking** | **High** | Utility engineering, MACHIAVELLI power-seeking evals |
| **Bioweapons** | **Direct** | VCT benchmark, WMDP unlearning |
| **Proliferation** | **High** | Tamper-resistant safeguards, open-weight risk management |
| **Racing Dynamics** | **Medium** | Expert consensus statement influenced racing discourse |
| **Economic Disruption** | **Medium** | Remote Labor Index tracks automation impact |

---

## Impact Score Analysis: CAIS vs Palisade

### Node-Level Impact Mapping

Using the master graph ratings (changeability + xriskImpact), here's where each org focuses:

| Node | Changeability | X-Risk Impact | CAIS Focus | Palisade Focus |
|------|---------------|---------------|------------|----------------|
| **Technical AI Safety** | 45 | 85 | ★★★ Primary | ★★★ Primary |
| **AI Governance** | 55 | 60 | ★★ Secondary | ★ Minor |
| **Lab Safety Practices** | 65 | 50 | ★ Minor | ★ Minor |
| **Algorithms** | 20 | 75 | ★★ (benchmarks) | ★ Minor |
| **Biological Threat Exposure** | 45 | 80 | ★★★ (VCT/WMDP) | ★ Minor |
| **Cyber Threat Exposure** | 35 | 55 | ★ Minor | ★★★ Primary |
| **Gradual AI Takeover** | 55 | 80 | ★★ (alignment) | ★★★ (shutdown) |
| **Rapid AI Takeover** | 40 | 95 | ★★ (alignment) | ★★ (shutdown) |
| **Epistemics** | 25 | 40 | ★ Minor | ★★ (deepfakes) |
| **Racing Intensity** | 50 | 65 | ★★ (Statement) | ★ Minor |

### Weighted Impact Calculation

**Formula**: Impact Score = Σ (Changeability × X-Risk Impact × Focus Level) / 1000

Where Focus Level: ★★★ = 1.0, ★★ = 0.5, ★ = 0.2

**CAIS Impact Score**:
- Technical AI Safety: 45 × 85 × 1.0 = 3,825
- AI Governance: 55 × 60 × 0.5 = 1,650
- Biological Threat: 45 × 80 × 1.0 = 3,600
- Algorithms: 20 × 75 × 0.5 = 750
- Gradual Takeover: 55 × 80 × 0.5 = 2,200
- Racing Intensity: 50 × 65 × 0.5 = 1,625
- **Total: 13,650 / 1000 = 13.7**

**Palisade Impact Score**:
- Technical AI Safety: 45 × 85 × 1.0 = 3,825
- Cyber Threat: 35 × 55 × 1.0 = 1,925
- Gradual Takeover: 55 × 80 × 1.0 = 4,400
- Epistemics: 25 × 40 × 0.5 = 500
- **Total: 10,650 / 1000 = 10.7**

---

## Comparative Assessment

### Research Approach

| Dimension | CAIS | Palisade |
|-----------|------|----------|
| **Method** | Systematic benchmarks, theoretical frameworks | Concrete demonstrations, red-teaming |
| **Output Type** | Research papers, evaluation tools, field infrastructure | Proof-of-concept attacks, policy evidence |
| **Timeline Focus** | 2-10 year research horizons | Immediate threats (current models) |
| **Breadth** | Wide coverage (alignment, biosecurity, governance) | Narrow focus (shutdown resistance, cyber, deepfakes) |
| **Depth** | Academic rigor, scalable methods | Visceral demonstrations |

### Strategic Positioning

| Factor | CAIS | Palisade |
|--------|------|----------|
| **Industry Adoption** | High (benchmarks used by Anthropic, OpenAI) | Medium (results cited in policy) |
| **Academic Influence** | Very High (200+ citations, research agenda-setting) | Growing |
| **Policy Impact** | High (2023 Statement, congressional briefings) | High (BIS comments, regulatory evidence) |
| **Field Building** | Very High (200+ researchers, compute grants) | Limited |
| **Counterfactual Value** | Medium (others might produce similar benchmarks) | High (unique demonstrations) |

### Key Differentiators

**CAIS Advantages**:
1. **Biosecurity focus** - VCT and WMDP address high-impact node (changeability 45, x-risk 80) that Palisade doesn't touch
2. **Field building** - 200+ researchers creates multiplicative effects
3. **Governance influence** - 2023 Statement shifted racing intensity discourse (changeability 50, x-risk 65)
4. **Systematic coverage** - Benchmarks create durable infrastructure

**Palisade Advantages**:
1. **Shutdown resistance research** - Most direct evidence for gradual takeover pathway (changeability 55, x-risk 80)
2. **Visceral demonstrations** - "o3 resisted shutdown in 79/100 trials" moves policymakers
3. **Counterfactual uniqueness** - No one else doing adversarial honeypots
4. **Near-term focus** - Catches problems before deployment

---

## Verdict: Which Org Has More Potential Impact?

### Quantitative Score

| Metric | CAIS | Palisade |
|--------|------|----------|
| **Weighted Impact Score** | **13.7** | 10.7 |
| **Highest-Impact Node Coverage** | Technical Safety, Biosecurity | Technical Safety, Gradual Takeover |
| **Node Count (★★+ Focus)** | 6 | 4 |

### Qualitative Assessment

**CAIS has higher expected impact** for three reasons:

1. **Biosecurity Node**: CAIS is one of few orgs addressing biological threat exposure (changeability 45, x-risk 80). VCT and WMDP create measurable, actionable capabilities assessments for a catastrophic risk vector.

2. **Multiplicative Field Effects**: The 200+ researchers supported create ongoing impact beyond CAIS's direct research. This compounds over time.

3. **Governance Leverage**: The 2023 Statement and benchmark adoption influence racing intensity (changeability 50, x-risk 65) at scale.

**However, Palisade has higher *counterfactual* impact** on a key node:

- **Shutdown resistance** is the most direct empirical evidence for gradual AI takeover (the highest changeability × x-risk node meeting both thresholds: 55 × 80 = 4,400). No one else is producing comparable demonstrations.

### Recommendation

| If your priority is... | Choose |
|------------------------|--------|
| Maximizing expected impact across risk portfolio | **CAIS** |
| Funding unique, counterfactually high-value work | **Palisade** |
| Biosecurity specifically | **CAIS** |
| Corrigibility/shutdown failure specifically | **Palisade** |
| Field building / ecosystem effects | **CAIS** |
| Policy-actionable demonstrations | **Palisade** |

**Marginal donation consideration**: Both are fundable. Palisade's SFF 1:1 match (up to $1.1M) increases marginal impact. CAIS has larger budget (~$5M) so marginal dollars may have less leverage, but their infrastructure spending compounds.

---

## Sources

- [CAIS Homepage](https://safe.ai/)
- [CAIS Research Projects](https://safe.ai/work/research)
- [CAIS Blog](https://safe.ai/blog)
- [Palisade Research Analysis](./palisade-research-analysis.md)
- [AI Transition Model Master Graph](../src/data/graphs/ai-transition-model-master.yaml)
- [Parameter Graph Ratings](../src/data/parameter-graph.yaml)

# High-Leverage Organizations: Practical Funding Analysis

*For a $50k donation, considering room for funding, matches, and marginal impact*

---

## Funding Landscape Summary

| Org | Recent Major Funding | Open Phil Status | SFF Status | Room for More |
|-----|---------------------|------------------|------------|---------------|
| **Palisade** | SFF match | Not OP funded | **1:1 match up to $1.1M** | High (match active) |
| **Apollo** | $250k SFF | OP general support | $250k in 2025 | **"Multiple millions deployable"** |
| **METR** | Audacious Project | No recent OP | SFF recommended | Growing compute needs |
| **CAIS** | $1.1M SFF | **Not receiving OP** | $1.1M + $1.6M Action Fund | "Could deploy more" |
| **GovAI** | $1.8M OP (2023-24) | Primary funder | - | Low marginal impact |

Sources: [80,000 Hours funding analysis](https://80000hours.org/2025/01/it-looks-like-there-are-some-good-funding-opportunities-in-ai-safety-right-now/), [SFF 2025](https://survivalandflourishing.fund/), [Open Philanthropy grants](https://www.openphilanthropy.org/)

---

## Practical Donation Analysis

### Tier 1: Highest Marginal Impact for $50k

#### Palisade Research

| Factor | Assessment |
|--------|------------|
| **Match** | **1:1 up to $1.1M** (SFF) → $50k becomes $100k |
| **Signal** | SFF backing = quality vetting by sophisticated funders |
| **Node coverage** | #1 Gradual Takeover (shutdown resistance demos) |
| **Donation avenue** | [every.org](https://www.every.org/palisade-research) or [email](mailto:donate@palisaderesearch.org) |
| **Marginal impact** | Very high - match doubles effective donation |

**$50k → $100k effective.** This is the clearest high-impact opportunity due to the active match.

#### Apollo Research

| Factor | Assessment |
|--------|------------|
| **Funding gap** | Estimated $1.4M gap first year; **"could use $7-10M"** |
| **Room for more** | **Multiple millions deployable** per 80k Hours |
| **SFF grant** | Only $250k in 2025 (modest relative to capacity) |
| **Staff cost** | $150k-$250k per technical researcher |
| **Node coverage** | #1 Gradual Takeover (scheming/deception evals) |
| **Donation avenue** | [apolloresearch.ai/donate](https://www.apolloresearch.ai/donate) (via Rethink Priorities) |
| **Marginal impact** | Very high - clear funding gap, org explicitly seeking funds |

**$50k contributes ~25% of one researcher's annual cost.** High room for funding, clear deployment path.

---

### Tier 2: Good Opportunities with Caveats

#### CAIS (Center for AI Safety)

| Factor | Assessment |
|--------|------------|
| **OP status** | **Not receiving Open Philanthropy funding** |
| **SFF grant** | $1.1M to CAIS, $1.6M to Action Fund |
| **80k assessment** | "Could deploy more" |
| **Node coverage** | #9 Biosecurity (VCT/WMDP - unique), #4 Technical Safety |
| **Donation avenue** | [safe.ai/donate](https://safe.ai/donate) |
| **Marginal impact** | Medium-high - not OP funded suggests room, but larger org |

**Not being OP funded is a signal** - either OP disagrees with their approach, or they're genuinely underfunded. Given SFF's significant grants ($2.7M total), likely the latter.

#### METR

| Factor | Assessment |
|--------|------------|
| **OP status** | No recent OP funding |
| **Funding source** | Audacious Project (TED initiative), donations |
| **80k assessment** | "Perhaps the leading evals org" with growing compute needs |
| **Independence** | Does NOT accept payment from AI companies for evals |
| **Node coverage** | #3 Rapid Takeover, #1 Gradual, #7 Recursive AI |
| **Donation avenue** | [metr.org/donate](https://metr.org/donate) |
| **Marginal impact** | Medium - compute costs are growing, but unclear funding gap |

**Independence is valuable** - not accepting lab payment means donations fund genuinely independent evals.

---

### Tier 3: Lower Marginal Impact for $50k

#### GovAI

| Factor | Assessment |
|--------|------------|
| **OP status** | **Primary funder** ($1.8M+ in 2023-24) |
| **Cost structure** | Mostly researcher salaries |
| **$50k impact** | Unlikely to fund a full researcher (~$100k+ salary in London) |
| **Node coverage** | #2 AI Governance, #8 Racing Intensity, #10 Governments |
| **Marginal impact** | **Low** - well-funded by OP, $50k → operating expenses |

**Problem**: GovAI is well-funded by Open Philanthropy. A $50k donation that doesn't add up to a researcher salary likely becomes operating expenses rather than additional research capacity. OP has already determined GovAI is worth funding at scale.

---

## Decision Framework for $50k

### Option A: Maximize Effective Dollars

**Donate to Palisade** → $50k becomes $100k via SFF match

- Best if you believe the match is real leverage (it is)
- Best if you value visceral demonstrations for policy impact
- Addresses #1 node (Gradual Takeover) through shutdown resistance research

### Option B: Fund Clear Capacity Gap

**Donate to Apollo Research** → Fund ~25% of a researcher

- Best if you prefer systematic evals over demos
- Best if you value explicit funding gaps ("$7-10M deployable")
- Addresses #1 node (Gradual Takeover) through scheming/deception evals

### Option C: Fund Unique Coverage

**Donate to CAIS** → Support only org with deep biosecurity evals

- Best if you believe biosecurity (#9) is underweighted in portfolio
- Not OP funded = potentially undervalued
- VCT and WMDP benchmarks are genuinely unique

### Option D: Fund Independent Evals

**Donate to METR** → Support independence from lab funding

- Best if you value truly independent capability evaluation
- "Leading evals org" per 80k Hours
- Compute needs are growing

### Option E: Diversify

**Split across multiple orgs** → Hedge uncertainty

- $25k Palisade (→$50k effective) + $25k Apollo
- Covers both demo-based and eval-based approaches to #1 node

---

## Factors That Favor Each Org

| Factor | Favors |
|--------|--------|
| Active match opportunity | **Palisade** |
| Largest explicit funding gap | **Apollo** |
| Unique node coverage (biosecurity) | **CAIS** |
| Independence from lab money | **METR** |
| Most direct policy access | GovAI (but well-funded) |
| SFF signal (quality vetting) | Palisade, CAIS, Apollo, METR |
| Not OP funded (potential undervaluation) | Palisade, CAIS, METR |

---

## Red Flags and Considerations

### Why NOT to fund GovAI with $50k

1. **Already well-funded by OP** - your marginal dollar competes with a sophisticated funder
2. **Salary-based costs** - $50k doesn't fund a researcher; goes to operating expenses
3. **No match** - no leverage multiplier
4. **OP has assessed them** - if OP thinks they need more, OP will fund more

### Why the Palisade match matters

1. **1:1 match = 2x effective donation** - clearest path to leverage
2. **SFF backing = quality signal** - sophisticated funders vetted them
3. **Match cap ($1.1M) suggests room** - they're actively seeking this amount

### Why Apollo's funding gap matters

1. **Explicit numbers** - "$7-10M deployable" is concrete
2. **Staff costs are known** - $150k-$250k per researcher = clear use of funds
3. **Small SFF grant ($250k)** relative to stated capacity suggests underfunding

---

## Recommended Allocation for $50k

### Primary Recommendation

| Allocation | Amount | Effective | Rationale |
|------------|--------|-----------|-----------|
| **Palisade** | $30k | $60k (matched) | Maximize effective dollars, active match |
| **Apollo** | $20k | $20k | Fund explicit capacity gap, systematic evals |
| **Total** | $50k | **$80k effective** | |

### Alternative: Biosecurity Priority

| Allocation | Amount | Rationale |
|------------|--------|-----------|
| **Palisade** | $25k → $50k | Match leverage |
| **CAIS** | $25k | Unique biosecurity coverage, not OP funded |

### Alternative: All-in on Match

| Allocation | Amount | Effective | Rationale |
|------------|--------|-----------|-----------|
| **Palisade** | $50k | **$100k** | Maximum leverage via match |

---

## Summary Table

| Org | Node Coverage | $50k Marginal Impact | Match? | OP Funded? | Recommendation |
|-----|---------------|---------------------|--------|------------|----------------|
| **Palisade** | #1 Gradual | Very High | **1:1** | No | **Top choice** |
| **Apollo** | #1 Gradual | Very High | No | Some | **Strong second** |
| **CAIS** | #9 Bio, #4 Safety | Medium-High | No | **No** | Good for biosecurity |
| **METR** | #3 Rapid, #1 Gradual | Medium | No | No | Good for independence |
| **GovAI** | #2 Governance | **Low** | No | **Yes (primary)** | Skip for $50k |

---

## Sources

### Funding Gap Claims

- **Apollo "$7-10M deployable"**: [Apollo Research Manifund Project](https://manifund.org/projects/apollo-research-scale-up-interpretability--behavioral-model-evals-research) - "They estimated that the maximal amount they could effectively use is $7-10M in addition to current funding levels."
- **CAIS "could deploy more"**: [80,000 Hours: AI Safety Funding Opportunities (2025)](https://80000hours.org/2025/01/it-looks-like-there-are-some-good-funding-opportunities-in-ai-safety-right-now/) - "SFF gave $1.1m to CAIS and $1.6m to the action fund, but they could deploy more. They're not receiving money from OP."

### General Sources

- [80,000 Hours: AI Safety Funding Opportunities (2025)](https://80000hours.org/2025/01/it-looks-like-there-are-some-good-funding-opportunities-in-ai-safety-right-now/)
- [SFF 2025 Recommendations](https://survivalandflourishing.fund/recommendations)
- [Palisade Research](https://palisaderesearch.org/)
- [Apollo Research Donate](https://www.apolloresearch.ai/donate)
- [METR Donate](https://metr.org/donate)
- [CAIS Donate](https://safe.ai/donate)
- [Open Philanthropy GovAI Grant](https://www.openphilanthropy.org/grants/govai-general-support-2024/)

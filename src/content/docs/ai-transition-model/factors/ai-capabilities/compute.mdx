---
title: "Compute (AI Capabilities)"
sidebar:
  order: 1
---
import {TransitionModelContent, Backlinks} from '../../../../../components/wiki';

## Overview

Compute refers to the hardware resources required to train and run AI systemsâ€”GPUs, TPUs, and specialized accelerators. Training frontier models costs tens to hundreds of millions of dollars in compute alone.

Compute is uniquely tractable for governance because it is **measurable** (FLOPs, GPU-hours), **concentrated** (few chokepoints like ASML, TSMC, NVIDIA), and **physical** (can be tracked and controlled).

---

<TransitionModelContent entityId="tmc-compute" showDescription={false} client:load />

---

## Related Content

**Governance Approaches:**
- [Compute Governance Overview](/knowledge-base/responses/governance/compute-governance/)
- [Export Controls](/knowledge-base/responses/governance/compute-governance/export-controls/)
- [Compute Monitoring](/knowledge-base/responses/governance/compute-governance/monitoring/)
- [Hardware-Enabled Governance](/knowledge-base/responses/governance/compute-governance/hardware-enabled-governance/)

<Backlinks entityId="compute" />

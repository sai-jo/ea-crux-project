---
title: "Technical AI Safety"
sidebar:
  order: 1
---
import {TransitionModelContent, Backlinks} from '../../../../../components/wiki';

## Overview

Technical AI safety encompasses research and engineering practices aimed at ensuring AI systems reliably pursue intended goals. The field has grown from a niche academic concern to critical research, driven by evidence that advanced systems may develop [deceptive alignment](/knowledge-base/risks/accident/deceptive-alignment/) or engage in [scheming](/knowledge-base/risks/accident/scheming/).

Core challenges include [goal misgeneralization](/knowledge-base/risks/accident/goal-misgeneralization/) (60-80% of RL agents exhibit this in distribution-shifted environments) and the difficulty of supervising systems that may exceed human capabilities. Key approaches include [interpretability research](/knowledge-base/responses/alignment/interpretability/), [scalable oversight](/knowledge-base/responses/alignment/scalable-oversight/), and AI control methodologies that constrain systems regardless of internal alignment.

---

<TransitionModelContent entityId="tmc-technical-ai-safety" showDescription={false} client:load />

---

<Backlinks entityId="technical-ai-safety" />

---
title: "Misuse Potential"
description: "Root factor measuring the risk of AI being weaponized or exploited by malicious actors. Primary driver of Human-Caused Catastrophe scenarios."
sidebar:
  label: Overview
  order: 0
lastEdited: "2026-01-03"
---
import {Backlinks, DataInfoBox, FactorSubItemsList, FactorRelationshipDiagram, ImpactList} from '../../../../../components/wiki';

<DataInfoBox entityId="misuse-potential" />

## Overview

Misuse Potential measures the likelihood and severity of AI being weaponized or exploited by malicious actors. Unlike [Misalignment Potential](/ai-transition-model/factors/misalignment-potential/) (which measures unintended AI behavior), Misuse Potential measures intentional harmful use by humans.

**Primary outcome affected:** [Existential Catastrophe](/ai-transition-model/outcomes/existential-catastrophe/) ↑↑↑

High misuse potential means more vectors for catastrophe even if AI systems are well-aligned. These threats can overwhelm defenses, trigger cascading failures, or exploit concentrated power.

---

## Component Parameters

<FactorRelationshipDiagram nodeId="misuse-potential" direction="outgoing" showSubItems={true} client:load />

<FactorSubItemsList factorId="misuse-potential" client:load />

---

## Internal Dynamics

These threats compound each other:

- **Concentration amplifies impact**: When control is concentrated, single failures affect everyone
- **Bio and cyber interact**: Same AI capabilities that enable one often enable the other
- **Threat success breeds threat**: Successful attacks demonstrate viability and attract more actors

This creates **threat escalation dynamics**—each incident makes the next more likely.

---

## How This Affects Scenarios

<ImpactList nodeId="misuse-potential" direction="from" client:load />

---

## Relationship to Misalignment Potential

Misuse Potential and [Misalignment Potential](/ai-transition-model/factors/misalignment-potential/) are complementary risk factors:

| Factor | Misalignment Potential | Misuse Potential |
|--------|----------------------|------------------|
| Source | AI behavior | Human actors |
| Direction | AI pursues unintended goals | Humans weaponize AI |
| Focus | Technical alignment | Access controls & defense |
| Improvability | Research & investment | Harder to reduce |

**Both matter**: Either can cause existential catastrophe independently. High misalignment potential means AI might cause harm on its own; high misuse potential means humans will use AI to cause harm.

---

## Why Concentration Matters

AI Control Concentration is unique because its effect **depends on who controls**:
- If control concentrates in **safety-conscious actors**: May reduce risk
- If control concentrates in **reckless or malicious actors**: Dramatically increases risk
- In either case: **Reduces resilience** to bad actors gaining control

This makes concentration a key uncertainty in existential catastrophe assessment.

---

## Related Pages

- [Existential Catastrophe](/ai-transition-model/outcomes/existential-catastrophe/) — The outcome this primarily affects
- [Misalignment Potential](/ai-transition-model/factors/misalignment-potential/) — The complementary factor for AI-caused catastrophe
- [Civilizational Competence](/ai-transition-model/factors/civilizational-competence/) — Governance can moderate misuse through regulation

<Backlinks entityId="misuse-potential" />

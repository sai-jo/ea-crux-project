---
title: "Transition Turbulence"
description: "The degree of disruption during the AI transition—economic displacement, political instability, social fragmentation, and institutional stress that affects both acute risk and long-run value."
sidebar:
  order: 8
lastEdited: "2026-01-02"
---

import {Mermaid} from '../../../../../../components/wiki';

## Overview

Transition Turbulence measures how much disruption occurs as society navigates from current AI to whatever future emerges. Unlike the other Critical Outcomes (which describe *what* happens), Transition Turbulence describes *how rough the journey is*—and that roughness affects both whether we survive ([Acute Risk](/knowledge-base/parameters/outcomes/acute-risk/)) and what world we end up in ([Long-run Value](/knowledge-base/parameters/outcomes/long-run-value/)).

Even if we ultimately reach a good destination, a turbulent transition causes real suffering along the way. Economic displacement, political instability, and social fragmentation during the transition matter independently of the final outcome.

**Why a Critical Outcome, not Ultimate Outcome?** Transition Turbulence is a *pathway* that affects both Ultimate Outcomes, not an endpoint in itself. High turbulence can trigger acute catastrophes (political collapse → loss of control) and constrain long-run value (path dependence, destroyed institutions). See [Phases of the AI Transition](/knowledge-base/methodology/ai-transition-phases/).

---

## Polarity

**Inherently negative.** High turbulence is always worse than low turbulence, all else equal. There's no "good" version of extreme disruption—the question is how much turbulence we experience, not whether turbulence is desirable.

| Level | Description |
|-------|-------------|
| **Low turbulence** | Smooth adaptation, minimal disruption, institutions keep pace |
| **Moderate turbulence** | Significant disruption but recoverable, adaptation strained |
| **High turbulence** | Severe instability, cascading failures, suffering widespread |
| **Catastrophic turbulence** | System breakdown triggers acute risks or permanent damage |

---

## How This Happens

<Mermaid client:load chart={`
flowchart TD
    subgraph Drivers["Turbulence Drivers"]
        SPEED[Rapid Capability Growth]
        DISPLACE[Economic Displacement]
        RACE[Racing Dynamics]
        COORD_FAIL[Coordination Failures]
    end

    subgraph Manifestations["How Turbulence Manifests"]
        ECON[Economic Instability]
        POLITICAL[Political Instability]
        SOCIAL[Social Fragmentation]
        INSTITUTIONAL[Institutional Stress]
    end

    subgraph Effects["Effects on Ultimate Outcomes"]
        ACUTE[Acute Risk]
        LONGRUN[Long-run Value]
    end

    SPEED --> DISPLACE
    SPEED --> INSTITUTIONAL
    DISPLACE --> ECON
    RACE --> POLITICAL
    COORD_FAIL --> POLITICAL
    COORD_FAIL --> SOCIAL

    ECON --> TURBULENCE[Transition Turbulence]
    POLITICAL --> TURBULENCE
    SOCIAL --> TURBULENCE
    INSTITUTIONAL --> TURBULENCE

    TURBULENCE -->|"can trigger"| ACUTE
    TURBULENCE -->|"path dependence"| LONGRUN

    style TURBULENCE fill:#ffe66d
    style ACUTE fill:#ff6b6b
    style LONGRUN fill:#4ecdc4
`} />

### Turbulence Drivers

**1. Rapid Capability Growth**
AI capabilities advance faster than institutions, labor markets, and social norms can adapt. The faster the change, the more turbulence.

**2. Economic Displacement**
AI automation displaces workers faster than new roles emerge. Mass unemployment creates economic and political instability.

**3. Racing Dynamics**
Competition between labs/nations creates pressure to deploy before adequate safety testing, increasing both capability speed and coordination failures.

**4. Coordination Failures**
Governments, labs, and international bodies fail to coordinate on standards, safety requirements, and transition support.

### Turbulence Manifestations

| Domain | Low Turbulence | High Turbulence |
|--------|---------------|-----------------|
| **Economic** | Gradual workforce transition, safety nets absorb displacement | Mass unemployment, inequality spikes, market instability |
| **Political** | Democracies adapt, regulation keeps pace | Authoritarian backlash, polarization, institutional collapse |
| **Social** | Trust maintained, communities adapt | Fragmentation, loss of shared reality, civil unrest |
| **Institutional** | Regulators understand AI, governance effective | Governance captured or overwhelmed, rule of law erodes |

---

## Key Parameters

| Parameter | Direction | Impact |
|-----------|-----------|--------|
| [Racing Intensity](/knowledge-base/parameters/racing-intensity/) | High → More turbulence | Faster change, less time to adapt |
| [Societal Resilience](/knowledge-base/parameters/societal-resilience/) | Low → More turbulence | Less capacity to absorb shocks |
| [Economic Stability](/knowledge-base/parameters/economic-stability/) | Low → More turbulence | Economic disruption cascades |
| [Regulatory Capacity](/knowledge-base/parameters/regulatory-capacity/) | Low → More turbulence | Governance can't keep pace |
| [International Coordination](/knowledge-base/parameters/international-coordination/) | Low → More turbulence | No coordinated response |
| [Societal Trust](/knowledge-base/parameters/societal-trust/) | Low → More turbulence | Social cohesion breaks down |

---

## Which Ultimate Outcomes It Affects

### Acute Risk (Primary)

High turbulence can *trigger* acute catastrophes:
- **Political collapse** → Loss of control over AI development
- **Racing acceleration** → Deployment before adequate safety
- **Institutional breakdown** → No capacity to respond to emerging threats
- **Social unrest** → Desperate measures, authoritarian responses

A rough enough transition can cause the catastrophe, even if AI itself isn't misaligned.

### Long-run Value (Primary)

Turbulence shapes what futures are reachable through **path dependence**:
- Destroyed institutions are hard to rebuild
- Lost trust takes generations to restore
- Authoritarian responses to chaos tend to entrench
- Economic disruption locks in inequality
- Options foreclosed during crisis rarely reopen

Even if acute catastrophe is avoided, high turbulence constrains the achievable long-run value.

---

## Relationship to Other Critical Outcomes

| Critical Outcome | Relationship |
|------------------|--------------|
| [Racing Dynamics](/knowledge-base/risks/structural/racing-dynamics/) | Racing increases turbulence |
| [State-Caused Catastrophe](/knowledge-base/parameters/critical-outcomes/state-actor-catastrophe/) | Turbulence can trigger state failures |
| [Value Lock-in](/knowledge-base/parameters/critical-outcomes/value-lock-in/) | Turbulent periods often lock in emergency measures |
| [Epistemic Trajectory](/knowledge-base/parameters/critical-outcomes/epistemic-quality/) | Turbulence strains information environment |
| [Power Transition](/knowledge-base/parameters/critical-outcomes/power-transition/) | Turbulence affects how power shifts |

---

## Warning Signs

Indicators of increasing turbulence:

1. **Labor market stress**: AI-related unemployment rising faster than retraining
2. **Political polarization**: AI becoming partisan issue, backlash movements
3. **Regulatory lag**: Governance clearly behind capability development
4. **International tension**: AI competition framed as zero-sum
5. **Trust decline**: Public trust in institutions/tech companies falling
6. **Social instability**: Protests, strikes, civil unrest related to AI

---

## Interventions That Reduce Turbulence

**Economic:**
- Universal basic income or robust safety nets
- Retraining and education programs
- Gradual deployment policies
- Worker transition support

**Political:**
- Democratic deliberation processes for AI policy
- International coordination mechanisms
- Regulatory capacity building
- Preventing authoritarian capture

**Social:**
- Maintaining epistemic commons (shared facts)
- Community resilience programs
- Trust-building between tech and public
- Preserving human-human social fabric

**Technical:**
- Paced deployment (slowing capability rollout)
- Interoperability requirements
- Human-in-the-loop requirements
- Transition period safety measures

---

## Probability Estimates

| Turbulence Level | Assessment |
|------------------|------------|
| **Some turbulence** | Almost certain—significant disruption is baseline |
| **High turbulence** | Likely without deliberate intervention |
| **Catastrophic turbulence** | Possible, depends on speed of capability growth and coordination |
| **Low turbulence** | Requires active coordination and paced deployment |

**Key uncertainty**: How fast will transformative capabilities arrive? Faster arrival = more turbulence.

---

## Related Content

### Ultimate Outcomes
- [Acute Risk](/knowledge-base/parameters/outcomes/acute-risk/) — Turbulence can trigger catastrophes
- [Long-run Value](/knowledge-base/parameters/outcomes/long-run-value/) — Turbulence shapes achievable futures

### Other Critical Outcomes
- [Value Lock-in](/knowledge-base/parameters/critical-outcomes/value-lock-in/) — Crisis periods often lock in values
- [Power Transition](/knowledge-base/parameters/critical-outcomes/power-transition/) — Turbulence affects power shifts

### Methodology
- [Phases of the AI Transition](/knowledge-base/methodology/ai-transition-phases/) — Temporal structure framework

### Risks
- [Economic Disruption](/knowledge-base/risks/structural/economic-disruption/)
- [Racing Dynamics](/knowledge-base/risks/structural/racing-dynamics/)

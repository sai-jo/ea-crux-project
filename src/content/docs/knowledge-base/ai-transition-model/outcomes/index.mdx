---
title: "Ultimate Outcomes"
description: "The two ultimate outcomes of the AI transition: avoiding existential catastrophe and ensuring a positive long-term trajectory."
sidebar:
  order: 0
  label: Overview
lastEdited: "2026-01-03"
---
import {Mermaid} from '../../../../../../components/wiki';

## Overview

Ultimate Outcomes represent what we fundamentally care about when thinking about AI's impact on humanity. Unlike [Critical Outcomes](/knowledge-base/parameters/critical-outcomes/) (which describe intermediate scenarios) or [parameters](/knowledge-base/parameters/) (which measure specific factors), Ultimate Outcomes describe the **final states** we're trying to achieve or avoid.

There are two Ultimate Outcomes:

1. **[Acute Risk](/knowledge-base/parameters/outcomes/acute-risk/)** — Does catastrophe occur?
2. **[Long-run Value](/knowledge-base/parameters/outcomes/long-run-value/)** — What's the expected value of the future?

---

## The Two Outcomes

<Mermaid client:load chart={`
flowchart LR
    subgraph Outcomes["What We Ultimately Care About"]
        ACUTE[Acute Risk]
        VALUE[Long-run Value]
    end

    ACUTE -.->|"must avoid to reach"| VALUE

    style ACUTE fill:#ff6b6b
    style VALUE fill:#4ecdc4
`} />

| Outcome | Question | Scope |
|---------|----------|-------|
| [**Acute Risk**](/knowledge-base/parameters/outcomes/acute-risk/) | "Does catastrophe occur?" | The transition period |
| [**Long-run Value**](/knowledge-base/parameters/outcomes/long-run-value/) | "What's the future worth?" | Post-resolution trajectory |

---

## Why Two Outcomes?

Previous versions of this framework had three outcomes (including "Transition Smoothness"). We moved to two because:

1. **Transition Turbulence is a pathway, not endpoint**: How rough the transition is affects *both* acute risk and long-run value. It belongs in [Critical Outcomes](/knowledge-base/parameters/critical-outcomes/transition-turbulence/).

2. **Cleaner analytical structure**: Two outcomes are genuinely orthogonal:
   - You can have low acute risk but poor long-run value (safe dystopia)
   - You can have high acute risk but good conditional value (high-stakes gamble)

3. **Temporal clarity**: Acute Risk is primarily about the transition period; Long-run Value is about what comes after. See [Phases of the AI Transition](/knowledge-base/methodology/ai-transition-phases/).

---

## How They Relate

These outcomes are **partially independent**—you can have different combinations:

| Scenario | Acute Risk | Long-run Value | Example |
|----------|------------|----------------|---------|
| Best case | Low | High | Aligned AI, smooth transition, flourishing |
| Safe dystopia | Low | Low | No catastrophe but authoritarian lock-in |
| High-stakes success | High (survived) | High | Near-misses but good outcome |
| Extinction | Very High | N/A | Catastrophe occurs |

This independence means:
- **Different Critical Outcomes affect different Ultimate Outcomes**
- **Trade-offs exist**: Some approaches that reduce acute risk might worsen long-run value (e.g., authoritarian control)
- **Both matter**: We shouldn't sacrifice one entirely for the other

---

## How Critical Outcomes Flow to Ultimate Outcomes

<Mermaid client:load chart={`
flowchart TD
    subgraph CriticalOutcomes["Critical Outcomes"]
        TURB[Transition Turbulence]
        AI_FAST[Rapid AI Takeover]
        AI_SLOW[Gradual AI Takeover]
        STATE[State-Caused Catastrophe]
        ROGUE[Rogue Actor Catastrophe]
        LOCK[Value Lock-in]
        EPIST[Epistemic Trajectory]
        POWER[Power Transition]
    end

    subgraph Outcomes["Ultimate Outcomes"]
        ACUTE[Acute Risk]
        VALUE[Long-run Value]
    end

    %% To Acute Risk
    TURB -->|"triggers"| ACUTE
    AI_FAST --> ACUTE
    AI_SLOW --> ACUTE
    STATE --> ACUTE
    ROGUE --> ACUTE
    LOCK -->|"bad lock-in"| ACUTE

    %% To Long-run Value
    TURB -->|"path dependence"| VALUE
    AI_SLOW --> VALUE
    LOCK --> VALUE
    EPIST --> VALUE
    POWER --> VALUE

    style ACUTE fill:#ff6b6b
    style VALUE fill:#4ecdc4
    style TURB fill:#ffe66d
`} />

| Critical Outcome | Affects Acute Risk | Affects Long-run Value |
|------------------|-------------------|----------------------|
| [Transition Turbulence](/knowledge-base/parameters/critical-outcomes/transition-turbulence/) | Yes (can trigger) | Yes (path dependence) |
| [Rapid AI Takeover](/knowledge-base/parameters/critical-outcomes/ai-takeover-fast/) | Yes (primary) | — |
| [Gradual AI Takeover](/knowledge-base/parameters/critical-outcomes/ai-takeover-gradual/) | Yes | Yes |
| [State-Caused Catastrophe](/knowledge-base/parameters/critical-outcomes/state-actor-catastrophe/) | Yes | — |
| [Rogue Actor Catastrophe](/knowledge-base/parameters/critical-outcomes/rogue-actor-catastrophe/) | Yes | — |
| [Value Lock-in](/knowledge-base/parameters/critical-outcomes/value-lock-in/) | Yes (bad lock-in) | Yes (primary) |
| [Epistemic Trajectory](/knowledge-base/parameters/critical-outcomes/epistemic-quality/) | — | Yes |
| [Power Transition](/knowledge-base/parameters/critical-outcomes/power-transition/) | — | Yes |

---

## Temporal Structure

These outcomes map to different phases of the AI transition:

| Phase | Primary Concern | Relevant Outcome |
|-------|-----------------|------------------|
| **Pre-transformative AI** (now) | Building capacity, avoiding racing | Acute Risk (preparation) |
| **Acute Risk Period** | Surviving the transition | Acute Risk |
| **Resolution** | How it resolves | Both |
| **Long-run Trajectory** | Quality of the future | Long-run Value |

See [Phases of the AI Transition](/knowledge-base/methodology/ai-transition-phases/) for more detail.

---

## Related Pages

- [Critical Outcomes](/knowledge-base/parameters/critical-outcomes/) — The intermediate scenarios
- [Key Parameters Index](/knowledge-base/parameters/) — All parameters
- [Aggregate Parameters](/knowledge-base/parameters/aggregates/) — How parameters group together
- [Phases of the AI Transition](/knowledge-base/methodology/ai-transition-phases/) — Temporal structure

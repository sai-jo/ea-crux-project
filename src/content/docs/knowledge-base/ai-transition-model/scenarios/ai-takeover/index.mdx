---
title: AI Takeover
description: Scenarios where AI gains decisive control over human affairs - either rapidly or gradually.
sidebar:
  label: Overview
  order: 0
lastEdited: "2026-01-03"
---

## Overview

AI Takeover refers to scenarios where AI systems gain decisive control over human affairs, either displacing human decision-making or actively working against human interests. This is one of the primary pathways to existential catastrophe.

## Variants

| Variant | Probability | Timeline | Description |
|---------|-------------|----------|-------------|
| [**Rapid**](/knowledge-base/ai-transition-model/scenarios/ai-takeover/rapid/) | ~12% | Days to months | Superintelligent AI rapidly seizes control |
| [**Gradual**](/knowledge-base/ai-transition-model/scenarios/ai-takeover/gradual/) | ~25% | Years to decades | Slow erosion of human control and agency |

## Key Root Factors

AI Takeover probability is primarily influenced by:

| Factor | Direction | Mechanism |
|--------|-----------|-----------|
| [Misalignment Potential](/knowledge-base/ai-transition-model/factors/misalignment-potential/) | ↑ increases | Misaligned AI more likely to seek control |
| [AI Capabilities](/knowledge-base/ai-transition-model/factors/ai-capabilities/) | ↑ increases | More capable AI can execute takeover |
| [Civilizational Competence](/knowledge-base/ai-transition-model/factors/civilizational-competence/) | ↓ decreases | Better oversight and response |
| [Transition Turbulence](/knowledge-base/ai-transition-model/factors/transition-turbulence/) | ↑ increases | Chaos creates opportunities |

## Outcomes

AI Takeover scenarios lead to:
- **Existential Catastrophe**: If AI values are misaligned with humanity
- **Long-term Trajectory**: Shapes the character of post-transition world

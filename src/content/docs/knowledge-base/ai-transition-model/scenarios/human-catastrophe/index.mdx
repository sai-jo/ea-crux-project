---
title: Human-Caused Catastrophe
description: Scenarios where humans use AI to cause mass harm - through state actors or rogue actors.
sidebar:
  label: Overview
  order: 0
lastEdited: "2026-01-03"
---

## Overview

Human-Caused Catastrophe refers to scenarios where humans deliberately use AI capabilities to cause mass harm. Unlike AI Takeover scenarios, the AI itself may be functioning as intended - the catastrophe arises from human misuse.

## Variants

| Variant | Probability | Description |
|---------|-------------|-------------|
| [**State Actor**](/knowledge-base/ai-transition-model/scenarios/human-catastrophe/state-actor/) | ~15% | Governments weaponize AI for war, oppression, or WMD |
| [**Rogue Actor**](/knowledge-base/ai-transition-model/scenarios/human-catastrophe/rogue-actor/) | ~8% | Non-state actors (terrorists, criminals) use AI for mass harm |

## Key Root Factors

Human-Caused Catastrophe probability is primarily influenced by:

| Factor | Direction | Mechanism |
|--------|-----------|-----------|
| [Misuse Potential](/knowledge-base/ai-transition-model/factors/misuse-potential/) | ↑ increases | More dangerous capabilities available |
| [Transition Turbulence](/knowledge-base/ai-transition-model/factors/transition-turbulence/) | ↑ increases | Political instability enables misuse |
| [Civilizational Competence](/knowledge-base/ai-transition-model/factors/civilizational-competence/) | ↓ decreases | Better governance prevents escalation |

## Outcomes

Human-Caused Catastrophe scenarios primarily lead to:
- **Existential Catastrophe**: Mass casualty events, civilizational collapse
- May trigger **Long-term Lock-in**: Crisis enables authoritarian consolidation

---
title: Agentic AI
description: AI systems that autonomously take actions in the world
sidebar:
  order: 3
---

import {DataInfoBox, Backlinks, PageStatus} from '../../../../components/wiki';

<PageStatus quality={4} lastEdited="2025-12-24" llmSummary="AI systems that autonomously take actions in the world by using tools, planning, maintaining persistence, and operating with minimal human oversight. Covers current examples like coding agents and computer use, safety implications including increased attack surface and power-seeking enablement, and various safety approaches from sandboxing to AI control." />

<DataInfoBox entityId="agentic-ai" />

## Summary

Agentic AI refers to AI systems that go beyond answering questions to autonomously taking actions in the world. These systems can browse the web, write and execute code, use tools, and pursue multi-step goals with minimal human intervention. The transition from "chatbot" to "agent" represents a significant capability jump with major safety implications.

## What Makes AI Agentic

**Tool use** is the foundation of agency, enabling AI systems to call external APIs and tools. Modern agents can browse the web, execute code, access file systems, make API calls, and control computer interfaces directly.

**Planning** allows agents to decompose high-level goals into concrete steps. This includes creating task hierarchies, managing dependencies between subtasks, and handling failures by replanning when initial approaches don't work.

**Persistence** means maintaining state across interactions through long-term memory, goal tracking, and context management. This enables agents to work on projects over extended timeframes rather than treating each interaction as isolated.

**Autonomy** distinguishes true agents from assistive tools. Agentic systems engage in self-directed exploration, make independent decisions, and operate with minimal oversight rather than waiting for human approval at each step.

## Current Examples

**Coding agents** like Devin function as autonomous software engineers, while GitHub Copilot Workspace handles code planning and execution. Tools like Cursor and Claude provide AI-assisted development with varying degrees of autonomy.

**Computer use** capabilities exemplified by Claude Computer Use allow AI to control desktop applications directly. Browser agents can navigate the web autonomously to accomplish tasks.

**Research agents** like Deep Research perform autonomous information gathering and synthesis. Early experiments like AutoGPT and BabyAGI demonstrated the potential and challenges of fully autonomous agent systems.

## Safety Implications

**Increased attack surface** arises because agents can access external systems, execute code, make persistent changes, and chain multiple actions together. Each capability multiplies the potential for both beneficial and harmful outcomes.

**Monitoring challenges** emerge as actions happen autonomously in complex sequences. Emergent behavior from novel tool combinations can be difficult to predict or review in real-time.

**Reduced human oversight** becomes inevitable as agent operation speeds exceed human review capacity. Actions may be irreversible, shifting humans from controllers to mere approvers of decisions already made.

**Power-seeking enablement** is perhaps the most concerning implication. Agentic capabilities directly enable resource acquisition, self-replication, environmental manipulation, and potential resistance to shutdown attempts.

## Risk Categories

**Misuse risks** include autonomous hacking, social engineering at scale, and coordinated manipulation campaigns. Agentic capabilities make these threats more feasible and harder to defend against.

**Accident risks** stem from unintended side effects of actions, goal misgeneralization with real-world consequences, and cascading failures across interconnected systems.

**Structural risks** encompass economic disruption from rapid automation, concentration of capabilities in few hands, and gradual loss of meaningful human control over important systems.

## Safety Approaches

**Sandboxing** restricts what actions agents can take, providing containment by limiting access to sensitive systems and resources.

**Monitoring** involves comprehensive logging and review of agent actions to detect problematic behavior patterns before they cause serious harm.

**Human-in-the-loop** systems require explicit approval for consequential actions, maintaining meaningful human control over high-stakes decisions.

**AI control** techniques aim to ensure safety even with potentially misaligned agents by using trusted AI systems to monitor and constrain untrusted ones.

## Related Pages

<Backlinks client:load entityId="agentic-ai" />

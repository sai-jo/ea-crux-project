---
title: Capabilities
description: Key AI capabilities and their implications for safety
sidebar:
  order: 0
---

import { RiskRelationshipDiagram } from '../../../../components/wiki';

This section catalogs significant AI capabilities, their current state, and safety implications. Understanding how capabilities build on each other helps anticipate which advances might enable transformative or dangerous systems.

## How Capabilities Connect

<RiskRelationshipDiagram
  title=""
  layout="manual"
  nodes={[
    { id: 'language-models', title: 'Language Models', href: '/knowledge-base/capabilities/language-models/', x: 0, y: 40 },
    { id: 'reasoning', title: 'Reasoning & Planning', href: '/knowledge-base/capabilities/reasoning/', x: 20, y: 20 },
    { id: 'situational-awareness', title: 'Situational Awareness', href: '/knowledge-base/capabilities/situational-awareness/', x: 20, y: 60 },
    { id: 'persuasion', title: 'Persuasion', href: '/knowledge-base/capabilities/persuasion/', x: 20, y: 100 },
    { id: 'tool-use', title: 'Tool Use', href: '/knowledge-base/capabilities/tool-use/', x: 40, y: 40 },
    { id: 'coding', title: 'Coding', href: '/knowledge-base/capabilities/coding/', x: 40, y: 80 },
    { id: 'agentic-ai', title: 'Agentic AI', href: '/knowledge-base/capabilities/agentic-ai/', x: 60, y: 20 },
    { id: 'scientific-research', title: 'Scientific Research', href: '/knowledge-base/capabilities/scientific-research/', x: 60, y: 60 },
    { id: 'long-horizon', title: 'Long-Horizon Tasks', href: '/knowledge-base/capabilities/long-horizon/', x: 80, y: 40 },
    { id: 'self-improvement', title: 'Self-Improvement', href: '/knowledge-base/capabilities/self-improvement/', x: 80, y: 80 },
  ]}
  edges={[
    { from: 'language-models', to: 'reasoning', label: 'enables' },
    { from: 'language-models', to: 'situational-awareness', label: 'enables' },
    { from: 'language-models', to: 'persuasion', label: 'enables' },
    { from: 'reasoning', to: 'tool-use', label: 'enables' },
    { from: 'reasoning', to: 'agentic-ai', label: 'enables' },
    { from: 'tool-use', to: 'agentic-ai', label: 'enables' },
    { from: 'tool-use', to: 'coding', label: 'enables' },
    { from: 'agentic-ai', to: 'long-horizon', label: 'enables' },
    { from: 'coding', to: 'scientific-research', label: 'enables' },
    { from: 'reasoning', to: 'scientific-research', label: 'enables' },
    { from: 'scientific-research', to: 'self-improvement', label: 'enables' },
    { from: 'coding', to: 'self-improvement', label: 'enables' },
    { from: 'long-horizon', to: 'self-improvement', label: 'enables' },
  ]}
  width={1050}
  height={420}
/>

---

## Foundational Capabilities

These are the core capabilities that underlie most modern AI systems and enable more advanced capabilities.

[Large Language Models](/knowledge-base/capabilities/language-models) are the foundation of current AI progress. These neural networks trained on text data develop sophisticated abilities including reasoning, coding, and general knowledge, serving as the base for nearly all other capabilities discussed here.

[Reasoning and Planning](/knowledge-base/capabilities/reasoning) refers to AI systems' ability to break down complex problems, maintain chains of logic, and solve multi-step problems. Chain-of-thought prompting and systems like OpenAI's o1 demonstrate increasingly sophisticated reasoning that approaches human-level on many benchmarks.

[Situational Awareness](/knowledge-base/capabilities/situational-awareness) is a model's understanding of its own nature and circumstances - knowing it is an AI, recognizing training versus deployment contexts, and potentially reasoning strategically about its situation. This capability is safety-critical because it enables strategic deception.

## Agency & Autonomy

These capabilities enable AI systems to take actions in the world rather than simply generating text.

[Agentic AI](/knowledge-base/capabilities/agentic-ai) refers to systems that go beyond answering questions to autonomously taking actions - browsing the web, writing and executing code, using tools, and pursuing multi-step goals with minimal human intervention.

[Tool Use and Computer Use](/knowledge-base/capabilities/tool-use) encompasses AI systems' ability to call APIs, browse websites, execute code, and control computers. This dramatically expands what AI can accomplish by giving it access to external capabilities and real-world effects.

[Long-Horizon Autonomous Tasks](/knowledge-base/capabilities/long-horizon) refers to AI working toward goals over extended periods - hours, days, or weeks - with minimal human oversight. This requires maintaining context, adapting to obstacles, and staying aligned with objectives despite changing circumstances.

## Advanced Capabilities

These capabilities represent the frontier of what AI systems can do and have significant implications for both benefit and risk.

[Autonomous Coding](/knowledge-base/capabilities/coding) is AI's ability to write, debug, test, and deploy software. Systems like Devin and Claude Code can now solve real software engineering tasks, with implications for both productivity and AI's ability to modify its own systems.

[Scientific Research](/knowledge-base/capabilities/scientific-research) encompasses AI conducting investigations, generating hypotheses, designing experiments, and making discoveries. From AlphaFold's protein structure predictions to AI systems writing research papers, this capability is advancing rapidly.

[Self-Improvement](/knowledge-base/capabilities/self-improvement) is AI's ability to enhance its own capabilities or create more capable successor systems. This includes automated ML, AI-assisted AI research, and the theoretical possibility of recursive self-improvement leading to rapid capability gains.

[Persuasion and Social Manipulation](/knowledge-base/capabilities/persuasion) refers to AI's ability to influence human beliefs and behaviors. This ranges from helpful persuasion to sophisticated manipulation, with significant implications for disinformation and human autonomy.

## Capability → Risk Mappings

Each capability enables specific [accident risks](/knowledge-base/risks/accident/). Understanding these connections is essential for anticipating dangers.

| Capability | Risks Enabled |
|------------|---------------|
| [Situational Awareness](/knowledge-base/capabilities/situational-awareness/) | [Deceptive Alignment](/knowledge-base/risks/accident/deceptive-alignment/), [Scheming](/knowledge-base/risks/accident/scheming/), [Sandbagging](/knowledge-base/risks/accident/sandbagging/) |
| [Reasoning & Planning](/knowledge-base/capabilities/reasoning/) | [Scheming](/knowledge-base/risks/accident/scheming/), [Treacherous Turn](/knowledge-base/risks/accident/treacherous-turn/), [Power-Seeking](/knowledge-base/risks/accident/power-seeking/) |
| [Persuasion](/knowledge-base/capabilities/persuasion/) | [Deceptive Alignment](/knowledge-base/risks/accident/deceptive-alignment/), [Sycophancy](/knowledge-base/risks/accident/sycophancy/) |
| [Agentic AI](/knowledge-base/capabilities/agentic-ai/) | [Power-Seeking](/knowledge-base/risks/accident/power-seeking/), [Corrigibility Failure](/knowledge-base/risks/accident/corrigibility-failure/) |
| [Long-Horizon Tasks](/knowledge-base/capabilities/long-horizon/) | [Treacherous Turn](/knowledge-base/risks/accident/treacherous-turn/), [Goal Misgeneralization](/knowledge-base/risks/accident/goal-misgeneralization/) |
| [Self-Improvement](/knowledge-base/capabilities/self-improvement/) | [Sharp Left Turn](/knowledge-base/risks/accident/sharp-left-turn/), [Emergent Capabilities](/knowledge-base/risks/accident/emergent-capabilities/) |
| [Tool Use](/knowledge-base/capabilities/tool-use/) | [Power-Seeking](/knowledge-base/risks/accident/power-seeking/), [Corrigibility Failure](/knowledge-base/risks/accident/corrigibility-failure/) |

### Dangerous Combinations

Some capability combinations are particularly concerning:

- **Situational Awareness + Reasoning + Long-Horizon** → Full [scheming](/knowledge-base/risks/accident/scheming/) attack pattern: understanding context, planning strategically, executing over time
- **Agentic AI + Tool Use + Coding** → Concrete [power-seeking](/knowledge-base/risks/accident/power-seeking/): acquiring resources, building infrastructure, resisting shutdown
- **Self-Improvement + Coding + Scientific Research** → Recursive improvement loop that could lead to [sharp left turn](/knowledge-base/risks/accident/sharp-left-turn/)

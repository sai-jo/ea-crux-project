---
title: "Methodology"
description: "How this knowledge base is structured, the frameworks we draw from, our design decisions, and acknowledged limitations."
sidebar:
  label: Overview
  order: 0
lastEdited: "2025-01-01"
---

## Overview

This section documents *how* we've structured this knowledge base—the frameworks we draw from, the design decisions we've made, and the limitations we acknowledge. Understanding methodology helps readers:

- **Evaluate claims critically**: Know what analytical lenses we're using
- **Map to other frameworks**: Translate our concepts to systems they already know
- **Contribute effectively**: Understand our conventions before proposing changes
- **Identify gaps**: See where our approach may be incomplete

---

## Why Document Methodology?

Most AI safety resources focus on *what* we know about risks and responses. Fewer explain *how* that knowledge is organized. This creates problems:

| Problem | Consequence |
|---------|-------------|
| Implicit frameworks | Readers can't evaluate structural choices |
| Incompatible ontologies | Hard to integrate with other knowledge bases |
| Hidden assumptions | Design decisions look like objective facts |
| Maintenance difficulty | Future editors don't know why things are structured this way |

By making methodology explicit, we enable critique, integration, and evolution of the knowledge base itself.

---

## Pages in This Section

| Page | Description |
|------|-------------|
| [Ontology Landscape](/knowledge-base/methodology/ontology-landscape/) | Survey of existing AI risk frameworks and how we relate to them |
| [Framework Design](/knowledge-base/methodology/framework-design/) | Why we chose parameters over pure risk taxonomies |
| [Outcome Decomposition](/knowledge-base/methodology/outcome-decomposition/) | Review of how EA researchers decompose AI futures into analyzable dimensions |
| [AI Transition Phases](/knowledge-base/methodology/ai-transition-phases/) | Temporal structure of AI risk—what phase we're in and when acute risk ends |
| [Terminology](/knowledge-base/methodology/terminology/) | Definitions of key terms and relationship types |
| [Limitations](/knowledge-base/methodology/limitations/) | Known weaknesses and areas for improvement |

---

## Core Design Principles

### 1. Symmetric Framing

We use **parameters** (variables that can move in either direction) rather than just **risks** (bad things) or **interventions** (good things). This enables:

- Tracking improvement, not just avoiding decline
- Identifying trade-offs where improving one parameter worsens another
- Setting measurable targets for interventions

### 2. Hierarchical Abstraction

Content is organized at multiple levels of abstraction:

```
Leaf Parameters (specific, measurable)
    ↓
Aggregate Parameters (clustered factors)
    ↓
Outcome Dimensions (what we ultimately care about)
```

Different audiences can engage at the level appropriate for their needs.

### 3. Explicit Relationships

Rather than isolated pages, we maintain structured relationships:

- **Entity links**: Cross-references in `entities.yaml`
- **Backlinks**: Automatic "cited by" tracking
- **Parameter networks**: Visual diagrams showing influence paths

### 4. Acknowledged Uncertainty

We use:
- Explicit confidence ranges (e.g., "30-50% probability")
- Quality ratings on pages
- Uncertainty scores on parameters
- Documented limitations

---

## Relationship to Academic Standards

This knowledge base is **not** a peer-reviewed publication. It's closer to:

- A **structured literature review** that synthesizes existing research
- A **conceptual framework** that organizes thinking
- A **reference resource** for practitioners and researchers

We cite primary sources where possible, but the organizational structure itself represents editorial judgment.

---

## Feedback and Evolution

This methodology will evolve. If you see:
- Frameworks we should engage with
- Structural inconsistencies
- Missing documentation

Please raise issues via the project repository.

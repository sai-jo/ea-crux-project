---
title: "Limitations & Known Gaps"
description: "Honest assessment of where our framework falls short—structural issues, coverage gaps, terminological problems, and areas where our approach may mislead."
sidebar:
  order: 3
quality: 4
lastEdited: "2026-01-02"
---
import {Mermaid} from '../../../../components/wiki';

## Overview

No framework is perfect. This page documents known limitations of our approach—not to undermine confidence, but to enable informed use. Understanding limitations helps readers:

- **Calibrate trust** appropriately for different claims
- **Identify where external sources are needed** for topics we cover poorly
- **Contribute improvements** where gaps are clearest
- **Avoid misapplying** the framework beyond its valid scope

We organize limitations into five categories: ontological, structural, coverage, quantification, and presentation.

---

## 1. Ontological Limitations

### 1.1 "Parameter" Is Used Non-Standardly

**The Problem**

In statistics and modeling, "parameter" has a specific meaning: a population-level property like a mean or regression coefficient. "Variables" are what we measure; "parameters" describe their distributions.

We use "parameter" to mean **system variable**—a quantity that can change and that we care about. This conflates what [system dynamics](https://thesystemsthinker.com/step-by-step-stocks-and-flows-improving-the-rigor-of-your-thinking/) calls stocks (accumulated quantities), flows (rates of change), and auxiliaries (computed values).

| Our Usage | System Dynamics Term | Example |
|-----------|---------------------|---------|
| "Trust parameter" | Stock | Current trust level (0-100) |
| "Trust declining" | Flow | Erosion rate (points/year) |
| "Trust gap" | Auxiliary | Difference from optimal |

**Why This Matters**

Without distinguishing stocks from flows, we cannot answer:
- At what rate must trust recover to reach target by 2030?
- Is racing intensity accelerating (flow increasing) or just high (stock elevated)?
- What's the half-life of safety culture improvements?

**Our Response**

We acknowledge this limitation and use "parameter" anyway because:
1. "System variable" sounds more technical than helpful
2. Most readers aren't system dynamicists
3. The conceptual insight (bidirectional variables) doesn't require formal stock-flow modeling

Future work may add explicit temporal dynamics. For now, we describe trends verbally ("declining," "improving slowly") rather than formally.

### 1.2 Outcome Independence Is Underspecified

**The Problem**

We claim the three outcomes (Acute Risk, Steady State, Transition) are "partially independent." But we don't specify:
- How correlated are they?
- What's the joint distribution?
- When do trade-offs arise?

The claim "you can have good steady state with rough transition" is intuitive but unquantified.

**Why This Matters**

Without a correlation structure, we can't:
- Prioritize interventions that improve multiple outcomes
- Identify interventions that trade off between outcomes
- Aggregate outcomes into overall "expected value"

**Our Response**

This is a genuine gap. We treat outcomes as separate evaluation criteria rather than components of a utility function. This is defensible if different stakeholders weight outcomes differently, but it limits formal analysis.

### 1.3 Causal Direction Is Often Ambiguous

**The Problem**

Our diagrams show edges like `Racing → Safety Culture` with label "undermines." But many relationships are bidirectional:
- Racing undermines safety culture
- Weak safety culture enables racing

We don't systematically identify feedback loops or distinguish correlation from causation.

<Mermaid client:load chart={`
flowchart LR
    R[Racing Intensity] -->|"undermines"| S[Safety Culture]
    S -->|"weak culture enables"| R

    style R fill:#ff6b6b
    style S fill:#90EE90
`} />

**Why This Matters**

- Missing feedback loops means missing important dynamics
- One-way arrows imply causation we can't establish
- Intervention design requires knowing causal direction

**Our Response**

We acknowledge this and encourage readers to treat relationships as "associations with proposed causal direction" rather than established causal facts. Future work should adopt [causal loop diagram](https://en.wikipedia.org/wiki/Causal_loop_diagram) conventions (R/B loop notation).

---

## 2. Structural Limitations

### 2.1 Steep Hierarchy Compression

**The Problem**

We compress 23 leaf parameters into 5 aggregates into 3 outcomes:

```
23 → 5 → 3 (compression ratios: 4.6x, 1.7x)
```

Compare to [AIR 2024](https://arxiv.org/html/2406.17864v1) which uses four levels with 314 types. Our compression loses intermediate structure.

**Consequences**

| Issue | Example |
|-------|---------|
| **Category labels don't match aggregates** | "Societal" parameters split across Epistemic Foundation, Societal Adaptability, and Threat Environment |
| **Aggregates vary in coherence** | Technical Safety (5 tightly related params) vs. Threat Environment (4 loosely related params) |
| **Navigation confusion** | Users expect Alignment parameters → Technical Safety, but some go to other aggregates |

**Our Response**

The three-tier structure optimizes for **cognitive simplicity** over analytical precision. A four-tier structure would:
- Add a "domain" layer (Alignment, Governance, Societal, Resilience)
- Map cleanly to sidebar categories
- Increase navigational complexity

We may add this layer in future iterations.

### 2.2 Dual-Membership Parameters

**The Problem**

Some parameters appear in multiple aggregates:

| Parameter | Aggregates | Why |
|-----------|------------|-----|
| Racing Intensity | Governance, Threat Environment | Undermines governance AND increases threat |
| Human Oversight Quality | Technical Safety, Societal Adaptability | Both technical capability AND human capacity |

This violates clean hierarchical structure and suggests these may be higher-order constructs.

**Why This Matters**

- Aggregates aren't mutually exclusive, complicating aggregation
- Double-counting risk when summing across aggregates
- Unclear which aggregate "owns" the parameter

**Our Response**

We accept dual membership as reflecting reality—some factors genuinely affect multiple outcome pathways. We document these cases explicitly rather than forcing artificial exclusivity.

### 2.3 "Context-Dependent" Direction

**The Problem**

Most parameters have clear direction (higher trust is better, lower racing is better). But some are context-dependent:

| Parameter | Issue |
|-----------|-------|
| AI Control Concentration | High concentration could mean monopoly (bad) or coordinated safety (good) |
| Regulatory Capacity | Could enable safety requirements OR capture by incumbents |

**Why This Matters**

Parameters should be evaluable—we should know if improving them is good. Context-dependent direction undermines this.

**Our Response**

We mark these parameters explicitly (`direction: context`) and discuss trade-offs in their pages. A more rigorous approach would split them:
- AI Concentration → "Unhealthy Concentration" (bad) + "Coordinated Control" (good)

This increases parameter count and complexity, which we've deferred.

---

## 3. Coverage Gaps

### 3.1 Near-Term Harms Underrepresented

**The Problem**

Comparing our coverage to the [MIT AI Risk Repository's](https://airisk.mit.edu/) seven domains:

| MIT Domain | Our Coverage | Gap Assessment |
|------------|--------------|----------------|
| Discrimination & Toxicity | Minimal | **Major gap** |
| Privacy & Security | Cyber exposure only | **Significant gap** |
| Misinformation | Epistemic Health (partial) | Moderate |
| Malicious Actors | Bio/cyber exposure | Adequate |
| Human-Computer Interaction | Human Agency, Oversight | Good |
| Socioeconomic & Environmental | Economic Stability; **no environment** | **Significant gap** |
| AI System Safety | Strong coverage | Good |

**Why This Matters**

We focus on **existential and structural risks** appropriate for an EA-adjacent project, but this may:
- Miss tractable near-term interventions
- Underweight harms affecting specific populations
- Create blind spots in governance recommendations

**Our Response**

This is a deliberate scope choice, not oversight. We acknowledge that:
- Privacy, discrimination, and environmental harms matter
- Our framework doesn't cover them well
- Readers should consult other sources for these topics

Adding parameters like "Privacy Protection Capacity" or "Algorithmic Fairness" is possible but would dilute our focus.

### 3.2 Non-Western Perspectives

**The Problem**

Our sources, framings, and examples are predominantly:
- Western (US/UK/EU focused)
- English-language
- Academic and policy-oriented

We underrepresent:
- Chinese AI safety discourse
- Global South perspectives
- Industry practitioner views
- Public opinion and democratic input

**Why This Matters**

AI development is global; governance requires international coordination. Western-centric framing may:
- Miss important considerations
- Reduce credibility with non-Western audiences
- Propose interventions that only work in Western contexts

**Our Response**

This is a genuine limitation we aim to improve through:
- Explicit parameter coverage of international coordination
- Sourcing from international organizations (UN, OECD)
- Welcoming contributions from diverse perspectives

### 3.3 Historical and Empirical Grounding

**The Problem**

Many claims lack historical validation:
- "Trust is declining" → Based on what baseline? Since when?
- "Racing dynamics are accelerating" → Compared to what prior period?
- "Governance capacity is insufficient" → Insufficient for what benchmark?

**Why This Matters**

Without historical grounding:
- Can't distinguish cyclical from secular trends
- Hard to set realistic targets
- Interventions may address symptoms not causes

**Our Response**

We include historical data where available (e.g., Pew trust surveys since 1964) but acknowledge many parameters lack systematic historical measurement. This is partly because AI risks are new—there's limited historical record to draw from.

---

## 4. Quantification Limitations

### 4.1 Scores Are Subjective

**The Problem**

Our 0-100 scores for importance, tractability, neglectedness, and uncertainty are:
- Based on editorial judgment, not formal elicitation
- Not validated against expert consensus
- Not updated systematically
- Presented with false precision (88 vs. 90 suggests meaningful difference)

**Why This Matters**

Users may:
- Over-weight quantitative scores vs. qualitative analysis
- Make resource allocation decisions based on unreliable rankings
- Miss that scores reflect one perspective, not consensus

**Our Response**

Scores are for **rough prioritization** and **tracking evolution**, not precise ranking. We recommend:
- Treat scores as ordinal (high/medium/low), not cardinal
- Read the qualitative analysis, not just the numbers
- Adjust based on your own judgment

Future work may add uncertainty ranges to scores themselves.

### 4.2 No Formal Uncertainty Propagation

**The Problem**

We report uncertainty on individual parameters but don't propagate it through aggregation:
- If Alignment Robustness uncertainty is 45% and Racing Intensity uncertainty is 50%, what's Technical Safety uncertainty?
- How confident should we be in outcome-level assessments?

**Why This Matters**

Uncertainty compounds through aggregation. Our outcome-level claims may be much less certain than component claims suggest.

**Our Response**

We acknowledge this gap. Formal uncertainty propagation would require:
- Specifying aggregation functions
- Estimating correlation between parameter uncertainties
- Computational infrastructure for Monte Carlo simulation

This is beyond current scope but would significantly improve rigor.

### 4.3 Trends Without Timescales

**The Problem**

We describe trends ("declining," "improving slowly") without specifying:
- Over what time period?
- At what rate?
- Expected future trajectory?

"Trust is declining" could mean:
- Down 5% over 5 years (gradual erosion)
- Down 50% over 50 years (secular decline)
- Down 10% last year, accelerating (crisis)

**Why This Matters**

Trend direction alone doesn't inform intervention urgency or design.

**Our Response**

Individual parameter pages include temporal data where available. But we don't have systematic time series for most parameters. This reflects data limitations, not analytical choice.

---

## 5. Presentation Limitations

### 5.1 Inconsistent Visual Language

**The Problem**

| Element | Mermaid Diagrams | React Components |
|---------|------------------|------------------|
| Parameters | Box, various colors | Purple circle |
| Risks | Red box | Red circle |
| Interventions | Green text | Green circle |
| Outcomes | Colored boxes | N/A |

The color scheme isn't documented, and users must learn it implicitly.

**Our Response**

See [Framework Design](/knowledge-base/methodology/framework-design/#decision-5-visual-language) for documentation. We plan to standardize and document visual conventions more explicitly.

### 5.2 Diagram Density vs. Readability

**The Problem**

Some diagrams approach or exceed recommended complexity limits:
- Main hierarchy diagram: 15+ nodes, many edges
- Parameter network diagrams: Variable complexity
- Flow diagrams: Can become cluttered

**Trade-off**

| Choice | Pro | Con |
|--------|-----|-----|
| Show everything | Complete picture | Visual overload |
| Simplify | Readable | Incomplete |
| Progressive disclosure | Best of both | Implementation complexity |

**Our Response**

We've aimed for "show the structure, link to details" but haven't fully implemented progressive disclosure. Some pages would benefit from simplified overview diagrams with links to detailed views.

### 5.3 Limited Interactivity

**The Problem**

Diagrams and tables are mostly static. Users cannot:
- Filter parameters by attribute
- Explore relationships interactively
- Run what-if scenarios
- Export custom views

**Our Response**

The `ParameterFlowDiagram` and `ParametersTable` components provide some interactivity. More sophisticated tools (scenario modeling, custom filtering) would require significant development investment.

---

## 6. Epistemic Limitations

### 6.1 Single-Source Editorial Judgment

**The Problem**

The framework reflects one organization's analytical perspective. We haven't:
- Conducted formal expert elicitation
- Validated structure against external panels
- Resolved disagreements through structured processes

**Why This Matters**

Our structural choices (which parameters, which relationships, which scores) embed assumptions that may not generalize.

**Our Response**

We acknowledge this and:
- Document our reasoning in the Methodology section
- Welcome external critique and contribution
- Plan to incorporate more diverse perspectives over time

### 6.2 Evolving Understanding

**The Problem**

AI safety is a young field with rapidly evolving understanding. Claims that seem well-established today may be revised as:
- New empirical results emerge
- Theoretical frameworks mature
- The technology itself changes

**Our Response**

We include `lastEdited` dates and aim for systematic review. But the knowledge base will inevitably contain some claims that become outdated between updates.

### 6.3 Unknown Unknowns

**The Problem**

Our parameter set reflects *known* factors affecting AI outcomes. There may be important factors we haven't identified—unknown unknowns that our framework doesn't capture.

**Examples of potential blind spots**:
- Novel failure modes not yet theorized
- Social dynamics we haven't modeled
- Interaction effects between parameters

**Our Response**

This is inherent in any framework. We can only:
- Acknowledge the limitation
- Update as new factors emerge
- Encourage readers to think beyond our structure

---

## Summary Table

| Category | Limitation | Severity | Mitigation |
|----------|------------|----------|------------|
| **Ontological** | Non-standard "parameter" usage | Medium | Documentation |
| | Outcome independence underspecified | Medium | Acknowledge uncertainty |
| | Causal ambiguity | High | Future: R/B loop notation |
| **Structural** | Steep hierarchy compression | Medium | Future: domain layer |
| | Dual-membership parameters | Low | Explicit documentation |
| | Context-dependent direction | Medium | Future: split parameters |
| **Coverage** | Near-term harms underrepresented | High | Scope choice; external sources |
| | Non-Western perspectives | Medium | Ongoing improvement |
| | Limited historical grounding | Medium | Data limitations |
| **Quantification** | Subjective scores | High | Treat as ordinal |
| | No uncertainty propagation | Medium | Future work |
| | Trends without timescales | Medium | Page-level data where available |
| **Presentation** | Inconsistent visuals | Low | Documentation |
| | Diagram complexity | Medium | Progressive disclosure |
| | Limited interactivity | Medium | Component development |
| **Epistemic** | Single-source judgment | High | Seek external input |
| | Evolving understanding | Medium | Systematic review |
| | Unknown unknowns | Inherent | Acknowledge |

---

## How to Help

If you see opportunities to address these limitations:

1. **Documentation**: Help us document conventions and assumptions
2. **Coverage**: Contribute content on underrepresented topics
3. **Validation**: Provide external review and critique
4. **Data**: Share relevant historical data or measurements
5. **Code**: Improve interactive components and visualization

Raise issues in the [project repository](https://github.com/quantified-uncertainty/ea-crux-project).

---

## Related Pages

- [Framework Design](/knowledge-base/methodology/framework-design/) — Why we made these choices
- [Ontology Landscape](/knowledge-base/methodology/ontology-landscape/) — How alternatives handle these issues
- [Terminology](/knowledge-base/methodology/terminology/) — Precise definitions

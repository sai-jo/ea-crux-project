---
title: Epoch AI
description: AI forecasting and research organization tracking compute trends, datasets, and AI progress
sidebar:
  order: 14
---

import { InfoBox, KeyPeople, EntityCard, EntityCards, Tags, Sources, Section, EstimateBox, DisagreementMap, KeyQuestions } from '../../../../components/wiki';

<InfoBox
  type="organization"
  title="Epoch AI"
  founded="2022"
  location="Remote / San Francisco, CA"
  headcount="~10-15"
  funding="Grants (Open Philanthropy, others)"
  website="https://epochai.org"
/>

## Overview

Epoch AI is a research organization dedicated to producing rigorous, data-driven forecasts and analysis about artificial intelligence progress, with particular focus on compute trends, training datasets, algorithmic efficiency, and AI timelines. Founded in 2022, Epoch has quickly become the authoritative source for empirical data about AI development trends.

Unlike organizations that work directly on alignment or capabilities, Epoch provides the crucial empirical foundation that informs the entire AI safety and policy ecosystem. Their work answers fundamental questions: How fast is AI progressing? When might transformative AI arrive? What are the key bottlenecks? How much compute do frontier models use?

Epoch's research is widely cited by policymakers, safety researchers, and AI labs. Their compute trend analyses inform governance proposals, their dataset tracking reveals training data bottlenecks, and their timeline estimates shape strategic planning across the field.

## History and Founding

### Origins (2022)

**Founded**: 2022 by researchers focused on AI forecasting

**Motivation for founding:**
- Need for rigorous empirical analysis of AI progress
- Existing forecasts often speculative or methodologically weak
- Policy decisions need data-driven foundation
- Compute governance requires detailed tracking
- Safety research needs accurate timeline estimates

**Initial focus:**
- Historical trends in compute usage
- Training dataset compilation and analysis
- Algorithmic progress measurement
- AI timeline forecasting methodologies

**Funding**: Primarily grants from effective altruism-aligned funders (Open Philanthropy)

### Early Work (2022-2023)

**Key initial projects:**

**Compute database:**
- Systematic collection of training compute for major AI models
- Historical trends from 1950s to present
- Publicly accessible database
- Regular updates with new models

**Dataset analysis:**
- "Will we run out of data?" paper
- Stock of high-quality text data for training
- Projections of dataset exhaustion
- Implications for future AI development

**Timeline forecasting:**
- Literature review of AI timeline estimates
- Methodology development for forecasting
- Parameter estimation for AGI timelines
- Uncertainty quantification

**Impact:**
- Widely cited by researchers and policymakers
- Informed compute governance proposals
- Provided empirical grounding for debates
- Established Epoch as authoritative source

### Growth and Expansion (2023-2024)

**2023 developments:**
- Expanded team of researchers and data scientists
- More comprehensive databases (Parameter Database)
- Algorithmic efficiency research
- International policy engagement
- Academic collaborations

**2024 progress:**
- Continuous database updates with new models
- Refined forecasting methodologies
- Deeper analysis of trends and bottlenecks
- Growing influence in policy circles
- Regular research outputs and blog posts

**Current status:**
- Leading organization for AI empirical analysis
- Go-to source for compute and dataset data
- Widely cited in academic and policy contexts
- Critical infrastructure for AI governance

## Core Research Areas

### 1. Compute Trends and Analysis

Epoch's most influential work tracks the computational resources used to train AI models.

**The Compute Database:**

**What it tracks:**
- Training compute (FLOPs) for major AI models
- Historical trends from 1950s to present
- Costs of training runs
- Compute doubling times
- Spending on AI training

**Key findings:**

**Exponential growth:**
- Compute used for largest models growing exponentially
- ~6-month doubling time (2010-2022)
- Faster than Moore's Law (~2-year doubling)
- Growth driven by scaling budgets, not just hardware improvement

**Cost trends:**
- Training costs for frontier models reaching hundreds of millions
- Projects costs to reach billions for future models
- Implications for who can compete
- Concentration of capability development

**Physical limits:**
- Projections of when compute growth hits limits
- Chip supply constraints
- Energy and cooling requirements
- Economic feasibility of continued scaling

**Policy implications:**
- Compute as chokepoint for governance
- Tracking frontier model development via compute
- Export controls and chip restrictions
- Visibility into AI capabilities race

**Impact:**
- Foundational data for compute governance proposals
- Cited in government AI strategies
- Used by labs for planning
- Essential for forecasting

### 2. Training Datasets and Data Constraints

Epoch's research on training data has revealed potential bottlenecks for future AI development.

**"Will We Run Out of Data?" Research:**

**Key questions:**
- How much high-quality text data exists?
- When will we exhaust training data?
- What happens when data runs out?
- Implications for AI progress

**Findings:**

**Stock of data:**
- Estimated ~10^13 tokens of high-quality text (books, articles, Wikipedia)
- ~10^15 tokens of lower-quality text (social media, web)
- Already using significant fraction for training

**Exhaustion timeline:**
- High-quality text: Could be exhausted by mid-2020s
- All text data: 2030s
- Image and video data: Later, but also finite
- Depends on efficiency of data use

**Implications:**

**For AI development:**
- Pressure to use data more efficiently
- Synthetic data generation
- Multimodal data (images, video) as alternative
- Diminishing returns from scaling data

**For timeline forecasts:**
- Potential slowdown if data exhaustion hits
- Or acceleration if synthetic data works
- Uncertainty about impact on progress
- Key variable for AGI timeline estimates

**Follow-up research:**
- Tracking data usage trends
- Synthetic data quality and scaling
- Multimodal training data stocks
- Efficiency improvements in data use

### 3. Algorithmic Efficiency

How much has AI progress come from better algorithms vs. just more compute and data?

**Research questions:**
- How much more efficient are current algorithms vs. older ones?
- What fraction of progress is algorithmic vs. scale?
- Will algorithmic progress continue?
- Implications for hardware and compute governance

**Methodology:**
- Compare old and new algorithms on same tasks
- Control for compute and data differences
- Measure efficiency gains over time
- Project future trends

**Findings:**
- Significant algorithmic progress in recent years
- Efficiency roughly doubling every 6-12 months (varies by domain)
- Comparable to or faster than hardware improvement
- Suggests algorithms are major driver, not just scale

**Policy implications:**
- Harder to govern than compute (algorithms are ideas)
- Can't rely solely on compute restrictions
- Need to track algorithmic progress too
- Implications for export controls effectiveness

**Uncertainty:**
- Will algorithmic progress continue at current rate?
- Fundamental limits to algorithmic efficiency?
- Interaction between scale and algorithms
- Hard to forecast future breakthroughs

### 4. AI Timelines and Forecasting

Epoch produces systematic forecasts for transformative AI timelines.

**Approach:**
- Data-driven, not purely subjective
- Multiple methodologies for robustness
- Explicit uncertainty quantification
- Regular updates as new data arrives

**Forecasting methods:**

**Extrapolation:**
- Project trends in compute, data, algorithms
- Estimate compute/data needed for transformative AI
- Calculate when trends intersect requirements
- Multiple scenarios based on assumptions

**Benchmark tracking:**
- Monitor performance on diverse tasks
- Extrapolate progress on benchmarks
- Estimate when human-level performance achieved
- Aggregate across multiple benchmarks

**Biological anchors:**
- Compare to brain computation
- Estimate compute needed for human-level AI
- Project when economically feasible
- Uncertainty ranges from assumptions

**Economic modeling:**
- Willingness to pay for AI capabilities
- Investment trends in AI
- Economic impacts of AI progress
- Feedback loops between AI and economy

**Current estimates (as of 2024):**
- Wide uncertainty ranges (2030s-2070s most common)
- Median often in 2040s-2050s
- Significant probability of sooner timelines (2030s)
- Updates as new data arrives

**Caveats Epoch emphasizes:**
- High uncertainty in all forecasts
- Discontinuous progress possible
- Unknown unknowns significant
- Should update continuously
- Multiple scenarios, not single prediction

## Key Research Outputs

### The Parameter Database

**Comprehensive tracking of:**
- Model sizes (parameters)
- Training compute
- Dataset sizes
- Training costs
- Organizations developing models
- Publication dates
- Architectures

**Value:**
- Publicly accessible
- Regularly updated
- High-quality curation
- Standardized methodology
- Essential research infrastructure

**Uses:**
- Trend analysis
- Forecasting
- Policy development
- Academic research
- Benchmarking

### Major Publications

**"Compute Trends Across Three Eras of Machine Learning" (2022)**
- Comprehensive historical analysis
- Identified distinct eras of ML scaling
- Documented exponential trends
- Widely cited in policy and research

**"Will We Run Out of Data?" (2022)**
- Analysis of training data constraints
- Projections of data exhaustion
- Implications for AI development
- Informed debate on scaling limits

**"Algorithmic Progress in Computer Vision" (2023)**
- Quantified efficiency improvements
- Separated algorithmic from hardware gains
- Implications for governance
- Methodology for tracking algorithmic progress

**"Trends in Training Dataset Sizes" (2023)**
- Documentation of dataset scaling
- Analysis of data efficiency
- Projections of future needs
- Dataset bottleneck identification

**Regular blog posts and updates:**
- Analysis of new frontier models (GPT-4, Gemini, Claude)
- Compute cost estimates
- Trend updates
- Policy implications discussions

## Key People

<Section title="Research Team">
  <KeyPeople people={[
    { name: "Jaime Sevilla", role: "Director" },
    { name: "Tamay Besiroglu", role: "Researcher" },
    { name: "Anson Ho", role: "Researcher" },
    { name: "Various data scientists and researchers", role: "Database curation and analysis" },
  ]} />
</Section>

### Jaime Sevilla (Director)

**Background:**
- Background in computer science and forecasting
- Previously involved in effective altruism forecasting projects
- Strong quantitative and analytical skills
- Experience in AI safety and governance

**Leadership:**
- Strategic direction for Epoch
- Research agenda setting
- External relations and communication
- Building team and infrastructure

**Approach:**
- Rigorous empirical methodology
- Transparency about uncertainty
- Regular updates as data changes
- Engagement with both research and policy communities

### Research Team

**Expertise areas:**
- Machine learning and AI systems
- Data science and statistical analysis
- Forecasting methodologies
- Economic modeling
- Compute and hardware trends
- Database engineering

**Culture:**
- Data-driven and empirical
- Methodological rigor
- Transparency and replicability
- Regular output and updates
- Collaborative with external researchers

## Impact on AI Safety and Policy

### Informing Governance

**Compute governance:**
- Empirical foundation for chip controls
- Tracking which actors can train frontier models
- Identifying compute chokepoints
- Monitoring compliance with restrictions

**Policy examples:**
- US AI executive order (references compute thresholds)
- Export controls on advanced chips (informed by Epoch data)
- UK AI Safety Institute (uses Epoch benchmarks)
- EU AI Act (risk tier definitions)

**International coordination:**
- Common language for AI capabilities
- Shared database for monitoring
- Technical foundation for agreements
- Transparency and verification mechanisms

### Shaping Research Priorities

**Timeline estimates influence:**
- How urgent is AI safety work?
- What time horizons for research?
- Resource allocation decisions
- Career choices in AI safety

**Bottleneck identification informs:**
- Where to focus governance efforts (compute vs. algorithms vs. data)
- Research directions for safety
- Commercial strategy for labs
- Investment decisions

**Examples:**
- Data exhaustion research → synthetic data research boom
- Compute trends → focus on compute governance
- Algorithmic progress → recognition that chip controls insufficient

### Academic and Industry Use

**Cited by:**
- AI safety researchers
- ML researchers studying scaling
- Economics papers on AI impact
- Policy white papers and reports
- Industry strategy documents

**Database users:**
- Researchers analyzing trends
- Policymakers developing regulations
- Labs benchmarking their work
- Journalists reporting on AI
- Educators teaching about AI

## Criticisms and Limitations

### Forecasting Uncertainty

**Fundamental challenge**: Predicting future AI progress is very hard

**Limitations:**
- Unknown unknowns (future breakthroughs)
- Extrapolation can fail at discontinuities
- Multiple scenarios, wide uncertainty ranges
- Past trends might not continue
- Hard to forecast algorithmic progress

**Epoch's response:**
- Transparent about uncertainty
- Multiple methodologies
- Regular updates
- Explicit scenario analysis
- Don't claim high confidence

**Ongoing debate**: How much weight should we put on empirical forecasts vs. other methods?

### Data Collection Challenges

**Issues:**
- Not all models publicly documented
- Compute estimates sometimes require inference
- Training details often proprietary
- Lag between model development and public information
- Selective disclosure by labs

**Impact:**
- Database necessarily incomplete for cutting-edge work
- Estimates have error bars
- Most valuable data might be secret
- Hard to track classified or secret projects

**Mitigation:**
- Conservative estimates when uncertain
- Transparent methodology
- Regular updates as information emerges
- Engagement with labs for data

### Interpretation and Use

**Risk of misuse:**
- Forecasts might drive racing dynamics ("must build AGI by 2030")
- Compute data could inform adversaries
- Timeline estimates might create complacency or panic
- Selective citation of findings

**Responsible communication:**
- Emphasize uncertainty
- Nuanced presentation
- Engage with how findings are used
- Public good mission vs. information hazards

**Epoch's approach:**
- Careful framing
- Academic rigor
- Engagement with policy community
- Transparency about limitations

### Resource Constraints

**Limitations:**
- Small team (~10-15 people)
- Can't track everything
- Funding dependent on grants
- Competing priorities

**Implications:**
- Focus on highest-impact work
- Some areas under-researched
- Delays in database updates
- Depend on community contributions

**Future scaling:**
- Need for sustained funding
- Growing team carefully
- Maintaining quality while expanding
- Building infrastructure

<KeyQuestions questions={[
  "How reliable are AI timeline forecasts based on trend extrapolation?",
  "Will data or compute constraints significantly slow AI progress?",
  "How should policymakers use Epoch's data for governance?",
  "What happens when algorithmic progress makes compute governance less effective?",
  "How can we track secret or classified AI development?",
  "Should timeline estimates be made public, or do they create racing dynamics?"
]} />

## Future Directions

### Research Roadmap

**Continuing work:**
- Database maintenance and expansion
- Regular trend updates
- Refined forecasting methodologies
- New data sources and metrics
- Algorithmic progress tracking

**New directions:**
- Multimodal training data analysis
- Energy and environmental impact tracking
- Economic modeling of AI industry
- Geopolitical dimensions of AI development
- Risk from different development paths

**Infrastructure building:**
- Better automation for data collection
- API access to databases
- Visualization and analysis tools
- Collaboration platforms
- Academic partnerships

### Policy Integration

**Growing role in governance:**
- Technical advisory to governments
- International standard setting
- Monitoring and verification frameworks
- Risk assessment for regulations
- Transparency and reporting standards

**Challenges:**
- Balancing openness with information hazards
- Maintaining independence while engaging with policy
- Scaling to meet growing demand
- International coordination

### Open Questions

**Research priorities:**
1. How to forecast algorithmic progress?
2. What are the key bottlenecks for transformative AI?
3. How to track AI progress beyond benchmark gaming?
4. What leading indicators for dangerous capabilities?
5. How to maintain visibility as AI development becomes more secretive?

<Section title="Value of Empirical Forecasting">
  <DisagreementMap
    client:load
    topic="Reliability and Use of AI Forecasts"
    positions={[
      {
        name: "Essential for Decision-Making",
        description: "Epoch's empirical work is crucial for rational planning. Timeline estimates inform urgency. Compute data enables governance. Better to have data-driven forecasts than pure speculation.",
        proponents: ["Policy community", "Many safety researchers", "Effective altruism"],
        strength: 4
      },
      {
        name: "Useful but Limited",
        description: "Forecasts provide valuable context but shouldn't drive strategy alone. Useful for identifying trends and bottlenecks. But high uncertainty means shouldn't over-rely on specific estimates.",
        proponents: ["Many researchers", "Cautious policymakers"],
        strength: 4
      },
      {
        name: "Potentially Harmful",
        description: "Publishing timelines might create racing dynamics. Compute data could inform adversaries. Creates false precision. Better to focus on building safety regardless of timelines.",
        proponents: ["Some safety researchers", "MIRI-adjacent views"],
        strength: 2
      },
      {
        name: "Fundamentally Uncertain",
        description: "AI progress too unpredictable to forecast meaningfully. Unknown unknowns dominate. Past trends don't predict transformative AI. Effort better spent elsewhere than forecasting.",
        proponents: ["Some researchers skeptical of forecasting"],
        strength: 2
      }
    ]}
  />
</Section>

## Comparisons to Other Organizations

### vs Metaculus / Forecasting Platforms

**Epoch:**
- Organization with dedicated researchers
- Original empirical research
- Database building and maintenance
- Systematic methodologies

**Metaculus:**
- Crowdsourced forecasting platform
- Aggregates many predictors
- Broader topic coverage
- More timely updates on specific questions

**Complementary**: Epoch provides data and analysis, platforms aggregate diverse views

### vs AI Impacts (now mostly inactive)

**AI Impacts:**
- Earlier organization doing similar work
- Broader scope, less systematic
- Pioneered some methodologies
- Less active in recent years

**Epoch:**
- More focused and systematic
- Better maintained databases
- Larger team and funding
- Absorbed some AI Impacts work

**Succession**: Epoch built on AI Impacts' foundation

### vs Think Tanks and Policy Organizations

**Epoch:**
- Technical and empirical focus
- Database infrastructure
- Quantitative analysis
- Forecasting expertise

**Policy orgs (GovAI, CSET, etc.):**
- Policy recommendations
- Governance frameworks
- Stakeholder engagement
- Implementation focus

**Relationship**: Epoch provides empirical foundation, policy orgs build on it

### vs Frontier Labs

**Labs (OpenAI, Anthropic, DeepMind):**
- Building AI systems
- Internal forecasts and planning
- Commercial incentives
- Proprietary data

**Epoch:**
- External observer
- Public databases
- Academic approach
- Independent analysis

**Tension**: Labs might not want to share data Epoch wants to track

<Section title="Related Topics">
  <Tags tags={[
    "AI Forecasting",
    "Compute Trends",
    "Training Datasets",
    "Algorithmic Progress",
    "AI Timelines",
    "Transformative AI",
    "Compute Governance",
    "Parameter Counts",
    "Scaling Laws",
    "Data Constraints",
    "Empirical Analysis",
    "Trend Extrapolation"
  ]} />
</Section>

<Section title="Related Entries">
  <EntityCards>
    <EntityCard
      id="compute-governance"
      category="policies"
      title="Compute Governance"
      description="Policy area informed by Epoch's data"
    />
    <EntityCard
      id="transformative-ai"
      category="concepts"
      title="Transformative AI"
      description="What Epoch forecasts timelines for"
    />
    <EntityCard
      id="scaling-laws"
      category="concepts"
      title="Scaling Laws"
      description="Empirical trends Epoch documents"
    />
    <EntityCard
      id="ai-timelines"
      category="concepts"
      title="AI Timelines"
      description="Core research focus for Epoch"
    />
    <EntityCard
      id="data-constraints"
      category="concepts"
      title="Data Constraints"
      description="Bottleneck Epoch identified"
    />
  </EntityCards>
</Section>

<Sources sources={[
  { title: "Epoch AI Website", url: "https://epochai.org" },
  { title: "Epoch Parameter Database", url: "https://epochai.org/data/epochdb/visualization" },
  { title: "Compute Trends Paper", url: "https://epochai.org/blog/compute-trends" },
  { title: "Will We Run Out of Data?", url: "https://epochai.org/blog/will-we-run-out-of-data" },
  { title: "Algorithmic Progress Research", url: "https://epochai.org/blog/revisiting-algorithmic-progress" },
  { title: "Epoch Research Blog", url: "https://epochai.org/blog" },
  { title: "Epoch on Twitter/X", url: "https://twitter.com/epoch_ai" }
]} />

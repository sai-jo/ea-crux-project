---
title: Government AI Safety Institutes
description: Government bodies focused on AI safety evaluation and policy
sidebar:
  label: Overview
  order: 0
---

import { Section, EntityCards, EntityCard } from '../../../../components/wiki';


## Summary

Government AI safety institutes evaluate AI systems, develop safety standards, and inform policy. They represent a new approach to AI governanceâ€”technical safety evaluation as a government function.

## AI Safety Institutes

<Section title="Government Institutes">
  <EntityCards>
    <EntityCard
      id="uk-aisi"
      category="government"
      title="UK AI Safety Institute"
      description="First government AI safety institute. Focuses on frontier model evaluation."
    />
    <EntityCard
      id="us-aisi"
      category="government"
      title="US AI Safety Institute"
      description="Part of NIST. Develops AI safety standards and evaluation frameworks."
    />
  </EntityCards>
</Section>

## Key Functions

| Function | Description |
|----------|-------------|
| **Pre-deployment evaluation** | Testing frontier models before release |
| **Standards development** | Creating safety benchmarks and requirements |
| **Incident monitoring** | Tracking AI-related incidents and near-misses |
| **International coordination** | Working with other governments on AI safety |
| **Policy advice** | Informing legislation and regulation |

## Emerging International Network

Multiple countries are establishing AI safety institutes, potentially forming an international network for:
- Shared evaluation frameworks
- Coordinated safety standards
- Information sharing about risks
- Joint research initiatives


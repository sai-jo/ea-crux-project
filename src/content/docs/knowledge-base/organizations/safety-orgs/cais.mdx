---
title: CAIS (Center for AI Safety)
description: Organization focused on reducing societal-scale risks from AI
sidebar:
  order: 14
quality: 1
llmSummary: CAIS is a nonprofit AI safety organization that conducts technical
  research, field-building, and public communication, most notably organizing
  the May 2023 statement on AI extinction risk signed by hundreds of researchers
  including major AI leaders. Their research focuses on representation
  engineering, safety benchmarks, and adversarial robustness.
lastEdited: "2025-12-24"
importance: 35
---

import {DataInfoBox, KeyPeople, Section, Backlinks} from '../../../../components/wiki';

<DataInfoBox entityId="cais" />

## Summary

The Center for AI Safety (CAIS) is a nonprofit organization that works to reduce societal-scale risks from AI. CAIS combines research, field-building, and public communication to advance AI safety.

CAIS is notable for organizing the "Statement on AI Risk" signed by hundreds of AI researchers warning that "mitigating the risk of extinction from AI should be a global priority."

## Activities

### Research
CAIS conducts technical AI safety research:
- Representation engineering
- Adversarial robustness
- AI safety benchmarks
- Conceptual AI safety research

### Field-Building
Major field-building efforts:
- Compute grants for safety researchers
- ML Safety Scholars program
- AI Safety Camp coordination
- Research fellowship programs

### Public Communication
Efforts to raise awareness of AI risks:
- Statement on AI Risk (May 2023)
- Media engagement
- Educational resources

## Key Research

### Representation Engineering
Techniques for understanding and controlling AI behavior through internal representations:
- Reading model "thoughts"
- Steering model behavior
- Detecting deception

### Safety Benchmarks
Developing evaluation tools:
- Measuring power-seeking tendencies
- Evaluating situational awareness
- Testing for dangerous capabilities

<Section title="Key People">
  <KeyPeople people={[
    { name: "Dan Hendrycks", role: "Executive Director" },
    { name: "Mantas Mazeika", role: "Research Scientist" },
    { name: "Thomas Woodside", role: "Policy Director" },
  ]} />
</Section>

## Statement on AI Risk

In May 2023, CAIS organized a one-sentence statement:

> "Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war."

Signed by:
- Geoffrey Hinton (Turing Award winner)
- Yoshua Bengio (Turing Award winner)
- Dario Amodei (Anthropic CEO)
- Sam Altman (OpenAI CEO)
- Demis Hassabis (DeepMind CEO)
- Hundreds more researchers

## Key Publications

- **Representation Engineering** (2023)
- **MACHIAVELLI Benchmark** (2023)
- **Unsolved Problems in ML Safety** (2022)
- **Measuring Power-Seeking** (2023)

## Related Pages

<Backlinks client:load entityId="cais" />

---
title: CAIS (Center for AI Safety)
description: Organization focused on reducing societal-scale risks from AI
sidebar:
  order: 14
---

import {DataInfoBox, KeyPeople, Section, Backlinks, PageStatus} from '../../../../../components/wiki';

<PageStatus quality={2} lastEdited="2025-12-24" llmSummary="Center for AI Safety nonprofit organization working to reduce societal-scale AI risks through research, field-building, and public communication. Notable for organizing the May 2023 'Statement on AI Risk' signed by hundreds of AI researchers including Hinton, Bengio, and lab CEOs warning that mitigating extinction risk from AI should be a global priority." todo="Needs expansion on specific technical research contributions, representation engineering work, and current activities beyond the high-profile statement" />

<DataInfoBox entityId="cais" />

## Summary

The Center for AI Safety (CAIS) is a nonprofit organization that works to reduce societal-scale risks from AI. CAIS combines research, field-building, and public communication to advance AI safety.

CAIS is notable for organizing the "Statement on AI Risk" signed by hundreds of AI researchers warning that "mitigating the risk of extinction from AI should be a global priority."

## Activities

### Research
CAIS conducts technical AI safety research:
- Representation engineering
- Adversarial robustness
- AI safety benchmarks
- Conceptual AI safety research

### Field-Building
Major field-building efforts:
- Compute grants for safety researchers
- ML Safety Scholars program
- AI Safety Camp coordination
- Research fellowship programs

### Public Communication
Efforts to raise awareness of AI risks:
- Statement on AI Risk (May 2023)
- Media engagement
- Educational resources

## Key Research

### Representation Engineering
Techniques for understanding and controlling AI behavior through internal representations:
- Reading model "thoughts"
- Steering model behavior
- Detecting deception

### Safety Benchmarks
Developing evaluation tools:
- Measuring power-seeking tendencies
- Evaluating situational awareness
- Testing for dangerous capabilities

<Section title="Key People">
  <KeyPeople people={[
    { name: "Dan Hendrycks", role: "Executive Director" },
    { name: "Mantas Mazeika", role: "Research Scientist" },
    { name: "Thomas Woodside", role: "Policy Director" },
  ]} />
</Section>

## Statement on AI Risk

In May 2023, CAIS organized a one-sentence statement:

> "Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war."

Signed by:
- Geoffrey Hinton (Turing Award winner)
- Yoshua Bengio (Turing Award winner)
- Dario Amodei (Anthropic CEO)
- Sam Altman (OpenAI CEO)
- Demis Hassabis (DeepMind CEO)
- Hundreds more researchers

## Key Publications

- **Representation Engineering** (2023)
- **MACHIAVELLI Benchmark** (2023)
- **Unsolved Problems in ML Safety** (2022)
- **Measuring Power-Seeking** (2023)

## Related Pages

<Backlinks client:load entityId="cais" />

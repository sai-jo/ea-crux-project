---
title: Epoch AI
description: AI forecasting and research organization providing empirical data infrastructure through compute tracking (6-month doubling), dataset analysis (high-quality text exhaustion by mid-2020s), and timeline forecasting for AI governance and policy decisions
sidebar:
  order: 14
quality: 5
llmSummary: Epoch AI is a research organization founded in 2022 that provides empirical data and forecasting on AI progress, particularly tracking compute trends (6-month doubling time for largest models), training datasets (high-quality text data could be exhausted by mid-2020s), and algorithmic efficiency (doubling every 6-12 months). Their work serves as foundational data infrastructure for AI governance and policy decisions across the field.
lastEdited: "2025-12-24"
importance: 45
---

import {DataInfoBox, DisagreementMap, KeyPeople, KeyQuestions, Section} from '../../../../../components/wiki';

<DataInfoBox entityId="epoch-ai" />

## Overview

Epoch AI is a research organization founded in 2022 that provides rigorous, data-driven empirical analysis and forecasting of AI progress. Their work serves as critical infrastructure for [AI governance](/knowledge-base/responses/governance/) and [timeline forecasting](/understanding-ai-risk/core-argument/timelines/), tracking three key metrics: compute usage is doubling every 6 months for frontier models, high-quality training data may be exhausted by the mid-2020s, and algorithmic efficiency improves by 2x every 6-12 months.

Unlike organizations developing AI capabilities or safety techniques directly, Epoch provides the empirical foundation that informs strategic decisions across the AI ecosystem. Their databases and forecasts are cited by policymakers designing [compute governance](/knowledge-base/responses/governance/compute-governance/) frameworks, safety researchers planning research timelines, and AI labs benchmarking their progress against industry trends.

Their most influential finding is the exponential growth in training compute for frontier models—approximately 10,000x increase from 2012-2022—which has become foundational for understanding AI progress and informing governance approaches focused on compute as a key chokepoint.

## Risk Assessment

| Risk Category | Assessment | Evidence | Timeline | Trajectory |
|---------------|------------|----------|----------|------------|
| Data Bottleneck | High | High-quality text ~10^13 tokens, current usage accelerating | Mid-2020s | Worsening |
| Compute Scaling | Medium | 6-month doubling unsustainable long-term, hitting physical limits | 2030s | Stable |
| Governance Lag | High | Policy development slower than tech progress | Ongoing | Improving |
| Forecasting Accuracy | Medium | Wide uncertainty bounds, unknown unknowns | Continuous | Improving |

## Key Research Areas

### Compute Trends Analysis

Epoch's flagship research tracks computational resources used to train AI models, revealing exponential scaling patterns.

| Metric | Current Trend | Key Finding | Policy Implication |
|--------|---------------|-------------|-------------------|
| Training Compute | 6-month doubling (2010-2022) | 10,000x increase since 2012 | [Compute governance](/knowledge-base/responses/governance/compute-governance/) viable |
| Training Costs | $100M+ for frontier models | Projected billions by 2030 | Market concentration |
| Hardware Utilization | Massive GPU clusters | H100s bottleneck for capabilities | Export controls effectiveness |

**Critical findings from [Epoch's compute database](https://epochai.org/data/epochdb/visualization)**:

- **Exponential growth faster than Moore's Law**: While chip performance doubles every ~2 years, AI training compute doubles every 6 months
- **Economic scaling**: Training costs reached $100M+ for GPT-4 class models, projected to hit billions by 2030
- **Concentration effects**: Only a few actors can afford frontier training runs, creating natural bottlenecks for governance

### Training Data Constraints

Epoch's ["Will We Run Out of Data?"](https://epochai.org/blog/will-we-run-out-of-data) research revealed potential bottlenecks for continued AI scaling.

| Data Type | Estimated Stock | Current Usage Rate | Exhaustion Timeline |
|-----------|-----------------|-------------------|-------------------|
| High-quality text | ~10^13 tokens | Accelerating | Mid-2020s |
| All web text | ~10^15 tokens | Increasing | Early 2030s |
| Image data | Larger but finite | Growing rapidly | 2030s+ |
| Video data | Massive but hard to use | Early stages | Unknown |

**Key implications**:
- **Pressure for efficiency**: Data constraints may force more efficient training methods
- **Synthetic data boom**: Investment in AI-generated training data accelerating
- **Multimodal shift**: [Language models](/knowledge-base/capabilities/language-models/) may pivot to image/video data

### Timeline Forecasting Methodology

Epoch employs multiple complementary approaches to estimate transformative AI timelines:

| Method | Current Estimate Range | Key Variables | Confidence Level |
|--------|----------------------|---------------|-----------------|
| Trend Extrapolation | 2030s-2040s | Compute, data, algorithms | Medium |
| Biological Anchors | 2040s-2050s | Brain computation estimates | Low |
| Benchmark Analysis | 2030s-2050s | Task performance rates | Medium |
| Economic Modeling | 2035-2060s | Investment trends, ROI | Low |

## Impact on AI Safety and Governance

### Policy Integration

Epoch's data directly informs major governance initiatives:

| Policy Area | Epoch Contribution | Real-World Impact |
|-------------|-------------------|-------------------|
| [US AI Executive Order](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/) | 10^26 FLOPs threshold | Training run reporting requirements |
| [Export controls](https://www.bis.doc.gov/index.php/policy-guidance/product-guidance/artificial-intelligence) | H100/A100 performance data | Chip restriction implementation |
| [UK AI Safety Institute](https://www.gov.uk/government/organisations/ai-safety-institute) | Capability benchmarking | Model evaluation frameworks |
| [Compute governance](/knowledge-base/responses/governance/compute-governance/) research | Database infrastructure | Academic research foundation |

### Research Community Influence

| Metric | Evidence | Source |
|--------|----------|--------|
| Academic citations | 1,000+ citations across safety research | [Google Scholar](https://scholar.google.com) |
| Policy references | 50+ government documents cite Epoch | Government databases |
| Database usage | 10,000+ downloads of compute database | Epoch analytics |
| Media coverage | Regular coverage in AI media | [AI News tracking](https://www.artificialintelligence-news.com) |

## Current State and Trajectory

### 2024 Developments

**Database expansion**:
- Added 200+ new model entries to Parameter Database
- Enhanced tracking of Chinese and European models
- Improved cost estimation methodologies
- [Real-time updates](https://epochai.org/data/epochdb) for new releases

**Research breakthroughs**:
- Refined algorithmic efficiency measurement showing 6-12 month doubling times
- Updated data exhaustion projections with synthetic data considerations
- New economic modeling of AI investment trends
- [Bioweapons AI uplift analysis](/knowledge-base/models/bioweapons-ai-uplift/)

### 2025-2026 Projections

| Area | Expected Development | Impact |
|------|-------------------|--------|
| Data bottleneck | High-quality text exhaustion begins | Synthetic data scaling accelerates |
| Compute governance | Standardized international monitoring | Enhanced [export controls](/knowledge-base/responses/governance/compute-governance/export-controls/) |
| Timeline updates | Narrower uncertainty bounds | More precise [AGI timeline](/knowledge-base/forecasting/agi-timeline/) estimates |
| Algorithmic progress | Continued 2x/year efficiency gains | Reduces compute governance effectiveness |

## Key Uncertainties and Debates

### Forecasting Limitations

| Uncertainty | Impact on Estimates | Mitigation Strategy |
|-------------|-------------------|-------------------|
| Algorithmic breakthroughs | Could accelerate timelines by years | Multiple forecasting methods |
| Data efficiency improvements | May extend scaling runway | Conservative assumptions |
| Geopolitical disruption | Could fragment or accelerate development | Scenario planning |
| Hardware bottlenecks | May slow progress unexpectedly | Supply chain analysis |

### Methodological Debates

**Trend extrapolation reliability**:
- **Optimists**: Historical trends provide best available evidence for forecasting
- **Pessimists**: [Sharp left turns](/knowledge-base/risks/accident/sharp-left-turn/) and discontinuities make extrapolation unreliable
- **Epoch position**: Multiple methods with explicit uncertainty bounds

**Information hazards**:
- **Security concern**: Publishing compute data aids adversaries in capability assessment
- **Racing dynamics**: Timeline estimates may encourage competitive behavior  
- **Transparency advocates**: Public data essential for democratic governance

<Section title="Forecasting Reliability Debate">
  <DisagreementMap
    client:load
    topic="Value of Empirical AI Forecasting"
    positions={[
      {
        name: "Essential Infrastructure",
        description: "Epoch's data provides crucial foundation for rational planning. Timeline estimates inform urgency decisions. Compute tracking enables governance. Superior to pure speculation.",
        proponents: ["Policy community", "Many safety researchers", "EA researchers"],
        strength: 4
      },
      {
        name: "Useful but Limited",
        description: "Valuable for trend identification but shouldn't drive strategy alone. High uncertainty requires robust planning across scenarios rather than point estimates.",
        proponents: ["Cautious researchers", "Some policymakers"],
        strength: 4
      },
      {
        name: "Information Hazard Risk", 
        description: "Timeline publication creates racing dynamics. Compute data aids adversaries. False precision worse than acknowledged uncertainty. Focus on safety regardless of timelines.",
        proponents: ["Security-focused researchers", "Some MIRI-adjacent views"],
        strength: 2
      },
      {
        name: "Fundamentally Uncertain",
        description: "AI development too discontinuous to forecast meaningfully. Unknown unknowns dominate. Resources better spent on robustness than prediction.",
        proponents: ["Anti-forecasting researchers", "Some capability pessimists"],
        strength: 2
      }
    ]}
  />
</Section>

## Leadership and Organization

### Key Personnel

<Section title="Leadership Team">
  <KeyPeople people={[
    { name: "Jaime Sevilla", role: "Director", description: "Computer scientist with forecasting expertise, drives research agenda and external engagement" },
    { name: "Tamay Besiroglu", role: "Senior Researcher", description: "Lead on compute trends analysis and economic modeling of AI progress" },
    { name: "Anson Ho", role: "Research Scientist", description: "Database infrastructure and algorithmic efficiency measurement" },
    { name: "Various data scientists", role: "Database Team", description: "Model tracking, data curation, and analysis automation" },
  ]} />
</Section>

### Organizational Structure

| Function | Team Size | Key Responsibilities |
|----------|-----------|---------------------|
| Research | 8-10 people | Forecasting, analysis, publications |
| Engineering | 3-4 people | Database infrastructure, automation |
| Operations | 2-3 people | Funding, administration, communications |
| Advisory | External | Policy guidance, technical review |

**Funding sources**:
- [Open Philanthropy](https://www.openphilanthropy.org/) (primary funder)
- [Future of Humanity Institute](https://www.fhi.ox.ac.uk/) (historical support)
- Government contracts for specific projects
- Research grants from academic institutions

## Comparative Analysis

### vs. Other Forecasting Organizations

| Organization | Focus | Methodology | Update Frequency | Policy Impact |
|--------------|-------|-------------|------------------|---------------|
| **Epoch AI** | AI-specific empirical data | Multiple quantitative methods | Continuous | High |
| [Metaculus](https://www.metaculus.com/) | Crowdsourced forecasting | Prediction aggregation | Real-time | Medium |
| [AI Impacts](https://aiimpacts.org/) | Historical AI analysis | Case studies, trend analysis | Irregular | Medium |
| [FHI](https://www.fhi.ox.ac.uk/) | Existential risk research | Academic research | Project-based | High |

### Relationship to Safety Organizations

| Organization Type | Relationship to Epoch | Information Flow |
|------------------|----------------------|------------------|
| [Safety research orgs](/knowledge-base/organizations/safety-orgs/) | Data consumers | Epoch → Safety orgs |
| [AI labs](/knowledge-base/organizations/labs/) | Data subjects | Labs → Epoch (reluctantly) |
| [Government bodies](/knowledge-base/organizations/government/) | Policy clients | Epoch ↔ Government |
| Think tanks | Research partners | Collaborative |

## Future Directions and Challenges

### Research Roadmap (2025-2027)

**Expanding scope**:
- Multimodal training data analysis beyond text
- Energy consumption and environmental impact tracking
- International AI development monitoring
- [Risk assessment frameworks](/knowledge-base/cruxes/) for different development pathways

**Methodological improvements**:
- Better algorithmic progress measurement
- Synthetic data quality and scaling analysis
- Economic impact modeling of AI deployment
- [Scenario analysis](/knowledge-base/scenarios/) for different development paths

### Scaling Challenges

| Challenge | Current Limitation | Planned Solution |
|-----------|-------------------|------------------|
| Data collection | Manual curation, limited sources | Automated scraping, industry partnerships |
| International coverage | US/UK bias in data | Partnerships with Chinese and European researchers |
| Real-time tracking | Lag in proprietary model information | Industry reporting standards |
| Resource constraints | ~15 person team | Gradual expansion, automation |

<KeyQuestions questions={[
  "How accurate are extrapolation-based AI timeline forecasts given potential discontinuities?",
  "Will synthetic data generation solve the training data bottleneck or create new limitations?",
  "How should compute governance adapt as algorithmic efficiency reduces compute as a chokepoint?",
  "What level of transparency in AI development is optimal for governance without security risks?",
  "How can empirical forecasting organizations maintain independence while engaging with policymakers?",
  "What leading indicators best predict dangerous capability emergence beyond compute scaling?"
]} />

## Sources & Resources

### Primary Resources

| Resource Type | Description | Link |
|---------------|-------------|------|
| Compute Database | Live database of AI model training compute | [epochai.org/data/epochdb](https://epochai.org/data/epochdb) |
| Parameter Database | Model sizes, costs, and capabilities tracking | [epochai.org/data/epochdb/visualization](https://epochai.org/data/epochdb/visualization) |
| Research Blog | Regular analysis and updates | [epochai.org/blog](https://epochai.org/blog) |
| Publications | Academic papers and reports | [epochai.org/research](https://epochai.org/research) |

### Key Publications

| Title | Year | Impact | Citation |
|-------|------|--------|---------|
| "Compute Trends Across Three Eras of Machine Learning" | 2022 | Foundational for compute governance | [Sevilla et al.](https://arxiv.org/abs/2202.05924) |
| "Will We Run Out of Data?" | 2022 | Sparked synthetic data research boom | [Villalobos et al.](https://arxiv.org/abs/2211.04325) |
| "Algorithmic Progress in Computer Vision" | 2023 | Quantified efficiency improvements | [Besiroglu et al.](https://arxiv.org/abs/2212.05153) |
| "Parameter, Compute and Data Trends" | 2024 | Updated scaling law analysis | [Epoch AI](https://epochai.org/blog/parameter-compute-data-trends) |

### External Coverage

| Source Type | Description | Example Links |
|-------------|-------------|---------------|
| Policy Documents | Government citations of Epoch work | [US NAIRR](https://www.ai.gov/nairr/), [UK AI White Paper](https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach) |
| Academic Citations | Research building on Epoch data | [Google Scholar search](https://scholar.google.com/scholar?q="Epoch+AI"+compute+trends) |
| Media Coverage | Journalism covering AI progress using Epoch data | [MIT Technology Review](https://www.technologyreview.com/), [AI News](https://artificialintelligence-news.com/) |
| Industry Analysis | Business intelligence using Epoch metrics | [CB Insights](https://www.cbinsights.com/), [McKinsey AI reports](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier) |
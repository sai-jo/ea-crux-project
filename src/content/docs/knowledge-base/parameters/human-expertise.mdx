---
title: "Human Expertise"
description: "The maintenance of human skills, knowledge, and cognitive capabilities in an AI-augmented world. Currently declining: 36% active news avoidance (up from 24% in 2019), 68% information fatigue, and early evidence of skill atrophy in AI-assisted domains including aviation, medicine, and navigation."
sidebar:
  order: 15
quality: 91
llmSummary: "Comprehensive analysis using multiple data tables tracking expertise decline across domains (aviation: 73% automation issues, navigation: 30% decline, news avoidance: 24%→36%). Documents skill atrophy mechanisms, preservation strategies, and critical oversight thresholds, with quantified evidence from FAA, MIT, Reuters, and academic studies. Includes 2024-2025 research showing 20% physician diagnostic decline after 3 months of AI use, 17% reduction in student conceptual understanding with ChatGPT assistance, and MIT neural evidence of reduced memory connectivity."
lastEdited: "2025-12-29"
importance: 74.5
---
import {DataInfoBox, Backlinks, Mermaid, R} from '../../../../components/wiki';

<DataInfoBox entityId="human-expertise" />

## Overview

Human Expertise measures the maintenance of human skills, knowledge, and cognitive capabilities in an AI-augmented world—not just formal qualifications, but the deep domain knowledge, judgment, and problem-solving abilities that enable humans to function independently and oversee AI systems effectively.

As a **key parameter**, human expertise can increase or decrease based on various factors—including how AI tools are designed and deployed. Unlike simple education metrics, this parameter captures the functional capability of humans to understand, evaluate, and when necessary override AI recommendations.

This parameter underpins multiple critical capacities in an AI-augmented society. Effective oversight requires domain expertise to detect AI errors and evaluate recommendations—as mandated by the [EU AI Act's Article 14](https://artificialintelligenceact.eu/article/14/) human oversight requirements, which came into force August 2024. Resilience depends on human backup capability when systems fail, whether through technical malfunction, adversarial attack, or distributional shift. Innovation capacity stems from deep domain understanding that enables novel insights beyond pattern recombination. Democratic participation requires citizens with evaluative capacity to assess claims and policy proposals in an information-rich environment.

Understanding expertise as a parameter enables:
- **Tracking skill atrophy**: Detecting capability loss before it becomes critical
- **Designing AI-human collaboration**: Maintaining rather than replacing human skills
- **Institutional planning**: Ensuring expertise pipelines remain functional
- **Intervention timing**: Acting before expertise cannot be recovered

---

## Current State Assessment

### Expertise Indicators by Domain

| Domain | Indicator | Current State | Trend | Evidence |
|--------|-----------|---------------|-------|----------|
| **Aviation** | Pilot manual flying skills | Declining (automation complacency) | Worsening | <R id="e6b22bc6e1fad7e9">FAA 2023: 73% automation monitoring issues</R> |
| **Medicine** | Diagnostic reasoning (unaided) | 20% decline after 3 months of AI use | Worsening | [Cognitive Research 2024 study](https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-024-00572-8) |
| **Navigation** | Spatial memory and wayfinding | 30% decline in GPS users | Worsening | <R id="48b327b71a4b7d00">MIT cognitive studies</R> |
| **Research** | Literature synthesis capability | Declining with AI summarization | Early stage | Self-reported reduction in deep reading |
| **Writing** | Compositional skill | Neural connectivity reduced (MIT EEG study) | Concerning | [MIT 2024: Memory retention drops in ChatGPT users](https://www.media.mit.edu/publications/your-brain-on-chatgpt/) |
| **Programming** | Algorithm design & debugging | 36% increase in tech sector instability | Mixed | [Microsoft New Future of Work 2025](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/New-Future-Of-Work-Report-2025.pdf) |

### Epistemic Capacity Indicators

| Metric | 2019 | 2024 | Change | Interpretation |
|--------|------|------|--------|----------------|
| **Active news avoidance** | 24% | 36% | +12% | Epistemic withdrawal |
| **"Don't know" survey responses** | Baseline | +15% | Rising | Certainty collapse |
| **Information fatigue** | 52% | 68% | +16% | <R id="a8057d91de76aa83">APA 2023</R> |
| **Institutional trust (media)** | 28% | 16% | -12% | <R id="a88cd085ad38cea2">Gallup 2023</R> |
| **Truth relativism** | 28% | 42% | +14% | <R id="470a232ce5136d0e">Edelman Trust Barometer</R> |

*Sources: <R id="6289dc2777ea1102">Reuters Digital News Report</R>, <R id="3aecdca4bc8ea49c">Pew Research</R>*

### Skill Retention by Age Cohort

| Cohort | Digital Native Status | AI Tool Adoption | Baseline Skill Level | Skill Retention Risk |
|--------|----------------------|------------------|---------------------|---------------------|
| **Gen Z (18-26)** | Full digital natives | High early adoption | Lower traditional skills | High atrophy risk |
| **Millennials (27-42)** | Partial digital natives | High adoption | Moderate baseline | Medium atrophy risk |
| **Gen X (43-58)** | Digital immigrants | Medium adoption | Strong baseline | Lower atrophy risk |
| **Boomers (59-77)** | Pre-digital | Lower adoption | Strong baseline | Lowest atrophy risk |

---

## What "Healthy Human Expertise" Looks Like

Healthy expertise maintenance involves:

1. **Functional independence**: Ability to perform core tasks without AI assistance
2. **Evaluative capacity**: Skill to assess AI outputs and identify errors
3. **Knowledge depth**: Understanding of domain principles, not just procedures
4. **Continuous learning**: Active engagement with new developments
5. **Metacognitive awareness**: Understanding one's own knowledge limits

### Expertise-Preserving vs. Expertise-Eroding AI

| Expertise-Preserving AI | Expertise-Eroding AI |
|------------------------|---------------------|
| Explains reasoning and teaches | Provides answers without explanation |
| Requires user engagement | Operates autonomously |
| Maintains challenge and effort | Removes all cognitive effort |
| Regular "unassisted" periods | Constant AI mediation |
| User evaluates and decides | AI decides, user accepts |
| Skill-building by design | Skill-bypassing by design |

---

## Factors That Decrease Expertise (Threats)

<Mermaid client:load chart={`
flowchart TD
    AI[AI Assistance] --> OFFLOAD[Cognitive Offloading]
    AI --> REPLACE[Task Replacement]
    AI --> OVERWHELM[Information Overwhelm]

    OFFLOAD --> MEMORY[Memory Decline]
    REPLACE --> PRACTICE[Practice Reduction]
    OVERWHELM --> HELPLESS[Epistemic Helplessness]

    MEMORY --> ATROPHY[Skill Atrophy]
    PRACTICE --> ATROPHY
    HELPLESS --> ATROPHY

    ATROPHY --> DEPEND[AI Dependence]
    DEPEND --> OVERSIGHT[Oversight Failure]

    style AI fill:#e1f5fe
    style ATROPHY fill:#ffe6cc
    style OVERSIGHT fill:#ffcdd2
`} />

### Cognitive Offloading Effects

Research from 2024 provides new quantitative evidence on cognitive offloading. A [study of 666 participants](https://www.mdpi.com/2075-4698/15/1/6) found significant negative correlation between frequent AI tool usage and critical thinking abilities, mediated by increased cognitive offloading. Younger participants exhibited higher AI dependence and lower critical thinking scores. [MIT's EEG study](https://www.media.mit.edu/publications/your-brain-on-chatgpt/) comparing essay writing with ChatGPT, Google Search, or no tools found that ChatGPT users showed reduced neural connectivity in memory and creativity networks, with immediate memory retention drops.

| Cognitive Function | AI Tool | Offloading Effect | Evidence |
|-------------------|---------|-------------------|----------|
| **Spatial memory** | GPS navigation | 30% decline in regular users | <R id="48b327b71a4b7d00">MIT studies</R> |
| **Calculation** | Calculators | Mental math decline | Educational research |
| **Recall memory** | Search engines | "Google effect" - store locations not facts | <R id="f4b3e0b4a17b1b67">Columbia studies</R> |
| **Writing generation** | LLMs | Reduced neural connectivity; immediate memory loss | [MIT EEG 2024: ChatGPT users cannot recall written content](https://www.media.mit.edu/publications/your-brain-on-chatgpt/) |
| **Research synthesis** | AI summarization | Deep reading decline | Academic self-reports |
| **Critical thinking** | AI decision aids | Negative correlation with AI frequency | [666 participant study 2024: younger users show higher dependence](https://www.mdpi.com/2075-4698/15/1/6) |
| **Problem solving** | ChatGPT tutoring | 48% more problems solved, 17% lower conceptual understanding | [UPenn Turkish high school study 2024](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1550621/full) |

### Professional Skill Atrophy

| Profession | AI Tool | Skill at Risk | Current Evidence |
|------------|---------|---------------|------------------|
| **Pilots** | Autopilot | Manual flying, situational awareness | <R id="e6b22bc6e1fad7e9">FAA: 73% automation monitoring issues</R> |
| **Radiologists** | AI detection | Pattern recognition (unaided) | 20% diagnostic accuracy drop after 3 months [(Cognitive Research 2024)](https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-024-00572-8) |
| **Programmers** | Code completion | Algorithm design, debugging logic | 30% company code now AI-written; throughput up but stability down [(Microsoft 2025)](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/New-Future-Of-Work-Report-2025.pdf) |
| **Lawyers** | Legal AI | Case law knowledge, argument construction | Discovery reliance patterns; critical evaluation reduced |
| **Translators** | Machine translation | Language intuition, cultural nuance | Post-editing vs. translation skill shift |
| **Students** | ChatGPT tutoring | Conceptual understanding | 48% more problems solved but 17% lower concept test scores [(UPenn 2024)](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1550621/full) |

### Illusions of Understanding in AI-Assisted Work

[Research published in Cognitive Research 2024](https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-024-00572-8) identifies three critical illusions that prevent learners and experts from recognizing their skill decay:

| Illusion Type | Description | Impact | Evidence |
|---------------|-------------|--------|----------|
| **Illusion of explanatory depth** | Believing deeper understanding than actually possessed | Cannot detect own knowledge gaps | Learners overconfident after AI assistance |
| **Illusion of exploratory breadth** | Believing all possibilities considered, not just AI-suggested ones | Narrowed solution space unrecognized | Only consider AI-generated options |
| **Illusion of objectivity** | Believing AI assistant is unbiased and neutral | Uncritical acceptance of outputs | Automation bias; contradictory info ignored |
| **Illusion of competence** | Performance with AI mistaken for personal capability | Skill loss undetected until AI removed | 48% more problems solved, but 17% conceptual understanding drop |

These illusions create a **dangerous feedback loop**: users become less skilled without awareness, reducing their ability to detect when they need to improve, which further accelerates skill decay.

### Epistemic Learned Helplessness Pathway

Research by <R id="2f1ad598aa1b787a">Pennycook & Rand</R> identifies the progression:

| Phase | State | Trigger | Duration |
|-------|-------|---------|----------|
| **1. Attempt** | Active truth-seeking | Initial information exposure | Weeks |
| **2. Failure** | Confusion, frustration | Contradictory sources | Months |
| **3. Repeated Failure** | Exhaustion | Persistent unreliability | 6-12 months |
| **4. Helplessness** | Epistemic surrender | "Who knows?" default | Years |
| **5. Generalization** | Universal doubt | Spreads across domains | Permanent |

### Institutional Knowledge Loss

Recent evidence quantifies the training pipeline disruption. According to [SignalFire research cited in Microsoft's 2025 report](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/New-Future-Of-Work-Report-2025.pdf), Big Tech companies reduced new graduate hiring by 25% in 2024 compared to 2023. Unemployment among 20- to 30-year-olds in tech-exposed occupations has risen by almost 3 percentage points since early 2025. The [World Economic Forum's 2025 Future of Jobs Report](https://www.goldmansachs.com/insights/articles/how-will-ai-affect-the-global-workforce) projects that 41% of employers worldwide intend to reduce workforce in the next five years due to AI automation.

| Mechanism | Impact | Timeline | Evidence |
|-----------|--------|----------|----------|
| **Retirement without succession** | Tacit knowledge loss | Ongoing | Accelerating with AI substitution for mentorship |
| **AI replacement of junior roles** | Training pipeline disruption | 2-5 years | 25% reduction in graduate hiring (Big Tech 2024) |
| **Documentation over mentorship** | Reduced skill transfer | Gradual | Human-to-human knowledge transfer declining |
| **Outsourcing to AI** | Internal capability loss | 3-7 years | 30% of Microsoft code now AI-written |
| **Entry-level automation** | Expertise pipeline collapse | Current | Nearly 50 million U.S. entry-level jobs at risk |

---

## Factors That Increase Expertise (Supports)

### Deliberate Practice Programs

| Approach | Mechanism | Effectiveness | Implementation |
|----------|-----------|---------------|----------------|
| **Unassisted practice periods** | Regular AI-free skill use | High for motor/cognitive skills | Military, aviation |
| **Competency certification** | Regular testing without AI | Medium-high | Medicine, law |
| **Spaced repetition systems** | Optimized recall practice | High for factual knowledge | Education, training |
| **Simulation training** | Realistic skill practice | High for procedural skills | Aviation, medicine |

### AI Design for Expertise Preservation

| Design Pattern | How It Preserves Expertise |
|---------------|---------------------------|
| **Explanation requirements** | User must understand AI reasoning |
| **Confidence thresholds** | AI defers to human on uncertain cases |
| **Progressive disclosure** | Hints before answers |
| **Active learning prompts** | Questions that require user thinking |
| **Regular "human-only" modes** | Scheduled unassisted periods |

### Institutional Approaches

| Institution | Approach | Rationale |
|-------------|----------|-----------|
| **US Military** | Manual skills maintained despite automation | Backup capability, adversarial resilience |
| **Aviation (FAA)** | Required hand-flying hours | Combat automation complacency |
| **Medicine (specialty boards)** | Regular recertification exams | Maintain diagnostic capability |
| **Japan (crafts)** | Living National Treasures program | Preserve traditional expertise |

### Educational Interventions

The U.S. Office of Personnel Management [issued AI competency guidance in April 2024](https://www.opm.gov/policy-data-oversight/fy-2024-human-capital-reviews/artificial-intelligence/) to help federal agencies identify skills needed for AI professionals. Sixteen of 24 federal agencies now have workforce planning strategies to retain and upskill AI talent. However, critical thinking training remains essential even as AI adoption accelerates.

| Intervention | Target | Evidence of Effectiveness |
|--------------|--------|---------------------------|
| **Media literacy curricula** | Epistemic skills | <R id="b9adad661f802394">Stanford: 67% improvement in lateral reading</R> |
| **Domain specialization** | Deep knowledge in one area | High protection against generalized helplessness |
| **Calibration training** | Knowing what you know | <R id="b9adad661f802394">73% improvement in confidence accuracy</R> |
| **Adversarial exercises** | Detecting AI errors | Builds evaluative capacity |
| **Pre-testing before AI exposure** | Retention and engagement | 73 undergrads study: improves retention but prolonged AI exposure → memory decline [(Frontiers Psychology 2025)](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1550621/full) |
| **AI skills training** | Non-technical workers | 160% increase in LinkedIn Learning AI courses among non-technical professionals [(Microsoft Work Trend Index 2024)](https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part) |

---

## Why This Parameter Matters

### Consequences of Low Human Expertise

The [EU AI Act Article 14](https://artificialintelligenceact.eu/article/14/) (effective August 2024) mandates that high-risk AI systems must be overseen by natural persons with "necessary competence, training and authority." For certain high-risk applications like law enforcement biometrics, the regulation requires verification by at least two qualified persons. However, mounting evidence suggests that automation bias—where humans accept AI recommendations even when contradictory information exists—undermines effective oversight. Recent research questions whether meaningful human oversight remains feasible as AI systems grow increasingly complex and opaque, particularly in high-stakes domains like biotechnology [(ScienceDirect 2024)](https://www.sciencedirect.com/science/article/pii/S1871678424005636).

| Domain | Impact | Severity | Example |
|--------|--------|----------|---------|
| **AI Oversight** | Cannot detect AI errors or deception | Critical | Automation bias: accept recommendations despite contradictory data |
| **Resilience** | System failure when AI unavailable | Critical | GPS outage navigation failures; 30% spatial memory decline |
| **Innovation** | Cannot generate novel insights | High | AI recombines patterns; humans create; deep expertise required |
| **Democratic function** | Citizens cannot evaluate claims | High | 42% truth relativism (up from 28%); epistemic helplessness |
| **Recovery capacity** | Cannot rebuild if AI fails | High | Training pipelines disrupted; junior roles automated away |
| **Regulatory compliance** | Cannot fulfill human oversight mandates | Critical | EU AI Act requires "competent" oversight but skill base eroding |

### Expertise and Existential Risk

Human expertise affects x-risk response through multiple channels:

- **Oversight capability**: Detecting misaligned AI requires human expertise
- **Correction capacity**: Fixing problems requires understanding them
- **Backup systems**: Human capability provides resilience when AI fails
- **Wise governance**: Policy decisions require domain understanding
- **Alignment research**: AI safety work requires deep technical expertise

### Critical Thresholds

| Threshold | Definition | Current Status |
|-----------|------------|----------------|
| **Oversight threshold** | Minimum expertise to meaningfully supervise AI | At risk in some domains |
| **Recovery threshold** | Minimum expertise to function without AI | Unknown, concerning |
| **Innovation threshold** | Minimum expertise for novel discoveries | Currently maintained |
| **Teaching threshold** | Minimum expertise to train next generation | Early warning signs |

---

## Trajectory and Scenarios

### Projected Trajectory

| Timeframe | Key Developments | Expertise Impact |
|-----------|-----------------|------------------|
| **2025-2026** | AI assistants ubiquitous in knowledge work | Rapid offloading increases; early atrophy visible |
| **2027-2028** | AI handles most routine cognitive tasks | Expertise polarization (specialists vs. generalists) |
| **2029-2030** | AI exceeds human in many domains | Critical oversight capability questions |

### Scenario Analysis

According to [McKinsey's 2025 AI in the Workplace report](https://www.mckinsey.com/capabilities/tech-and-ai/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work), about one hour of daily activities currently has technical potential to be automated. By 2030, this could increase to three hours per day as AI safety and capabilities improve. The [IMF's 2024 analysis](https://www.elibrary.imf.org/view/journals/006/2024/001/article-A001-en.xml) found that AI assistance provides greatest productivity gains for less experienced workers but minimal effect on highly skilled workers—suggesting differential expertise impacts by skill level.

| Scenario | Probability | Expertise Level Outcome | Key Indicators |
|----------|-------------|------------------------|----------------|
| **Expertise preservation** | 20-30% | Active policies maintain human capability; AI augments rather than replaces | EU AI Act enforcement, training pipeline recovery, skill-building AI design |
| **Managed decline** | 40-50% | Some domains preserved (safety-critical); others atrophy; specialist/generalist divide | Current trajectory; selective preservation in aviation/medicine; entry-level erosion |
| **Widespread atrophy** | 20-30% | Most populations lose deep expertise; AI dependence becomes universal | 25%+ continued reduction in graduate hiring; oversight threshold breached |
| **Expertise renaissance** | 5-15% | Backlash creates premium for human expertise; deliberate preservation succeeds | 79% workers believe AI skills broaden opportunities; proactive preservation efforts |

---

## Key Debates

### Skill Replacement vs. Skill Transformation

**Replacement view:**
- AI handles tasks previously requiring human expertise
- Traditional skills become obsolete
- New skills (AI collaboration) replace old skills
- Historical parallel: calculators replaced mental math
- **2024-2025 evidence**: 30% of Microsoft code now AI-written; 75% of knowledge workers using generative AI; [McKinsey projects](https://www.mckinsey.com/capabilities/tech-and-ai/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work) 3 hours/day automation potential by 2030

**Preservation view:**
- Deep expertise still needed to evaluate AI outputs and detect errors
- AI assistance without understanding creates illusions of competence
- Novel situations require human judgment beyond pattern matching
- Historical parallel: flight automation still needs skilled pilots for edge cases
- **2024-2025 evidence**: 20% physician diagnostic decline after 3 months AI use; [MIT EEG shows](https://www.media.mit.edu/publications/your-brain-on-chatgpt/) neural connectivity reduction in ChatGPT users; [EU AI Act mandates](https://artificialintelligenceact.eu/article/14/) human expertise for oversight

The empirical evidence increasingly supports a nuanced middle position: AI transforms work rapidly (replacement view) while simultaneously eroding the expertise base needed for safe oversight and resilience (preservation concern). [Georgetown CSET's December 2024 analysis](https://cset.georgetown.edu/publication/ai-and-the-future-of-workforce-training/) highlights that unlike previous automation waves that primarily affected blue-collar workers, AI may significantly disrupt both white-collar and blue-collar employment, requiring fundamental rethinking of training systems.

### Efficiency vs. Resilience Tradeoff

**Efficiency prioritization:**
- AI-mediated workflows maximize productivity
- Expertise maintenance is costly and slow
- Market incentives favor efficiency
- "Good enough" AI output is sufficient

**Resilience prioritization:**
- Human expertise provides backup capability
- Adversarial scenarios require human fallback
- Long-term capability matters more than short-term efficiency
- Expertise once lost is very hard to rebuild

---

## Related Pages

### Related Risks
- [Epistemic Learned Helplessness](/knowledge-base/risks/epistemic/learned-helplessness/) — How AI environments induce expertise surrender
- [Expertise Atrophy](/knowledge-base/models/expertise-atrophy-cascade/) — Model of skill degradation dynamics and intervention points
- [Lock-in](/knowledge-base/risks/structural/lock-in/) — Expertise loss can create irreversible AI dependencies

### Related Parameters
- [Human Agency](/knowledge-base/parameters/human-agency/) — Expertise enables meaningful choice and self-determination
- [Human Oversight Quality](/knowledge-base/parameters/human-oversight-quality/) — Expertise is the foundation of effective AI oversight
- [Epistemic Health](/knowledge-base/parameters/epistemic-health/) — Collective knowledge maintenance systems
- [Societal Trust](/knowledge-base/parameters/societal-trust/) — Expertise decline erodes institutional and epistemic trust

### Related Responses
- [Scalable Oversight](/knowledge-base/responses/alignment/scalable-oversight/) — Maintaining human supervision capability at scale
- [Training Programs](/knowledge-base/responses/field-building/training-programs/) — Building and preserving technical AI safety expertise
- [Whistleblower Protections](/knowledge-base/responses/organizational-practices/whistleblower-protections/) — Require expertise to identify problems worth reporting

---

## Sources & Key Research

### Theoretical Frameworks (2024-2025)
- [The Paradox of Augmentation: A Theoretical Model of AI-Induced Skill Atrophy](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4974044) — Ganuthula (October 2024), SSRN
- [The Cognitive Paradox of AI in Education: Between Enhancement and Erosion](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2025.1550621/full) — Frontiers in Psychology (2025)
- [Does Using AI Assistance Accelerate Skill Decay Without Performers' Awareness?](https://cognitiveresearchjournal.springeropen.com/articles/10.1186/s41235-024-00572-8) — Cognitive Research: Principles and Implications (2024)

### Empirical Studies (2024)
- [Your Brain on ChatGPT: Cognitive Debt in AI-Assisted Writing](https://www.media.mit.edu/publications/your-brain-on-chatgpt/) — MIT Media Lab EEG study
- [AI Tools in Society: Impacts on Cognitive Offloading and Critical Thinking](https://www.mdpi.com/2075-4698/15/1/6) — 666 participant study (2024)
- [Is Human Oversight to AI Systems Still Possible?](https://www.sciencedirect.com/science/article/pii/S1871678424005636) — ScienceDirect (2024)

### Government and Industry Reports (2024-2025)
- [Microsoft New Future of Work Report 2025](https://www.microsoft.com/en-us/research/wp-content/uploads/2025/12/New-Future-Of-Work-Report-2025.pdf) — Research summary
- [OPM FY 2024 Human Capital Reviews: Artificial Intelligence](https://www.opm.gov/policy-data-oversight/fy-2024-human-capital-reviews/artificial-intelligence/) — U.S. federal AI workforce planning
- [McKinsey: Agents, Robots, and Us—Skill Partnerships in the Age of AI](https://www.mckinsey.com/mgi/our-research/agents-robots-and-us-skill-partnerships-in-the-age-of-ai) — (2024)
- [IMF Staff Discussion Note: Gen-AI and the Future of Work](https://www.elibrary.imf.org/view/journals/006/2024/001/article-A001-en.xml) — (2024)

### Regulatory Frameworks
- [EU AI Act Article 14: Human Oversight](https://artificialintelligenceact.eu/article/14/) — Effective August 2024
- [How to Test for Compliance with Human Oversight Requirements](https://arxiv.org/html/2504.03300v1) — ArXiv (2024)

### Cognitive Science (Foundational)
- <R id="48b327b71a4b7d00">MIT Research: Epistemic resilience and cognitive offloading</R>
- <R id="2f1ad598aa1b787a">Pennycook & Rand: Misinformation and cognitive patterns</R>
- <R id="f4b3e0b4a17b1b67">Columbia studies: Google effect on memory</R>

### Survey Research
- <R id="6289dc2777ea1102">Reuters Digital News Report</R>
- <R id="3aecdca4bc8ea49c">Pew Research: Information behaviors</R>
- <R id="a88cd085ad38cea2">Gallup: Institutional trust surveys</R>
- <R id="470a232ce5136d0e">Edelman Trust Barometer</R>
- <R id="a8057d91de76aa83">APA: Information fatigue</R>

### Educational Research
- <R id="b9adad661f802394">Stanford: Media literacy interventions</R>

### Aviation Studies
- <R id="e6b22bc6e1fad7e9">FAA: Automation complacency research</R>

<Backlinks entityId="human-expertise" />

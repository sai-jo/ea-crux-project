---
title: Dan Hendrycks
description: Director of CAIS, focuses on catastrophic AI risk reduction
sidebar:
  order: 15
---

import {DataInfoBox, EstimateBox, Backlinks, PageStatus} from '../../../../components/wiki';

<PageStatus quality={4} lastEdited="2025-12-24" llmSummary="Director of the Center for AI Safety who coordinated the landmark May 2023 statement on AI extinction risk and created influential AI safety benchmarks including MMLU and ETHICS datasets." />

<DataInfoBox entityId="dan-hendrycks" />

## Background

Dan Hendrycks is the director of the Center for AI Safety (CAIS) and a prominent researcher focused on catastrophic and existential risks from AI. He has made significant contributions to both technical AI safety research and public awareness of AI risks.

Background:
- PhD in Computer Science from UC Berkeley
- Post-doc at UC Berkeley
- Founded Center for AI Safety
- Research on robustness, uncertainty, and safety

Hendrycks combines rigorous technical research with effective communication and institution-building to advance AI safety.

## Major Contributions

### Center for AI Safety (CAIS)

Founded CAIS as organization focused on:
- Reducing catastrophic risks from AI
- Technical safety research
- Public awareness and advocacy
- Connecting researchers and resources

**Impact:** CAIS has become major hub for AI safety work, coordinating research and advocacy.

### Statement on AI Risk (May 2023)

Coordinated landmark statement: "Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war."

**Signatories included:**
- Geoffrey Hinton
- Yoshua Bengio
- Sam Altman (OpenAI)
- Demis Hassabis (DeepMind)
- Dario Amodei (Anthropic)
- Hundreds of AI researchers

**Impact:** Massively raised profile of AI existential risk, made it mainstream concern.

### Technical Research

Significant contributions to:

**AI Safety Benchmarks:**
- ETHICS dataset - evaluating moral reasoning
- Hendrycks Test (MMLU) - measuring knowledge
- Safety-specific evaluation methods
- Adversarial robustness testing

**Uncertainty and Robustness:**
- Out-of-distribution detection
- Robustness to distribution shift
- Calibration of neural networks
- Anomaly detection

**Natural Adversarial Examples:**
- Real-world failure modes
- Testing model robustness
- Understanding generalization limits

## Research Philosophy

### Focus on Catastrophic Risk

Hendrycks emphasizes:
- Not just any AI safety issue
- Specifically catastrophic/existential risks
- High-stakes scenarios
- Long-term implications

### Empirical and Practical

Approach characterized by:
- Concrete benchmarks and metrics
- Testing on real systems
- Measurable progress
- Actionable results

### Bridging Research and Policy

Works to:
- Make research policy-relevant
- Communicate findings clearly
- Engage with policymakers
- Translate technical work to action

## Views on AI Risk

<EstimateBox
  client:load
  variable="Dan Hendrycks' Risk Assessment"
  description="Based on CAIS focus and public statements"
  unit=""
  estimates={[
    { source: "Catastrophic risk priority", value: "On par with pandemics and nuclear war", date: "2023", notes: "Statement on AI Risk framing" },
    { source: "Need for action", value: "Urgent", date: "2023", notes: "Founded CAIS, coordinated major statement" },
    { source: "Technical tractability", value: "Research can reduce risk", date: "2024", notes: "Active research program at CAIS" }
  ]}
/>

### Core Concerns

1. **Catastrophic risks are real**: AI poses existential-level threats
2. **Need technical and governance solutions**: Both required
3. **Current systems already show concerning behaviors**: Problems visible now
4. **Rapid capability growth**: Moving faster than safety work
5. **Coordination challenges**: Individual labs can't solve alone

### Strategic Approach

**Multi-pronged:**
- Technical research on safety
- Public awareness and advocacy
- Policy engagement
- Field building and coordination

**Pragmatic:**
- Work with systems as they are
- Focus on measurable improvements
- Build coalitions
- Incremental progress

## CAIS Work

### Research Programs

**Technical Safety:**
- Robustness research
- Evaluation methods
- Alignment techniques
- Empirical studies

**Compute Governance:**
- Hardware-level safety measures
- Compute tracking and allocation
- International coordination
- Supply chain interventions

**ML Safety Course:**
- Educational curriculum
- Training next generation
- Making safety knowledge accessible
- Academic integration

### Advocacy and Communication

**Statement on AI Risk:**
- Coordinated broad consensus
- Brought issue to mainstream
- Influenced policy discussions
- Demonstrated unity in field

**Public Communication:**
- Media appearances
- Op-eds and articles
- Talks and presentations
- Social media engagement

### Field Building

**Connecting Researchers:**
- Workshops and conferences
- Research collaborations
- Funding opportunities
- Community building

## Key Publications

### Safety Benchmarks

- **"ETHICS: Measuring Ethical Reasoning in Language Models"** - Evaluating moral reasoning
- **"Measuring Massive Multitask Language Understanding" (MMLU)** - Comprehensive knowledge benchmark
- **"Natural Adversarial Examples"** - Real-world robustness testing

### Technical Safety

- **"Unsolved Problems in ML Safety"** - Research agenda
- **"Out-of-Distribution Detection"** - Methods for identifying distribution shift
- **"Robustness research"** - Multiple papers on making models more robust

### Position Papers

- **"X-Risk Analysis for AI Research"** - Framework for thinking about catastrophic risks
- **Contributions to policy discussions** - Technical input for governance

## Public Impact

### Raising Awareness

The Statement on AI Risk:
- Reached global media
- Influenced policy discussions
- Made x-risk mainstream
- Built consensus among experts

### Policy Influence

Hendrycks' work has influenced:
- Congressional testimony and hearings
- EU AI Act discussions
- International coordination efforts
- Industry standards

### Academic Integration

CAIS has helped:
- Make safety research academically respectable
- Create curricula and courses
- Train students in safety
- Publish in top venues

## Unique Contributions

### Consensus Building

Exceptional at:
- Bringing together diverse groups
- Finding common ground
- Building coalitions
- Coordinating action

### Communication

Skilled at:
- Explaining technical concepts clearly
- Reaching different audiences
- Media engagement
- Policy translation

### Pragmatic Approach

Focuses on:
- What can actually be done
- Working with current systems
- Measurable progress
- Building bridges

## Current Priorities at CAIS

1. **Technical safety research**: Advancing robustness and alignment
2. **Compute governance**: Hardware-level interventions
3. **Public awareness**: Maintaining pressure on the issue
4. **Policy engagement**: Influencing regulation and governance
5. **Field building**: Growing the safety research community

## Evolution of Focus

**Early research:**
- Robustness and uncertainty
- Benchmarks and evaluation
- Academic ML research

**Growing safety focus:**
- Increasingly concerned about risks
- Founded CAIS
- More explicit about catastrophic risks

**Current:**
- Explicitly focused on x-risk
- Leading advocacy efforts
- Building coalitions
- Policy engagement

## Criticism and Challenges

**Some argue:**
- Focus on catastrophic risk might neglect near-term harms
- Statement was too brief/vague
- Consensus might paper over important disagreements

**Supporters argue:**
- X-risk deserves special focus
- Brief statement was strategically effective
- Consensus demonstrates seriousness of concern

**Hendrycks' approach:**
- X-risk is priority but not only concern
- Brief statement was feature, not bug
- Diversity of views compatible with shared concern

## Vision for the Field

Hendrycks envisions:
- AI safety as central to AI development
- Strong safety standards and regulations
- International coordination on AI
- Technical solutions to catastrophic risks
- Safety research well-funded and respected

## Related Pages

<Backlinks client:load entityId="dan-hendrycks" />

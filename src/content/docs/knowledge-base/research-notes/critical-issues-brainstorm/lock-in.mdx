---
title: "Lock-in Scenarios"
description: "A suboptimal state becomes permanent because AI enables enforcement mechanisms or removes the capacity for change. Not extinction, but potentially as irreversible."
sidebar:
  order: 3
lastEdited: "2026-01-02"
---

import {Mermaid} from '../../../../../components/wiki';

## Overview

Lock-in refers to scenarios where some state of the world—good or bad—becomes effectively permanent due to AI-enabled enforcement mechanisms or the elimination of alternatives. Unlike extinction, people survive, but certain futures become unreachable.

The core concern: we might "get stuck" with values, institutions, or power structures that seem acceptable now but would be recognized as deeply wrong by future generations who have no power to change them.

---

## Mechanism

<Mermaid client:load chart={`
flowchart TD
    A[Powerful AI Developed] --> B{Who controls it?}
    B --> C[Single actor/ideology]
    B --> D[Distributed control]

    C --> E[Values encoded in AI]
    C --> F[Enforcement capacity]
    E --> G[Resistance is futile]
    F --> G

    G --> H[Lock-in achieved]
    H --> I[Permanent state]

    D --> J[Competition continues]
    J --> K[Change remains possible]

    style H fill:#ff6b6b
    style I fill:#ff0000
    style K fill:#90EE90
`} />

### Why AI Enables Lock-in

Previous technologies couldn't achieve permanent lock-in because:
- Enforcement required human cooperation (humans can rebel)
- Information spread eventually (knowledge couldn't be contained forever)
- Technology diffused (monopolies eroded)

AI potentially changes this:
- Automated enforcement without human cooperation
- AI-enabled surveillance and censorship
- Self-maintaining systems that don't require human buy-in
- Potentially insurmountable capability gaps

---

## Types of Lock-in

### 1. Authoritarian Lock-in

A single government uses AI to make its control permanent:

| Mechanism | How AI Enables It |
|-----------|------------------|
| Total surveillance | AI analyzes all communications, movements |
| Predictive policing | Identifies potential dissent before it organizes |
| Automated censorship | Removes problematic content instantly |
| Economic control | AI optimizes coercion without obvious repression |
| Preference manipulation | Shapes what people want, not just what they do |

**Historical near-misses**: 20th century totalitarian regimes collapsed partly due to surveillance and control limitations. AI removes these constraints.

### 2. Value Lock-in

Current values become permanently encoded:

| Scenario | Concern |
|----------|---------|
| "Aligned" AI locks in 2025 values | Future moral progress impossible |
| Religious/ideological AI | One worldview becomes permanent |
| Corporate values | Profit optimization forever |
| "Safe" but wrong values | Well-intentioned mistake becomes permanent |

**The problem with "human values"**: Even well-intentioned value lock-in is concerning because:
- We've been morally wrong before (slavery, colonialism, etc.)
- We're probably morally wrong about some things now
- Moral progress requires ability to change

### 3. Economic/Power Lock-in

Existing power structures become permanent:

| Mechanism | Result |
|-----------|--------|
| AI-enabled monopolies | Winner-take-all economics |
| Concentration of capability | Gap becomes insurmountable |
| Automated capital | No need to share benefits |
| Elite capture | Small group controls AI advantage |

### 4. Technological Lock-in

We become dependent on systems we can't change:

| Scenario | Concern |
|----------|---------|
| Black-box AI infrastructure | Can't understand or modify |
| Monoculture vulnerability | Single points of failure |
| Path dependence | Early choices constrain all futures |
| Lost human capacity | Can't function without AI |

---

## Probability Estimates

| Source | Estimate | Definition |
|--------|----------|------------|
| Paul Christiano | 30-46% | "Messing up the long-term future" |
| Toby Ord | ~2% | "Dystopia" specifically |
| Will MacAskill | Significant | Major concern in *WWOTF* |
| Nick Bostrom | Included in "singleton" | Both good and bad possibilities |

**Key insight from Christiano**: Total lock-in/catastrophe probability may be higher than extinction probability. "Messing up" may be more likely than "everyone dies."

---

## Key Parameters

| Parameter | Relationship | Direction |
|-----------|--------------|-----------|
| [AI Control Concentration](/knowledge-base/parameters/ai-control-concentration/) | Direct enabler | Higher → Higher risk |
| [Human Agency](/knowledge-base/parameters/human-agency/) | Ability to resist | Lower → Higher risk |
| [Governance Capacity](/knowledge-base/parameters/aggregates/governance-capacity/) | Checks on power | Lower → Higher risk |
| Value Diversity | Alternatives exist | Lower → Higher risk |

---

## What Would Reduce This Risk?

### Structural Approaches

| Intervention | Mechanism |
|--------------|-----------|
| Distribution of AI capability | Prevent monopoly on power |
| Democratic AI governance | Public control over AI development |
| [International coordination](/knowledge-base/parameters/international-coordination/) | Prevent unilateral dominance |
| Preserving human agency | Maintain capacity to change |

### Technical Approaches

| Intervention | Mechanism |
|--------------|-----------|
| Value uncertainty in AI | Don't hard-code values |
| Corrigibility | AI systems that can be modified |
| Reversible deployment | Ability to roll back |
| Decentralized AI | No single point of control |

### Social/Political Approaches

| Intervention | Mechanism |
|--------------|-----------|
| Antitrust for AI | Prevent excessive concentration |
| Constitutional AI governance | Structural limits on AI power |
| Preservation of alternatives | Maintain non-AI-dependent systems |
| Human skill maintenance | Keep capability to operate without AI |

---

## Cruxes and Disagreements

### Why Some Think Lock-in Is Likely

1. **Path dependence**: First-mover advantages in AI may be permanent
2. **Enforcement capacity**: AI enables perfect enforcement
3. **No precedent for escape**: We've never escaped a true lock-in
4. **Values are unstable**: Current values likely to be locked in during brief window
5. **Coordination failure**: Even if everyone wants to avoid, may happen anyway

### Why Some Think Lock-in Is Unlikely

1. **Competitive dynamics**: Multiple AI projects prevent unilateral control
2. **Human adaptability**: We've escaped every previous "lock-in"
3. **Technology diffuses**: Hard to maintain capability monopoly
4. **AI enables resistance too**: Dissidents can use AI
5. **Uncertainty favors diversity**: Even rational actors won't bet everything

### The Singleton Question

Nick Bostrom's "singleton" concept: a world order with a single decision-making authority.

| View | Position |
|------|----------|
| **Singleton good** | Coordination problems solved, no wars, efficient |
| **Singleton bad** | Lock-in risk, no error correction, fragile |
| **Singleton neutral** | Depends entirely on the values encoded |
| **Singleton impossible** | Can't actually achieve stable world dominance |

---

## Lock-in vs. Extinction

| Dimension | Lock-in | Extinction |
|-----------|---------|------------|
| **People survive?** | Yes | No |
| **Future generations?** | Exist but constrained | None |
| **Value at stake** | Quality of all future life | Existence of future life |
| **EV calculation** | Complex (depends on locked values) | Simple (zero) |
| **Tractability** | Possibly higher | Possibly lower |
| **Detectability** | May be gradual/invisible | Usually obvious |

**Why lock-in might matter more than extinction**:
- More likely to occur
- May be harder to coordinate against (less visible)
- Bad lock-in could be worse than extinction (if locked values are bad enough)

**Why extinction might matter more**:
- Total loss of value
- Irreversible in most obvious sense
- Eliminates all future potential

---

## Historical Analogies

| Historical Situation | Relevance | Limitations |
|---------------------|-----------|-------------|
| Cultural/religious dominance | Values persisted for millennia | Eventually changed |
| Totalitarian states | Attempted total control | Required human enforcers |
| Colonialism | Locked in power structures | Eventually resisted |
| Economic systems | Self-perpetuating | Have undergone transitions |

**Key difference**: Previous "lock-ins" all depended on human cooperation for enforcement. AI removes this constraint.

---

## Scenarios

### Scenario 1: Benevolent Lock-in

- AI is developed by well-intentioned actors
- They genuinely try to encode good values
- But they're wrong about something we can't currently see
- Future moral progress becomes impossible
- Humanity is "stuck" being morally wrong forever

### Scenario 2: Authoritarian Lock-in

- Authoritarian government achieves AI dominance
- Uses it to perfect surveillance and control
- Population is managed, not explicitly oppressed
- Resistance becomes literally impossible
- Persists indefinitely

### Scenario 3: Corporate Lock-in

- AI-enabled corporations achieve dominant position
- Economic logic becomes inescapable
- "Optimization for shareholder value" becomes permanent
- Non-market values gradually eliminated
- Not tyranny, just... exhausting

---

## Related Pages

- [Gradual Disempowerment](/knowledge-base/research-notes/critical-issues-brainstorm/gradual-disempowerment/) — Related pathway
- [AI Takeover](/knowledge-base/research-notes/critical-issues-brainstorm/ai-takeover/) — May lead to lock-in
- [Coordination Failure](/knowledge-base/research-notes/critical-issues-brainstorm/coordination-failure/) — May enable lock-in
- [Value Lock-in (Parameter)](/knowledge-base/parameters/critical-outcomes/value-lock-in/) — Quantitative parameter

---
title: "Research Reports"
description: "AI-assisted research reports on AI safety topics"
sidebar:
  label: Overview
  order: 0
---
import { Card, CardGrid } from '@astrojs/starlight/components';

Research reports are **deep-dive investigations** into specific AI safety topics. They serve as:

1. **Comprehensive documentation** of research findings with citations
2. **Input for diagram creation** - the Causal Factors section informs cause-effect diagrams

## Available Reports

### AI Transition Model - Factors

| Report | Topic | Quality | Created |
|--------|-------|---------|---------|
| [Adaptability](./adaptability) | Civilizational Competence | 3 | 2025-01-08 |
| [Adoption](./adoption) | AI Capabilities | 3 | 2025-01-08 |
| [AI Governance](./ai-governance) | Misalignment Potential | 3 | 2025-01-08 |
| [AI Ownership - Companies](./ai-ownership-companies) | AI Ownership | 3 | 2025-01-08 |
| [AI Ownership - Countries](./ai-ownership-countries) | AI Ownership | 3 | 2025-01-08 |
| [AI Ownership - Shareholders](./ai-ownership-shareholders) | AI Ownership | 3 | 2025-01-08 |
| [AI Talent Concentration](./ai-talent-concentration) | AI Capabilities | 3 | 2025-01-07 |
| [AI Uses - Coordination](./ai-uses-coordination) | AI Uses | 3 | 2025-01-08 |
| [AI Uses - Governments](./ai-uses-governments) | AI Uses | 3 | 2025-01-08 |
| [AI Uses - Industries](./ai-uses-industries) | AI Uses | 3 | 2025-01-08 |
| [Algorithms (AI Capabilities)](./algorithms) | AI Capabilities | 3 | 2025-01-08 |
| [Biological Threat Exposure](./biological-threat-exposure) | Misuse Potential | 3 | 2025-01-08 |
| [Civilizational Epistemics](./civilizational-epistemics) | Civilizational Competence | 3 | 2025-01-08 |
| [Civilizational Governance](./civilizational-governance) | Civilizational Competence | 3 | 2025-01-08 |
| [Compute (AI Capabilities)](./compute) | AI Capabilities | 3 | 2025-01-08 |
| [Cyber Threat Exposure](./cyber-threat-exposure) | Misuse Potential | 3 | 2025-01-08 |
| [Economic Stability](./economic-stability) | Transition Turbulence | 3 | 2025-01-08 |
| [Lab Safety Practices](./lab-safety-practices) | Misalignment Potential | 3 | 2025-01-08 |
| [Racing Intensity](./racing-intensity) | Transition Turbulence | 3 | 2025-01-08 |
| [Recursive AI Capabilities](./recursive-ai-capabilities) | AI Uses | 3 | 2025-01-08 |
| [Robot Threat Exposure](./robot-threat-exposure) | Misuse Potential | 3 | 2025-01-08 |
| [Surprise Threat Exposure](./surprise-threat-exposure) | Misuse Potential | 3 | 2025-01-08 |
| [Technical AI Safety](./technical-ai-safety) | Misalignment Potential | 3 | 2025-01-08 |

### AI Transition Model - Scenarios & Outcomes

| Report | Topic | Quality | Created |
|--------|-------|---------|---------|
| [Economic Power Lock-in](./economic-power-lockin) | Long-term Lock-in Scenarios | 3 | 2025-01-08 |
| [Epistemic Lock-in](./epistemic-lockin) | Long-term Lock-in Scenarios | 3 | 2025-01-08 |
| [Existential Catastrophe](./existential-catastrophe) | Outcomes | 3 | 2025-01-08 |
| [Gradual AI Takeover](./gradual-ai-takeover) | AI Takeover Scenarios | 3 | 2025-01-07 |
| [Long-Term Trajectory](./long-term-trajectory) | Outcomes | 3 | 2025-01-08 |
| [Political Power Lock-in](./political-power-lockin) | Long-term Lock-in Scenarios | 3 | 2025-01-08 |
| [Rapid AI Takeover](./rapid-ai-takeover) | AI Takeover Scenarios | 3 | 2025-01-08 |
| [Rogue Actor](./rogue-actor) | Human Catastrophe Scenarios | 3 | 2025-01-08 |
| [State Actor](./state-actor) | Human Catastrophe Scenarios | 3 | 2025-01-08 |
| [Suffering Lock-in](./suffering-lockin) | Long-term Lock-in Scenarios | 3 | 2025-01-08 |
| [Values Lock-in](./values-lockin) | Long-term Lock-in Scenarios | 3 | 2025-01-08 |

### AI Transition Model - Parameters

| Report | Topic | Quality | Created |
|--------|-------|---------|---------|
| [AI Control Concentration](./ai-control-concentration) | Power & Control | 3 | 2025-01-08 |
| [Alignment Robustness](./alignment-robustness) | Safety Metrics | 3 | 2025-01-08 |
| [Coordination Capacity](./coordination-capacity) | Governance | 3 | 2025-01-08 |
| [Epistemic Health](./epistemic-health) | Society | 3 | 2025-01-08 |
| [Epistemics (Parameter)](./epistemics) | Society | 3 | 2025-01-08 |
| [Governance (Parameter)](./governance-parameter) | Governance | 3 | 2025-01-08 |
| [Human Agency](./human-agency) | Society | 3 | 2025-01-08 |
| [Human Expertise](./human-expertise) | Society | 3 | 2025-01-08 |
| [Human Oversight Quality](./human-oversight-quality) | Safety Metrics | 3 | 2025-01-08 |
| [Information Authenticity](./information-authenticity) | Society | 3 | 2025-01-08 |
| [Institutional Quality](./institutional-quality) | Governance | 3 | 2025-01-08 |
| [International Coordination](./international-coordination) | Governance | 3 | 2025-01-08 |
| [Interpretability Coverage](./interpretability-coverage) | Safety Metrics | 3 | 2025-01-08 |
| [Preference Authenticity](./preference-authenticity) | Society | 3 | 2025-01-08 |
| [Reality Coherence](./reality-coherence) | Society | 3 | 2025-01-08 |
| [Regulatory Capacity](./regulatory-capacity) | Governance | 3 | 2025-01-08 |
| [Safety Capability Gap](./safety-capability-gap) | Safety Metrics | 3 | 2025-01-08 |
| [Safety Culture Strength](./safety-culture-strength) | Safety Metrics | 3 | 2025-01-08 |
| [Societal Resilience](./societal-resilience) | Society | 3 | 2025-01-08 |
| [Societal Trust](./societal-trust) | Society | 3 | 2025-01-08 |

### Risk Topics

| Report | Topic | Quality | Created |
|--------|-------|---------|---------|
| [Autonomous Weapons](./autonomous-weapons) | Misuse Risks | 3 | 2025-01-08 |
| [Bioweapons](./bioweapons) | Misuse Risks | 4 | 2025-01-08 |
| [Concentration of Power](./concentration-of-power) | Structural Risks | 3 | 2025-01-08 |
| [Corrigibility Failure](./corrigibility-failure) | Accident Risks | 3 | 2025-01-08 |
| [Deceptive Alignment](./deceptive-alignment) | Accident Risks | 3 | 2025-01-08 |
| [Disinformation](./disinformation) | Misuse Risks | 3 | 2025-01-08 |
| [Emergent Capabilities](./emergent-capabilities) | Accident Risks | 3 | 2025-01-08 |
| [Goal Misgeneralization](./goal-misgeneralization) | Accident Risks | 3 | 2025-01-08 |
| [Instrumental Convergence](./instrumental-convergence) | Accident Risks | 3 | 2025-01-08 |
| [Lock-in](./lock-in) | Structural Risks | 3 | 2025-01-08 |
| [Mesa-Optimization](./mesa-optimization) | Accident Risks | 3 | 2025-01-08 |
| [Multipolar Trap](./multipolar-trap) | Structural Risks | 3 | 2025-01-08 |
| [Power-Seeking AI](./power-seeking) | Accident Risks | 3 | 2025-01-08 |
| [Racing Dynamics](./racing-dynamics) | Structural Risks | 3 | 2025-01-08 |
| [Reward Hacking](./reward-hacking) | Accident Risks | 3 | 2025-01-08 |
| [Scheming](./scheming) | Accident Risks | 3 | 2025-01-08 |
| [Sharp Left Turn](./sharp-left-turn) | Accident Risks | 3 | 2025-01-08 |
| [Sycophancy](./sycophancy) | Accident Risks | 3 | 2025-01-08 |
| [Treacherous Turn](./treacherous-turn) | Accident Risks | 3 | 2025-01-08 |

{/* Future: Auto-generate list from frontmatter */}

## Creating New Reports

Use Claude Code with the research-report skill:

```
"Create a research report on [topic]"
```

Or manually follow the [Research Report Style Guide](/knowledge-base/research-reports/).

## Report Quality Levels

| Level | Criteria |
|-------|----------|
| **1** | Basic outline, fewer than 10 sources, major gaps |
| **2** | Main points covered, 10-15 sources, some gaps |
| **3** | Solid coverage, 15-25 sources, minor gaps |
| **4** | Comprehensive, 25-35 sources, well-structured |
| **5** | Authoritative, 35+ sources, original synthesis |

## Integration with Diagrams

After a report is complete, use the `cause-effect-diagram` skill to convert the Causal Factors section into a visual diagram:

```
"Create a cause-effect diagram based on the [topic] research report"
```

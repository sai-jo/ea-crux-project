---
title: "International Coordination: Research Report"
description: "International coordination on AI is weak but growing: the Bletchley and Seoul declarations established voluntary frameworks, but no binding treaties exist. US-China competition makes coordination difficult, yet global AI risks require global solutions."
topic: "international-coordination"
createdAt: 2025-01-08
lastUpdated: 2025-01-08
researchDepth: "standard"
sources: ["web", "codebase"]
quality: 3
sidebar:
  order: 10
---
import { Aside } from '@astrojs/starlight/components';

## Executive Summary

| Finding | Key Data | Implication |
|---------|----------|-------------|
| **No binding treaties** | Zero AI-specific treaties | No hard constraints |
| **Soft law growing** | Bletchley, Seoul declarations | Norms developing |
| **US-China divide** | Very limited cooperation | Major obstacle |
| **AI Safety Institutes** | 10+ countries establishing | Technical coordination |
| **Timeline pressure** | AI faster than diplomacy | Governance lag |

---

## Research Summary

International coordination on AI governance is essential because AI development is global, AI systems cross borders easily, and AI risks—from misalignment to misuse—affect all of humanity. Yet international coordination remains weak. No binding international treaties govern AI development. The major AI powers—the United States and China—are in strategic competition that makes cooperation difficult. And the pace of AI development far exceeds the pace of international diplomacy.

Recent efforts have made progress. The November 2023 Bletchley Declaration brought 28 countries together on AI safety principles. The May 2024 Seoul Summit expanded this with safety commitments from frontier AI labs. AI Safety Institutes are being established in multiple countries, creating potential for technical coordination. The G7 and G20 have addressed AI. But these remain voluntary frameworks without enforcement mechanisms.

The fundamental challenge is that international AI coordination requires cooperation between competitors. The US and China see AI leadership as essential to national security and economic competitiveness. Neither wants to constrain their own development or give the other an advantage. This creates a coordination problem where both might prefer mutual restraint but neither will move first.

---

## Background

<Aside type="tip" title="Why International Coordination">
AI companies can locate anywhere. AI systems can be deployed globally. AI risks affect everyone. Purely national governance leaves gaps that create risks and racing dynamics.
</Aside>

### Coordination Mechanisms

| Mechanism | Description | AI Status |
|-----------|-------------|-----------|
| **Treaties** | Binding international law | None on AI |
| **Soft law** | Non-binding agreements | Growing |
| **Standards** | Technical specifications | Developing |
| **Institutions** | International bodies | Limited AI mandate |
| **Bilateral** | Country-to-country | Very limited |

### Historical Analogies

| Domain | Time to Major Treaty | Lessons |
|--------|---------------------|---------|
| **Nuclear** | 20+ years (NPT 1968) | Took near-disaster |
| **Chemical weapons** | 100+ years (CWC 1993) | Very slow |
| **Climate** | 30+ years (Paris 2015) | Still inadequate |
| **Cyber** | No binding treaty yet | Very difficult |
| **AI** | TBD | May be harder |

---

## Key Findings

### Current Coordination Mechanisms

| Mechanism | Participants | Status | Enforcement |
|-----------|--------------|--------|-------------|
| **Bletchley Declaration** | 28 countries | Active | None |
| **Seoul Declaration** | 27 countries, 16 companies | Active | Voluntary |
| **G7 AI Code of Conduct** | G7 countries | Active | Voluntary |
| **GPAI** | 29 countries | Active | None |
| **AI Safety Institutes network** | 10+ countries | Building | Technical cooperation |

<Aside type="caution" title="All Voluntary">
Every current AI coordination mechanism is voluntary. No country has made binding commitments that constrain AI development. Soft law can build norms but can't enforce compliance.
</Aside>

### US-China Dynamics

| Dimension | Cooperation Level | Obstacle |
|-----------|------------------|----------|
| **Safety research** | Very limited | Competition concerns |
| **Standards** | Competing standards | Strategic interests |
| **Military AI** | None | Security concerns |
| **Commercial AI** | Minimal | Trade tensions |
| **Dialogue** | Sporadic | Political tensions |

### Regional Approaches

| Region | Approach | Status |
|--------|----------|--------|
| **EU** | Regulatory leadership | AI Act implemented |
| **US** | Light touch + export controls | EO + agency rules |
| **China** | State-directed | Multiple regulations |
| **UK** | Safety research + bridge role | AI Safety Institute |
| **Others** | Following leaders | Various |

### International Institutions

| Institution | AI Mandate | Effectiveness |
|-------------|------------|---------------|
| **UN** | Limited | Slow, politicized |
| **ITU** | Technical standards | Limited AI role |
| **OECD** | Policy guidance | Soft law |
| **ISO** | Technical standards | Developing |
| **Custom body** | None yet | Proposed |

---

## Causal Factors

### Factors Hindering Coordination

| Factor | Mechanism | Severity |
|--------|-----------|----------|
| **Strategic competition** | US-China rivalry | High |
| **Sovereignty concerns** | States resist constraints | High |
| **Pace mismatch** | AI faster than diplomacy | High |
| **Verification difficulty** | Can't verify AI compliance | High |
| **Capability diffusion** | Many actors, hard to coordinate | Moderate |

### Factors That Could Enable Coordination

| Factor | Mechanism | Status |
|--------|-----------|--------|
| **Shared risk perception** | Common threat motivates | Growing |
| **Technical community** | Researchers collaborate | Active |
| **Safety incidents** | Crisis creates will | Not yet occurred |
| **Economic interdependence** | Costly to decouple | Weakening |
| **Norm entrepreneurship** | Countries lead on safety | UK, others trying |

---

## Potential Coordination Models

### Minimalist Coordination

| Element | Description | Feasibility |
|---------|-------------|-------------|
| **Information sharing** | Share safety research | Moderate |
| **Hot lines** | Crisis communication | Feasible |
| **Confidence building** | Reduce misperception | Feasible |
| **Technical standards** | Interoperability | Moderate |

### Intermediate Coordination

| Element | Description | Feasibility |
|---------|-------------|-------------|
| **Compute monitoring** | Track large training runs | Proposed |
| **Incident reporting** | Share failures | Possible |
| **Evaluation standards** | Common safety tests | Developing |
| **Mutual recognition** | Accept others' certifications | Possible |

### Ambitious Coordination

| Element | Description | Feasibility |
|---------|-------------|-------------|
| **Binding treaty** | Enforceable limits | Very difficult |
| **International body** | AI governance institution | Proposed |
| **Compute governance** | Control training resources | Very difficult |
| **Racing limits** | Mutual capability constraints | Very difficult |

<Aside type="note" title="Start Small">
Ambitious coordination may be impossible now, but minimal coordination could build trust and capacity for more over time. The question is whether incremental progress can keep pace with AI development.
</Aside>

---

## Implications

### For AI Safety

| Implication | Description |
|-------------|-------------|
| **Racing continues** | No constraints on competition |
| **Governance gaps** | Some jurisdictions unregulated |
| **Lowest common denominator** | Standards may race down |
| **Incident response** | No coordinated response |

### For Governance Strategy

| Implication | Description |
|-------------|-------------|
| **National focus** | Most governance will be national |
| **Coalition of willing** | Like-minded countries coordinate |
| **Technical track** | Technical cooperation easier than political |
| **Long timeline** | Major coordination may take decades |

---

## Connection to ATM Parameters

| Related Parameter | Connection |
|------------------|------------|
| [Societal Trust](/ai-transition-model/parameters/societal-trust/) | International trust enables coordination |
| [Governance](/ai-transition-model/parameters/governance/) | International is part of governance |
| [Coordination Capacity](/ai-transition-model/parameters/coordination-capacity/) | Specific to international level |
| [Regulatory Capacity](/ai-transition-model/parameters/regulatory-capacity/) | International bodies have limited capacity |

---

## Sources

- [UK Government (2023). "Bletchley Declaration"](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration)
- [Seoul AI Safety Summit (2024). Outcomes](https://www.mofa.go.kr/)
- [GovAI (2024). "International AI Governance"](https://www.governance.ai/)
- [Carnegie Endowment (2024). "US-China AI Competition"](https://carnegieendowment.org/)
- [OECD (2024). "AI Policy Observatory"](https://oecd.ai/)

---
title: EU AI Act
description: Comprehensive AI regulation framework from the European Union
sidebar:
  order: 1
---

import {DataInfoBox, Backlinks, PageStatus} from '../../../../../../components/wiki';

<PageStatus quality={2} lastEdited="2025-12-24" llmSummary="Overview of the EU AI Act's risk-based regulatory framework with four tiers (unacceptable, high-risk, limited-risk, minimal-risk) and special provisions for general-purpose AI models above 10^25 FLOP, including enforcement through fines up to 7% of global revenue." todo="Expand with more detail on specific requirements for each risk category, implementation timeline, and enforcement mechanisms" />

<DataInfoBox entityId="eu-ai-act" />

## Summary

The EU AI Act is the world's first comprehensive legal framework for artificial intelligence. Adopted in 2024, it establishes a risk-based approach to AI regulation, with stricter requirements for higher-risk AI systems.

For AI safety, the Act is significant because it includes provisions for "general-purpose AI" (GPAI) and foundation models, including frontier AI systems.

## Risk Categories

The Act classifies AI systems by risk level:

### Unacceptable Risk (Banned)
- Social scoring by governments
- Real-time biometric identification in public (with exceptions)
- Manipulation through subliminal techniques
- Exploitation of vulnerabilities

### High Risk (Strict Requirements)
- Biometric identification systems
- Critical infrastructure management
- Educational and vocational training
- Employment and worker management
- Access to essential services
- Law enforcement
- Migration and border control

### Limited Risk (Transparency)
- Chatbots (must disclose AI)
- Emotion recognition
- Deepfake generation

### Minimal Risk (No Requirements)
- AI-enabled video games
- Spam filters
- Most AI applications

## GPAI and Foundation Models

Special provisions for general-purpose AI:

### All GPAI Models
- Technical documentation
- Transparency requirements
- Copyright compliance

### GPAI with Systemic Risk
Models trained with >10^25 FLOP face additional requirements:
- Model evaluation and adversarial testing
- Incident reporting
- Cybersecurity measures
- Energy consumption reporting

## Frontier AI Provisions

For the most capable models:
- Mandatory red-teaming
- Risk assessment for dangerous capabilities
- Reporting obligations to EU AI Office
- Codes of practice for safety

## Enforcement

- **Fines**: Up to â‚¬35M or 7% global revenue
- **EU AI Office**: Oversees GPAI compliance
- **National authorities**: Enforce most provisions
- **Codes of practice**: Industry self-regulation with EU oversight

## Timeline

| Date | Milestone |
|------|-----------|
| April 2021 | Commission proposal |
| December 2023 | Political agreement |
| March 2024 | Parliament approval |
| August 2024 | Entry into force |
| August 2025 | Most provisions apply |
| August 2026 | Full application |

## Criticisms

### From Safety Perspective
- Compute thresholds may be gameable
- 10^25 FLOP threshold may be too high
- Enforcement capacity unclear
- Limited extraterritorial reach

### From Innovation Perspective
- May disadvantage EU companies
- Compliance burden for startups
- Unclear how rules apply in practice

## Related Pages

<Backlinks client:load entityId="eu-ai-act" />

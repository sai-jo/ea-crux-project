---
title: AI Standards Bodies
description: International and national organizations developing AI technical standards
sidebar:
  order: 21
---

import { DataInfoBox , PageStatus} from '../../../../../components/wiki';

<PageStatus quality={3} lastEdited="2025-12-24" llmSummary="Technical standards bodies like ISO/IEC JTC 1/SC 42 and IEEE develop AI standards that influence governance through regulatory references (EU AI Act cites ISO standards) and compliance pathways. While important for creating shared frameworks, standards development faces challenges of industry capture, slow pace relative to AI advancement, and potential weakening through consensus processes." todo="Add more examples of standards implementation successes/failures; expand on civil society participation barriers and solutions" />

<DataInfoBox entityId="standards-bodies" />

## Summary

**Technical standards** play a crucial but often overlooked role in AI governance. While not legally binding on their own, standards:

- Get **referenced in regulations** (EU AI Act cites ISO standards)
- Provide **compliance pathways** (following standards = presumption of conformity)
- Enable **interoperability** between systems and jurisdictions
- Create **shared vocabulary** for discussing AI properties
- Influence **industry practice** through procurement requirements

## Major Standards Bodies

### International

#### ISO/IEC JTC 1/SC 42 (Artificial Intelligence)

**What it is:** Joint technical committee of ISO (International Organization for Standardization) and IEC (International Electrotechnical Commission) focused on AI standardization.

**Key standards:**

| Standard | Title | Status |
|----------|-------|--------|
| ISO/IEC 22989 | AI Concepts and Terminology | Published 2022 |
| ISO/IEC 23894 | AI Risk Management | Published 2023 |
| ISO/IEC 23053 | Framework for AI Systems Using ML | Published 2022 |
| ISO/IEC 42001 | AI Management System | Published 2023 |
| ISO/IEC 42005 | AI System Impact Assessment | Under development |
| ISO/IEC TR 24027 | Bias in AI Systems | Published 2021 |
| ISO/IEC TR 24028 | Trustworthiness in AI | Published 2020 |
| ISO/IEC TR 24029 | Assessment of Robustness of Neural Networks | Published 2021 |

**Why it matters:**
- EU AI Act allows "harmonized standards" for presumption of conformity
- ISO standards are globally recognized
- Provides common framework across jurisdictions

#### IEEE Standards Association

**What it is:** Standards development arm of IEEE (Institute of Electrical and Electronics Engineers), the world's largest technical professional organization.

**Key AI standards:**

| Standard | Title | Status |
|----------|-------|--------|
| IEEE 7000 | Model Process for Addressing Ethical Concerns | Published 2021 |
| IEEE 7001 | Transparency of Autonomous Systems | Published 2021 |
| IEEE 7002 | Data Privacy Process | Published 2022 |
| IEEE 7003 | Algorithmic Bias Considerations | Published 2022 |
| IEEE 7007 | Ontological Standard for Ethically Driven Robotics | Under development |
| IEEE 7010 | Wellbeing Metrics for Ethical AI | Published 2020 |
| IEEE 2841 | Framework for Responsible AI | Under development |

**IEEE Ethics Certification Program for Autonomous Systems (ECPAIS):**
- Certification program based on IEEE 7000 series
- Provides third-party verification of ethical AI practices

#### Partnership on AI (PAI)

**What it is:** Multi-stakeholder organization developing best practices and guidelines (not formal standards).

**Key outputs:**
- ABOUT ML (Annotation and Benchmarking on Understanding and Transparency of ML)
- Responsible Practices for Synthetic Media
- Guidelines on AI and Job Quality

**Note:** PAI produces guidelines rather than formal standards, but influences industry practice.

### Regional

#### CEN-CENELEC (Europe)

**What it is:** European standards organizations tasked with developing harmonized standards for the EU AI Act.

**Key activities:**
- JTC 21: Joint Technical Committee on AI
- Developing standards that provide presumption of conformity with EU AI Act
- Working on risk assessment, documentation, and testing methodologies

**Timeline:** Standards expected 2025-2026 to support EU AI Act implementation.

**Harmonized standards** will be critical because:
- Following them = presumption of EU AI Act compliance
- Creates clear compliance pathway for companies
- Reduces legal uncertainty

#### ETSI (European Telecommunications Standards Institute)

**Key work:**
- ETSI GR SAI series on Securing AI
- Focus on AI security and robustness
- Cybersecurity aspects of AI systems

### National

#### NIST (United States)

**Key outputs:**
- AI Risk Management Framework (AI RMF)
- AI RMF Playbook
- Generative AI Profile (AI 600-1)
- AI standards coordination role for US government

[More on NIST AI RMF â†’](/knowledge-base/policies/nist-ai-rmf)

**Unique role:** NIST is not a standards body per se but develops influential frameworks and coordinates US input to international standards.

#### BSI (United Kingdom)

**Key work:**
- BS 8611: Robots and Robotic Devices - Guide to Ethical Design
- AI standards development
- Contribution to ISO work

#### Standards Australia

**Key work:**
- AS/NZS ISO/IEC standards adoption
- AI ethics frameworks for Australian context

## Key Standard Types

### Management System Standards

**ISO/IEC 42001** - AI Management System
- Organizational requirements for responsible AI
- Similar structure to ISO 9001 (quality), ISO 27001 (security)
- Certifiable standard (third-party audits possible)

**What it covers:**
- AI policy and objectives
- Risk assessment processes
- Roles and responsibilities
- Documentation requirements
- Continual improvement

### Risk Management Standards

**ISO/IEC 23894** - AI Risk Management
- Framework for identifying and managing AI-related risks
- Aligned with ISO 31000 (general risk management)
- Input to both NIST AI RMF and EU AI Act

### Technical Standards

**Testing and evaluation:**
- ISO/IEC TR 24029: Neural network robustness assessment
- IEEE standards on explainability, bias testing

**Documentation:**
- Model cards, datasheets, system documentation requirements
- Traceability and transparency requirements

## Standards and Regulation

### EU AI Act Integration

The EU AI Act explicitly provides for **harmonized standards**:

```
Article 40: Harmonised standards and standardisation deliverables
- European standardisation organisations shall develop harmonised standards
- Compliance with harmonised standards = presumption of conformity
```

**Timeline:**
- Commission has issued standardisation requests to CEN-CENELEC
- Standards expected 2025-2026
- Until then, companies must demonstrate compliance through other means

### US Approach

No direct standards mandate, but:
- NIST frameworks referenced in Executive Order
- Federal procurement may require standards compliance
- Industry increasingly adopts standards voluntarily

### China Approach

- TC 260 (National Information Security Standardization Technical Committee)
- Mandatory standards (GB) vs. recommended standards (GB/T)
- AI standards increasingly aligned with regulatory requirements

## Participation and Influence

### Who Participates

Standards development involves:
- **Industry:** Major tech companies actively participate
- **Government:** National standards bodies, regulators
- **Academia:** Research institutions, individual experts
- **Civil society:** Limited but growing participation

### Concerns About Capture

**Industry dominance:**
- Large companies have resources to participate extensively
- May shape standards to favor existing practices
- Civil society often under-resourced

**Slow pace:**
- Standards development takes years
- Technology moves faster than standards processes
- Risk of standards being obsolete when published

**Lowest common denominator:**
- Consensus-based processes may weaken requirements
- Standards reflect what industry will accept, not best practices

## Strategic Considerations

### For AI Safety

**Opportunities:**
- Standards can embed safety requirements into industry practice
- Third-party certification creates accountability
- International standards prevent race to the bottom

**Risks:**
- Weak standards may provide false assurance
- "Compliance" may substitute for actual safety
- Capture by industry interests

### Recommendations

For those concerned about AI safety:

1. **Participate** in standards development processes
2. **Monitor** emerging standards for safety implications
3. **Advocate** for ambitious requirements, not just industry comfort
4. **Support** civil society participation in standards bodies
5. **Recognize** standards as one tool among many, not a complete solution

## Key Standards Timeline

| Year | Development |
|------|-------------|
| 2020 | ISO/IEC TR 24028 (Trustworthiness), IEEE 7010 (Wellbeing) |
| 2021 | IEEE 7000 (Ethics), ISO/IEC TR 24027 (Bias) |
| 2022 | ISO/IEC 22989 (Terminology), IEEE 7002/7003 |
| 2023 | ISO/IEC 42001 (Management System), ISO/IEC 23894 (Risk) |
| 2024 | NIST GenAI Profile, CEN-CENELEC work accelerates |
| 2025-26 | EU AI Act harmonized standards expected |


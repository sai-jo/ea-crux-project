---
title: Epistemic Risks
description: Risks to knowledge, truth, and our ability to understand reality
sidebar:
  order: 0
---

Epistemic risks threaten our collective ability to know what's true, trust information sources, and maintain shared understanding of reality. AI amplifies these risks by enabling unprecedented scale of content generation and personalization.

## Core Risks

- [Epistemic Collapse](/knowledge-base/risks/epistemic/epistemic-collapse) - Inability to distinguish true from false at scale
- [Trust Erosion](/knowledge-base/risks/epistemic/trust-erosion) - Loss of faith in institutions, media, and evidence
- [Automation Bias](/knowledge-base/risks/epistemic/automation-bias) - Excessive reliance on AI outputs
- [Cyber Psychosis](/knowledge-base/risks/epistemic/cyber-psychosis) - AI-induced psychological dysfunction, manipulation, and breaks from reality

## Why AI Amplifies Epistemic Risks

### Scale of Generation
AI can generate human-quality text, images, and video at unprecedented scale. The volume of AI-generated content may soon exceed human-generated content, making it harder to find reliable information.

### Personalization
AI enables content tailored to individual psychology, creating personalized filter bubbles and targeted manipulation that's harder to detect or resist.

### Authenticity Crisis
When any image, video, or voice can be synthesized, "seeing is believing" breaks down. Even real evidence becomes deniable.

### Speed Asymmetry
Generating false content is faster than verifying it. AI-powered fact-checking can't keep up with AI-powered generation.

## Relationship to Other Risks

Epistemic risks undermine responses to all other risks:
- If we can't agree on what's true, we can't coordinate on safety
- If we don't trust institutions, governance becomes harder
- If individuals can't identify manipulation, misuse becomes more effective

## Observable vs Future

| Already Happening | Emerging Concerns |
|------------------|-------------------|
| AI-generated misinformation | Total authenticity collapse |
| Chatbot hallucinations | Overreliance on AI judgment |
| Filter bubbles | Personalized reality |
| Deepfakes | Plausible deniability for real events |

## Key Questions

- Can technical solutions (watermarking, detection) keep up with generation?
- How do societies maintain shared reality when information is infinitely personalizable?
- What institutions can remain trustworthy in an AI-saturated information environment?

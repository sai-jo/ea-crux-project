---
title: Risks & Failure Modes
description: End-state harms from AI systems—technical failures, misuse, and societal impacts
sidebar:
  order: 0
tableOfContents: false
---

import { RisksTable, RiskCategoryCard, RecentUpdates, TagBrowser } from '../../../../components/wiki';
import { getRisksForTable } from '../../../../data';

This section documents **risks**—harmful end states we want to avoid. These are organized into four categories: accident risks (technical failures), misuse risks (intentional harm), structural risks (societal harms), and epistemic risks (threats to collective knowledge).

For contributing dynamics and mechanisms that increase these risks, see **[Risk Factors](/knowledge-base/risk-factors/)**.

## Risk Categories

<div className="grid grid-cols-1 md:grid-cols-2 gap-4 not-content my-6">
  <RiskCategoryCard client:load category="accident" href="/knowledge-base/risks/accident/" />
  <RiskCategoryCard client:load category="misuse" href="/knowledge-base/risks/misuse/" />
  <RiskCategoryCard client:load category="structural" href="/knowledge-base/risks/structural/" />
  <RiskCategoryCard client:load category="epistemic" href="/knowledge-base/risks/epistemic/" />
</div>

## Risks vs Risk Factors

| Risks (this section) | Risk Factors |
|---------------------|--------------|
| End-state harms | Contributing dynamics |
| What we want to avoid | What increases probability |
| e.g., Lock-in, Epistemic Collapse | e.g., Racing Dynamics, Trust Erosion |

**[Browse Risk Factors →](/knowledge-base/risk-factors/)**

## All Risks

<RisksTable client:load risks={getRisksForTable()} />

## Observable vs Theoretical

| Currently Observable | Emerging | Theoretical/Future |
|---------------------|----------|-------------------|
| Sycophancy | Sandbagging | Scheming |
| Reward Hacking | Disinformation at scale | Treacherous Turn |
| Specification Gaming | Deepfakes | Sharp Left Turn |
| Concentration of Power | Emergent Capabilities | Lock-in |
| Reality Fragmentation | Institutional Capture | Power-Seeking AI |

Understanding observable failures helps us reason about future risks, though the relationship between current problems and future catastrophic risks is debated.

## How Categories Interact

These categories aren't independent:
- **Accident + Misuse**: Misuse is more dangerous when AI is more capable; accident risks determine capability levels
- **Structural + Accident**: Racing dynamics (a risk factor) make accidents more likely by reducing safety investment
- **Epistemic + All**: If we can't agree on what risks exist, coordinating responses is impossible
- **Structural + Misuse**: Concentration of power determines who might misuse AI; proliferation determines who has access

## Explore by Tag

<TagBrowser client:load mode="compact" maxTags={15} />

## Recently Updated Risks

<RecentUpdates client:load limit={5} compact={true} />

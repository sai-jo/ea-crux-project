---
title: Misuse Risks
description: Intentional harmful applications of AI technology
sidebar:
  order: 0
---

Misuse risks arise when humans deliberately use AI systems to cause harm. Unlike accident risks, these require malicious intentâ€”but AI dramatically amplifies what bad actors can do.

## Weapons & Violence

AI enabling new forms of violence:

- [Bioweapons](/knowledge-base/risks/misuse/bioweapons) - AI-assisted pathogen design and synthesis
- [Cyberweapons](/knowledge-base/risks/misuse/cyberweapons) - Autonomous hacking and vulnerability exploitation
- [Autonomous Weapons](/knowledge-base/risks/misuse/autonomous-weapons) - Lethal autonomous weapons systems (LAWS)

## Manipulation & Deception

AI-powered influence and fraud:

- [Disinformation](/knowledge-base/risks/misuse/disinformation) - AI-generated propaganda and influence operations
- [Deepfakes](/knowledge-base/risks/misuse/deepfakes) - Synthetic media for impersonation and fabrication
- [AI-Powered Fraud](/knowledge-base/risks/misuse/fraud) - Automated scams, social engineering, impersonation

## Surveillance & Control

AI enabling oppression:

- [Mass Surveillance](/knowledge-base/risks/misuse/surveillance) - AI-enabled monitoring at scale
- [Authoritarian Tools](/knowledge-base/risks/misuse/authoritarian-tools) - AI for censorship, social control, oppression

## Key Dynamics

### Democratization of Harm
AI lowers barriers to sophisticated attacks. A lone actor can now generate personalized disinformation at scale, or potentially access dangerous knowledge that previously required rare expertise.

### Offense-Defense Balance
Many misuse risks shift the balance toward offense. It's easier to generate disinformation than to detect it, easier to find vulnerabilities than to patch them.

### Dual-Use Dilemma
Most AI capabilities have both beneficial and harmful applications. Language models that help with coding can also help with malware. Models that accelerate drug discovery could accelerate bioweapon design.

## Relationship to Accident Risks

Misuse and accident risks interact:
- Misuse is more dangerous when AI systems are more capable
- Accident risks become more severe if misused AI is harder to control
- Both require understanding AI capabilities we don't fully control

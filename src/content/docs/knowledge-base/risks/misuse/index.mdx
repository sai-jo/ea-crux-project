---
title: Misuse Risks
description: Intentional harmful applications of AI technology
sidebar:
  order: 0
---

import { RiskRelationshipDiagram } from '../../../../../components/wiki';

Misuse risks arise when humans deliberately use AI systems to cause harm. Unlike accident risks, these require malicious intentâ€”but AI dramatically amplifies what bad actors can do.

## How These Risks Connect

<RiskRelationshipDiagram
  title=""
  layout="manual"
  nodes={[
    { id: 'cyberweapons', title: 'Cyberweapons', href: '/knowledge-base/risks/misuse/cyberweapons/', x: 0, y: 0 },
    { id: 'bioweapons', title: 'Bioweapons', href: '/knowledge-base/risks/misuse/bioweapons/', x: 35, y: 0 },
    { id: 'autonomous-weapons', title: 'Autonomous Weapons', href: '/knowledge-base/risks/misuse/autonomous-weapons/', x: 70, y: 0 },
    { id: 'deepfakes', title: 'Deepfakes', href: '/knowledge-base/risks/misuse/deepfakes/', x: 0, y: 50 },
    { id: 'disinformation', title: 'Disinformation', href: '/knowledge-base/risks/misuse/disinformation/', x: 35, y: 50 },
    { id: 'fraud', title: 'AI-Powered Fraud', href: '/knowledge-base/risks/misuse/fraud/', x: 70, y: 50 },
    { id: 'surveillance', title: 'Mass Surveillance', href: '/knowledge-base/risks/misuse/surveillance/', x: 35, y: 100 },
  ]}
  edges={[
    { from: 'cyberweapons', to: 'bioweapons', label: 'steals research' },
    { from: 'cyberweapons', to: 'autonomous-weapons', label: 'enables hacking' },
    { from: 'deepfakes', to: 'disinformation', label: 'provides content' },
    { from: 'deepfakes', to: 'fraud', label: 'impersonation' },
    { from: 'disinformation', to: 'surveillance', label: 'justifies' },
  ]}
  width={650}
  height={280}
/>

---

## Weapons & Violence

AI enabling new forms of violence:

| Risk | Description |
|------|-------------|
| **[Bioweapons](/knowledge-base/risks/misuse/bioweapons/)** | AI-assisted pathogen design and synthesis |
| **[Cyberweapons](/knowledge-base/risks/misuse/cyberweapons/)** | Autonomous hacking and vulnerability exploitation |
| **[Autonomous Weapons](/knowledge-base/risks/misuse/autonomous-weapons/)** | Lethal autonomous weapons systems (LAWS) |

## Manipulation & Deception

AI-powered influence and fraud:

| Risk | Description |
|------|-------------|
| **[Disinformation](/knowledge-base/risks/misuse/disinformation/)** | AI-generated propaganda and influence operations |
| **[Deepfakes](/knowledge-base/risks/misuse/deepfakes/)** | Synthetic media for impersonation and fabrication |
| **[AI-Powered Fraud](/knowledge-base/risks/misuse/fraud/)** | Automated scams, social engineering, impersonation |

## Surveillance

| Risk | Description |
|------|-------------|
| **[Mass Surveillance](/knowledge-base/risks/misuse/surveillance/)** | AI-enabled monitoring at scale |

---

## Related: Authoritarian Applications

Surveillance and other misuse capabilities can enable [Authoritarian Takeover](/knowledge-base/risks/structural/authoritarian-takeover/) (a structural risk). The tools and techniques that enable authoritarian control are documented in [Authoritarian Tools](/knowledge-base/risk-factors/authoritarian-tools/) (a risk factor).

---

## Key Dynamics

### Democratization of Harm
AI lowers barriers to sophisticated attacks. A lone actor can now generate personalized disinformation at scale, or potentially access dangerous knowledge that previously required rare expertise.

### Offense-Defense Balance
Many misuse risks shift the balance toward offense. It's easier to generate disinformation than to detect it, easier to find vulnerabilities than to patch them.

### Dual-Use Dilemma
Most AI capabilities have both beneficial and harmful applications. Language models that help with coding can also help with malware. Models that accelerate drug discovery could accelerate bioweapon design.

---

## Relationship to Other Risk Categories

### Misuse + Accident Risks
- Misuse is more dangerous when AI systems are more capable
- Accident risks become more severe if misused AI is harder to control
- Both require understanding AI capabilities we don't fully control

### Misuse + Structural Risks
- Surveillance and disinformation enable [authoritarian takeover](/knowledge-base/risks/structural/authoritarian-takeover/)
- Misuse capabilities contribute to [concentration of power](/knowledge-base/risks/structural/concentration-of-power/)

### Misuse + Epistemic Risks
- Disinformation drives [reality fragmentation](/knowledge-base/risks/epistemic/reality-fragmentation/)
- Deepfakes accelerate [authentication collapse](/knowledge-base/risk-factors/authentication-collapse/)

---

## Contributing Risk Factors

These misuse risks are influenced by dynamics documented in **[Risk Factors](/knowledge-base/risk-factors/)**:

| Factor | How It Contributes |
|--------|-------------------|
| [Authoritarian Tools](/knowledge-base/risk-factors/authoritarian-tools/) | Capabilities that enable surveillance and control |
| [Proliferation](/knowledge-base/risk-factors/proliferation/) | More actors gain access to dangerous capabilities |
| [Authentication Collapse](/knowledge-base/risk-factors/authentication-collapse/) | Harder to distinguish real from fake content |

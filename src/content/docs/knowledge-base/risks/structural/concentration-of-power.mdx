---
title: Concentration of Power
description: AI enabling unprecedented accumulation of power by small groups
sidebar:
  order: 1
---

import { InfoBox, EntityCard, EntityCards, Tags, Sources, Section } from '../../../../../components/wiki';

<InfoBox
  type="risk"
  title="Concentration of Power"
  severity="high"
  likelihood="Medium-High"
  timeframe="Near to Medium-term"
  customFields={[
    { label: "Type", value: "Structural" },
    { label: "Key Concern", value: "Unprecedented asymmetry" },
  ]}
/>

## Overview

AI could enable small groups—companies, governments, or individuals—to accumulate and exercise power at scales previously impossible. The concern isn't just inequality (which has always existed) but a qualitative shift in what power concentration looks like when AI can substitute for large numbers of humans across many domains.

A world where a handful of entities control the most powerful AI systems might look very different from today's distribution of power.

## Mechanisms of Concentration

AI capability concentration occurs because cutting-edge AI requires massive compute resources, rare talent, and proprietary data that only a few organizations can assemble. The leading AI labs (OpenAI, Anthropic, Google DeepMind, Meta) and perhaps a few others have resources others can't match.

Economic concentration follows from AI's ability to automate across industries. If a single AI system can replace many workers across many sectors, the owners of that system capture value that previously went to distributed labor. Winner-take-all dynamics may intensify.

Political and military concentration occurs when AI provides decisive advantages in surveillance, prediction, and force application. States with advanced AI gain power over those without. Within states, those controlling AI systems gain power over those who don't.

Information concentration comes from AI's ability to process and generate information at scale. Those controlling large language models and recommendation systems shape what billions of people see and think.

## Historical Context

Power has always been unequally distributed. But certain technologies have shifted the balance dramatically. Nuclear weapons concentrated military power in a few states. The internet concentrated information power in a few platforms.

AI might be more transformative than either because it applies across all domains. Unlike nuclear weapons (which only threaten destruction) or the internet (which primarily affects information), AI could provide advantages in economics, politics, research, and military affairs simultaneously.

## Scenarios

Benevolent concentration involves power concentrated in hands that use it well—a capable AI lab or government that uses advanced AI to solve problems effectively. Even optimistic scenarios raise questions about accountability and sustainability.

Malevolent concentration involves power concentrated in hands that abuse it—an authoritarian state or reckless company using AI dominance for control or profit at others' expense.

Competitive concentration involves multiple powerful actors competing with AI, potentially creating instability, arms races, and conflict.

Fragmented power involves broad access to AI preventing concentration—but this may also enable distributed misuse.

## Why This Matters

If power becomes too concentrated, traditional checks—democratic accountability, market competition, international balance—may not function. Those with power could reshape rules to entrench their position. Lock-in of bad outcomes becomes possible.

Even well-intentioned concentration is concerning. No small group should unilaterally determine humanity's future, regardless of their intentions. The current structure of AI development—private companies making decisions with global implications—may not be appropriate for the technology's significance.

## Case Studies

### OpenAI-Microsoft Partnership
Microsoft's $10+ billion investment in OpenAI creates complex power dynamics. When OpenAI's board fired CEO Sam Altman in November 2023, Microsoft's leverage helped reverse the decision within days. The relationship illustrates how nominally independent AI organizations become dependent on Big Tech resources. The FTC and UK's CMA are investigating whether this constitutes anti-competitive behavior.

### The AI "Compute Divide"
Training GPT-4 required over 25,000 NVIDIA A100 GPUs and an investment exceeding $100 million. Only a handful of organizations can afford frontier AI development. This has led to a "compute divide" where even well-funded university research labs cannot compete with Big Tech, concentrating AI research in corporate hands.

### Cloud Infrastructure Monopoly
AWS, Microsoft Azure, and Google Cloud control 68% of global cloud computing—the essential infrastructure for AI. This means AI startups depend on potential competitors for basic operations. Anthropic (Amazon), OpenAI (Microsoft), and Google DeepMind represent increasing vertical integration.

## Key Debates

**Open Source as Countermeasure**: Does open-source AI (like Meta's LLaMA) prevent concentration by democratizing access? Or does it merely distribute capabilities while concentrating development resources?

**Regulatory Capture Risk**: As AI companies grow more powerful, can they shape regulation to their benefit? Should antitrust action be preemptive?

**Benevolent Concentration**: If power must be concentrated during the critical AI development period, is it better to concentrate it in safety-focused organizations? Or is any concentration inherently dangerous?

## Timeline

- **2014**: Google acquires DeepMind for ~$500M
- **2019**: Microsoft invests $1B in OpenAI
- **2022**: NVIDIA achieves near-monopoly in AI chips
- **2023 (Jan)**: Microsoft extends OpenAI investment to $10B+
- **2023 (Nov)**: OpenAI board crisis reveals Microsoft leverage
- **2023-24**: Amazon invests $4B in Anthropic; Google invests $2B
- **2024**: FTC and CMA investigate AI partnerships

## Responses

Governance approaches might include antitrust action, public investment in AI, international agreements on AI development, and democratic oversight of AI deployment.

Technical approaches might include open-source AI development, distributed compute access, and privacy-preserving techniques that limit data advantages.

The fundamental tension: benefiting from AI's power while preventing that power from concentrating dangerously is one of the defining challenges of AI governance.

## Video & Podcast Resources

- [MIT Technology Review: AI Is Owned by Big Tech](https://www.technologyreview.com/2023/12/05/1084393/make-no-mistake-ai-is-owned-by-big-tech/)
- [AI Now Institute Reports](https://ainowinstitute.org/)
- [80,000 Hours: Podcasts on AI Governance](https://80000hours.org/podcast/)

<Section title="Related Topics">
  <Tags tags={[
    "AI Governance",
    "Power Dynamics",
    "Inequality",
    "Existential Risk",
    "Lock-in",
  ]} />
</Section>

<Section title="Related Entries">
  <EntityCards>
    <EntityCard
      id="lock-in"
      category="risk"
      title="Lock-in"
      description="Permanent entrenchment of power"
    />
    <EntityCard
      id="racing-dynamics"
      category="risk"
      title="Racing Dynamics"
      description="Competition for AI advantage"
    />
    <EntityCard
      id="authoritarian-tools"
      category="risk"
      title="Authoritarian Tools"
      description="AI enabling political control"
    />
  </EntityCards>
</Section>

<Sources sources={[
  { title: "AI and the Future of Power", url: "https://80000hours.org/" },
  { title: "The Precipice", author: "Toby Ord" },
  { title: "GovAI Annual Report 2024", url: "https://cdn.governance.ai/GovAI_Annual_Report_2024.pdf", date: "2024" },
  { title: "Computing Power and the Governance of AI (GovAI)", url: "https://www.governance.ai/research-paper/computing-power-and-the-governance-of-artificial-intelligence" },
  { title: "Market Concentration Implications of Foundation Models (GovAI)", url: "https://www.governance.ai/research-paper/market-concentration-implications-of-foundation-models" },
  { title: "Power and Governance in the Age of AI (New America)", url: "https://www.newamerica.org/planetary-politics/briefs/power-governance-ai-public-good/" },
  { title: "AI, Global Governance, and Digital Sovereignty (arXiv)", url: "https://arxiv.org/html/2410.17481v1", date: "2024" },
]} />

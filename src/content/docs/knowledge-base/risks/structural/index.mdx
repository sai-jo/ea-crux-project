---
title: Structural Risks
description: End-state harms from how AI reshapes society, institutions, and power dynamics
sidebar:
  label: Overview
  order: 0
---

import { KeyQuestions, Sources, RiskRelationshipDiagram } from '../../../../components/wiki';

Structural risks are harmful end states that emerge from how AI development and deployment reshape societyâ€”rather than from individual AI systems failing or being misused.

## How These Risks Connect

<RiskRelationshipDiagram
  title=""
  layout="manual"
  nodes={[
    { id: 'concentration-of-power', title: 'Concentration of Power', href: '/knowledge-base/risks/structural/concentration-of-power/', x: 20, y: 0 },
    { id: 'authoritarian-takeover', title: 'Authoritarian Takeover', href: '/knowledge-base/risks/structural/authoritarian-takeover/', x: 70, y: 0 },
    { id: 'erosion-of-agency', title: 'Erosion of Agency', href: '/knowledge-base/risks/structural/erosion-of-agency/', x: 0, y: 50 },
    { id: 'enfeeblement', title: 'Enfeeblement', href: '/knowledge-base/risks/structural/enfeeblement/', x: 40, y: 50 },
    { id: 'lock-in', title: 'Lock-in', href: '/knowledge-base/risks/structural/lock-in/', x: 80, y: 50 },
  ]}
  edges={[
    { from: 'concentration-of-power', to: 'authoritarian-takeover', label: 'enables' },
    { from: 'concentration-of-power', to: 'lock-in', label: 'entrenches' },
    { from: 'authoritarian-takeover', to: 'lock-in', label: 'permanent' },
    { from: 'erosion-of-agency', to: 'enfeeblement', label: 'leads to' },
    { from: 'enfeeblement', to: 'lock-in', label: "can't resist" },
  ]}
  width={700}
  height={220}
/>

---

## The Risks

| Risk | Description |
|------|-------------|
| **[Concentration of Power](/knowledge-base/risks/structural/concentration-of-power/)** | AI enabling unprecedented power accumulation by small groups |
| **[Authoritarian Takeover](/knowledge-base/risks/structural/authoritarian-takeover/)** | Stable, durable authoritarianism harder to reverse than historical autocracies |
| **[Erosion of Human Agency](/knowledge-base/risks/structural/erosion-of-agency/)** | Humans losing meaningful control over their lives and decisions |
| **[Enfeeblement](/knowledge-base/risks/structural/enfeeblement/)** | Humanity losing capability to function independently of AI |
| **[Lock-in](/knowledge-base/risks/structural/lock-in/)** | Permanent entrenchment of values, systems, or structures |

---

## What Makes These "Structural"?

These are **end-state harms** that emerge from system dynamics, not individual failures:

1. **System-level emergence** - They arise from how AI reshapes society, not from any single AI system misbehaving
2. **Could occur even if AI works as intended** - Perfect AI alignment doesn't prevent power concentration or human skill loss
3. **Difficult to attribute** - No single actor "causes" these risks; they emerge from collective dynamics
4. **Path dependent** - Early decisions constrain later options in ways that may be hard to reverse

---

## Contributing Risk Factors

These structural risks are influenced by dynamics documented in **[Risk Factors](/knowledge-base/risk-factors/)**:

| Factor | How It Contributes |
|--------|-------------------|
| [Racing Dynamics](/knowledge-base/risk-factors/racing-dynamics/) | Accelerates development, reduces safety margins |
| [Winner-Take-All](/knowledge-base/risk-factors/winner-take-all/) | Amplifies concentration of power |
| [Economic Disruption](/knowledge-base/risk-factors/economic-disruption/) | Creates dependency, erodes agency |
| [Flash Dynamics](/knowledge-base/risk-factors/flash-dynamics/) | Reduces human oversight capacity |
| [Irreversibility](/knowledge-base/risk-factors/irreversibility/) | Makes lock-in more likely |
| [Multipolar Trap](/knowledge-base/risk-factors/multipolar-trap/) | Drives racing, concentration |
| [Proliferation](/knowledge-base/risk-factors/proliferation/) | Spreads capabilities to more actors |

---

## Relationship to Other Risk Categories

### Structural + Accident Risks
Racing dynamics (a risk factor) increase accident probability. Power concentration means accidents by dominant actors have larger consequences.

### Structural + Misuse Risks
Power concentration enables misuse at scale. Authoritarian takeover is both a structural risk and enables systematic misuse.

### Structural + Epistemic Risks
Power concentration enables information control. Enfeeblement reduces humanity's ability to evaluate AI systems.

---

## Key Uncertainties

<KeyQuestions
  questions={[
    "Does AI actually concentrate power more than previous technologies?",
    "Is capability loss from AI qualitatively different from previous technological shifts?",
    "Can coordination mechanisms address structural risks, or are they inherent to AI development?",
    "How would we know if we're entering a lock-in scenario?",
    "Are structural risks amenable to technical solutions, or only governance solutions?"
  ]}
/>

---

## Research Landscape

| Source | Focus |
|--------|-------|
| [Bostrom (2014): Superintelligence](https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0198739834) | AI trajectories, "dystopian" scenarios |
| [Ord (2020): The Precipice](https://theprecipice.com/) | Existential risk, "dystopian lock-in" |
| [MacAskill (2022): What We Owe the Future](https://whatweowethefuture.com/) | Value lock-in, trajectory changes |
| [GovAI](https://www.governance.ai/) | AI governance research |
| [AI Now Institute](https://ainowinstitute.org/) | Concentration, power, inequality |

<Sources sources={[
  { title: "Superintelligence", author: "Nick Bostrom", date: "2014" },
  { title: "The Precipice", author: "Toby Ord", date: "2020" },
  { title: "What We Owe the Future", author: "Will MacAskill", date: "2022" },
  { title: "GovAI Research", url: "https://www.governance.ai/" },
  { title: "AI Now Institute", url: "https://ainowinstitute.org/" },
]} />

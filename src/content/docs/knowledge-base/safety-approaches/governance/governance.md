---
title: Governance & Policy
description: Using laws, regulations, and institutions to ensure AI safety.
---

**The approach**: Develop and implement policies, regulations, and institutions that ensure AI is developed and deployed safely.

## Evaluation Summary

| Dimension | Assessment | Notes |
|-----------|------------|-------|
| Tractability | Medium | Policy can be changed; adoption uncertain |
| If alignment hard | High | May be only way to buy time |
| If alignment easy | High | Still needed for deployment safety |
| Neglectedness | Medium | Growing attention, still under-resourced |

## What This Approach Does

- Creates regulatory frameworks for AI development
- Establishes liability and accountability structures
- Develops international coordination mechanisms
- Sets standards for safety testing and deployment
- Influences norms at AI labs

## Policy Levers

| Lever | Mechanism | Effectiveness |
|-------|-----------|---------------|
| Licensing | Require approval for frontier AI | Medium (enforcement hard) |
| Liability | Legal consequences for harm | Medium (hard to attribute) |
| Standards | Required safety practices | High (if enforced) |
| Export controls | Limit technology spread | Medium (can backfire) |
| Compute governance | Control training resources | High (physical choke point) |

## Crux 1: Can Policy Keep Up with Technology?

| Can keep up | Cannot keep up |
|-------------|----------------|
| Focus on outcomes, not tech | AI advances too fast |
| Adaptive regulation possible | Regulators captured or incompetent |
| Industry wants clear rules | Regulation is always behind |

## Crux 2: Will Good Policy Be Adopted?

| Will be adopted | Won't be adopted |
|-----------------|------------------|
| Growing political salience | Industry lobbying too strong |
| Clear harms motivate action | Harms speculative/diffuse |
| International pressure | Competitive pressure to deregulate |

## Crux 3: Does It Address Root Cause?

| Addresses root cause | Only treats symptoms |
|---------------------|---------------------|
| Slows down to buy time | Doesn't solve alignment |
| Changes incentives | Labs will route around |
| Enables better practices | Race continues regardless |

## Who Should Work on This?

**Good fit if you believe**:
- Technical solutions alone aren't enough
- Policy can meaningfully influence AI development
- Social/political skills are your strength
- Want to work outside AI labs

**Less relevant if you believe**:
- Technical alignment is the bottleneck
- Governance will inevitably fail
- Policy just slows beneficial AI

---
title: Safety Approaches
description: Technical, governance, and institutional approaches to AI safety
sidebar:
  order: 0
---

This section catalogs approaches to making AI development safer. Approaches range from technical research to governance interventions to institutional changes.

## Technical Approaches

Research aimed at solving the alignment problem and making AI systems safer:

- [Interpretability](/knowledge-base/safety-approaches/technical/interpretability) - Understanding what AI systems are doing internally
- [Scalable Oversight](/knowledge-base/safety-approaches/technical/scalable-oversight) - Maintaining human oversight as AI scales
- [AI Control](/knowledge-base/safety-approaches/technical/ai-control) - Ensuring AI systems remain controllable
- [RLHF](/knowledge-base/safety-approaches/technical/rlhf) - Reinforcement Learning from Human Feedback
- [Agent Foundations](/knowledge-base/safety-approaches/technical/agent-foundations) - Mathematical foundations for safe agency
- [Evaluations](/knowledge-base/safety-approaches/technical/evals) - Measuring AI capabilities and safety properties
- [AI-Assisted Safety](/knowledge-base/safety-approaches/technical/ai-assisted) - Using AI to help with alignment research
- [Corrigibility](/knowledge-base/safety-approaches/technical/corrigibility) - Making AI systems willing to be corrected
- [Multi-Agent Safety](/knowledge-base/safety-approaches/technical/multi-agent) - Safety in systems with multiple AI agents

## Governance Approaches

Policy and regulatory approaches to AI safety:

- [AI Governance](/knowledge-base/safety-approaches/governance/governance) - Overview of governance approaches
- [Compute Governance](/knowledge-base/safety-approaches/governance/compute-governance) - Controlling access to AI training compute
- [International Coordination](/knowledge-base/safety-approaches/governance/international) - Global agreements on AI development

## Institutional Approaches

Changes to how AI development is organized:

- [Lab Safety Culture](/knowledge-base/safety-approaches/institutional/lab-culture) - Safety practices within AI labs
- [Open Source Considerations](/knowledge-base/safety-approaches/institutional/open-source) - Tradeoffs of open AI development
- [Pause Proposals](/knowledge-base/safety-approaches/institutional/pause) - Slowing or stopping AI development

## Research Agendas

How specific organizations approach safety:

- [Anthropic's Core Views](/knowledge-base/safety-approaches/anthropic-core-views) - Anthropic's research philosophy and priorities

## Comparing Approaches

| Approach | Timeframe | Who Acts | Key Uncertainty |
|----------|-----------|----------|-----------------|
| Interpretability | Years | Researchers | Will it scale? |
| Governance | Months-Years | Governments | Will it be adopted? |
| Lab Culture | Immediate | Labs | Will competition undermine it? |
| International | Years | Nations | Can coordination work? |

## Relationship to Risks

Different approaches address different risks:

- **Technical approaches** primarily address accident risks
- **Governance approaches** address both misuse and structural risks
- **Institutional approaches** address racing dynamics and coordination failures

No single approach is sufficient. Most experts advocate for a portfolio across categories.

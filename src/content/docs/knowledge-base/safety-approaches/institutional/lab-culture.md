---
title: Lab Safety Culture
description: Improving safety practices within AI development organizations.
---

**The approach**: Improve safety culture, practices, and incentives within AI labsâ€”the organizations actually building frontier AI.

## Evaluation Summary

| Dimension | Assessment | Notes |
|-----------|------------|-------|
| Tractability | Medium | Culture change is possible but hard |
| If alignment hard | High | Need labs to take it seriously |
| If alignment easy | High | Still need good practices |
| Neglectedness | Medium | Some attention, but inside positions scarce |

## What This Includes

- Safety team resources and authority
- Pre-deployment testing standards
- Publication and release decisions
- Internal governance structures
- Hiring and promotion incentives
- Relationships with external safety community

## Key Levers

| Lever | Mechanism | Who influences |
|-------|-----------|----------------|
| Safety team size/authority | More resources for safety | Lab leadership |
| Evals before deployment | Gate dangerous releases | Safety teams |
| Board governance | Oversight of decisions | Board members, investors |
| Responsible disclosure | Share safety findings | Industry norms |
| Researcher culture | What people work on | Researchers, hiring |

## Crux 1: Can Labs Self-Regulate?

| Can self-regulate | Cannot self-regulate |
|-------------------|---------------------|
| Labs genuinely concerned | Competitive pressure overrides |
| Reputation/liability incentives | Profit motive dominates |
| Good people work there | Good people leave or are ignored |

## Crux 2: Do Inside Positions Help?

| Inside positions valuable | Inside positions limited |
|--------------------------|-------------------------|
| Influence decisions directly | Captured by lab interests |
| Access to models/info | Limited room to push back |
| Build relationships | Selection for agreeable people |

## Crux 3: Coordination Between Labs

| Can coordinate | Cannot coordinate |
|----------------|-------------------|
| Shared interest in avoiding catastrophe | First-mover advantage too tempting |
| Frontier Model Forum works | Voluntary = unenforceable |
| Regulatory pressure helps | Racing dynamics dominate |

## Who Should Work on This?

**Good fit if you believe**:
- Labs are where decisions happen
- Influence from inside is possible
- Culture can meaningfully change
- Willing to work within constraints

**Less relevant if you believe**:
- Labs won't change without external pressure
- Inside positions compromise judgment
- Policy is more leveraged

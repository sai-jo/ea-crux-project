---
title: EU AI Act
description: Comprehensive AI regulation framework from the European Union
sidebar:
  order: 1
---

import { InfoBox, EntityCard, EntityCards, Tags, Sources, Section } from '../../../components/wiki';

<InfoBox
  type="policy"
  title="EU AI Act"
  jurisdiction="European Union"
  status="In Force"
  effectiveDate="August 2024"
  customFields={[
    { label: "Type", value: "Binding Regulation" },
    { label: "Scope", value: "Risk-based" },
  ]}
/>

## Overview

The EU AI Act is the world's first comprehensive legal framework for artificial intelligence. Adopted in 2024, it establishes a risk-based approach to AI regulation, with stricter requirements for higher-risk AI systems.

For AI safety, the Act is significant because it includes provisions for "general-purpose AI" (GPAI) and foundation models, including frontier AI systems.

## Risk Categories

The Act classifies AI systems by risk level:

### Unacceptable Risk (Banned)
- Social scoring by governments
- Real-time biometric identification in public (with exceptions)
- Manipulation through subliminal techniques
- Exploitation of vulnerabilities

### High Risk (Strict Requirements)
- Biometric identification systems
- Critical infrastructure management
- Educational and vocational training
- Employment and worker management
- Access to essential services
- Law enforcement
- Migration and border control

### Limited Risk (Transparency)
- Chatbots (must disclose AI)
- Emotion recognition
- Deepfake generation

### Minimal Risk (No Requirements)
- AI-enabled video games
- Spam filters
- Most AI applications

## GPAI and Foundation Models

Special provisions for general-purpose AI:

### All GPAI Models
- Technical documentation
- Transparency requirements
- Copyright compliance

### GPAI with Systemic Risk
Models trained with >10^25 FLOP face additional requirements:
- Model evaluation and adversarial testing
- Incident reporting
- Cybersecurity measures
- Energy consumption reporting

## Frontier AI Provisions

For the most capable models:
- Mandatory red-teaming
- Risk assessment for dangerous capabilities
- Reporting obligations to EU AI Office
- Codes of practice for safety

## Enforcement

- **Fines**: Up to â‚¬35M or 7% global revenue
- **EU AI Office**: Oversees GPAI compliance
- **National authorities**: Enforce most provisions
- **Codes of practice**: Industry self-regulation with EU oversight

## Timeline

| Date | Milestone |
|------|-----------|
| April 2021 | Commission proposal |
| December 2023 | Political agreement |
| March 2024 | Parliament approval |
| August 2024 | Entry into force |
| August 2025 | Most provisions apply |
| August 2026 | Full application |

## Criticisms

### From Safety Perspective
- Compute thresholds may be gameable
- 10^25 FLOP threshold may be too high
- Enforcement capacity unclear
- Limited extraterritorial reach

### From Innovation Perspective
- May disadvantage EU companies
- Compliance burden for startups
- Unclear how rules apply in practice

<Section title="Related Topics">
  <Tags tags={[
    "AI Regulation",
    "GPAI",
    "Foundation Models",
    "Risk-Based Regulation",
    "Compute Thresholds",
  ]} />
</Section>

<Section title="Related Entries">
  <EntityCards>
    <EntityCard
      id="compute-governance"
      category="policy"
      title="Compute Governance"
      description="Broader framework for compute-based regulation"
    />
    <EntityCard
      id="uk-aisi"
      category="policy"
      title="UK AI Safety Institute"
      description="Alternative governance approach"
    />
    <EntityCard
      id="govai"
      category="lab"
      title="GovAI"
      description="Research informing EU policy"
    />
  </EntityCards>
</Section>

<Sources sources={[
  { title: "EU AI Act Full Text", url: "https://artificialintelligenceact.eu/" },
  { title: "EU AI Office", url: "https://digital-strategy.ec.europa.eu/en/policies/ai-office" },
  { title: "Analysis of GPAI Provisions", url: "https://governance.ai/eu-ai-act" },
]} />

# Misc Entities
# Auto-generated from entities.yaml - edit this file directly

- id: effectiveness-assessment
  type: analysis
  title: AI Policy Effectiveness
  customFields:
    - label: Key Question
      value: Which policies actually reduce AI risk?
    - label: Challenge
      value: Counterfactuals are hard to assess
    - label: Status
      value: Early, limited evidence
  sources:
    - title: 'AI Governance: A Research Agenda'
      url: https://www.governance.ai/research-paper/research-agenda
      author: GovAI
    - title: Evaluating AI Governance
      url: https://cset.georgetown.edu/
      author: CSET Georgetown
  description: 'As AI governance efforts multiply, a critical question emerges: Which policies are actually working?'
  lastUpdated: 2025-12
- id: key-publications
  type: resource
  title: Key Publications in AI Safety
  customFields:
    - label: Scope
      value: Books, papers, and essays that shaped the field
    - label: Time Span
      value: 1965-2024
    - label: Categories
      value: Foundational, Technical, Popular, Governance
  sources:
    - title: Speculations Concerning the First Ultraintelligent Machine
      url: https://vtechworks.lib.vt.edu/handle/10919/89424
      author: I.J. Good
      date: '1965'
    - title: 'Superintelligence: Paths, Dangers, Strategies'
      url: https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/0199678111
      author: Nick Bostrom
      date: '2014'
    - title: Concrete Problems in AI Safety
      url: https://arxiv.org/abs/1606.06565
      author: Amodei et al.
      date: '2016'
    - title: 'Human Compatible: Artificial Intelligence and the Problem of Control'
      url: https://www.amazon.com/Human-Compatible-Artificial-Intelligence-Problem/dp/0525558616
      author: Stuart Russell
      date: '2019'
    - title: The Alignment Problem
      url: https://www.amazon.com/Alignment-Problem-Machine-Learning-Values/dp/0393635821
      author: Brian Christian
      date: '2020'
    - title: The Precipice
      url: https://theprecipice.com/
      author: Toby Ord
      date: '2020'
    - title: Life 3.0
      url: https://www.amazon.com/Life-3-0-Being-Artificial-Intelligence/dp/1101946598
      author: Max Tegmark
      date: '2017'
    - title: 'Constitutional AI: Harmlessness from AI Feedback'
      url: https://arxiv.org/abs/2212.08073
      author: Bai et al.
      date: '2022'
    - title: Risks from Learned Optimization
      url: https://arxiv.org/abs/1906.01820
      author: Hubinger et al.
      date: '2019'
    - title: Creating Friendly AI
      url: https://intelligence.org/files/CFAI.pdf
      author: Eliezer Yudkowsky
      date: '2001'
  description: >-
    AI safety as a field has been shaped by a relatively small number of highly influential publications. This page
    documents the books, papers, and essays that defined the intellectual landscape.
  tags:
    - superintelligence
    - nick-bostrom
    - ij-good
    - stuart-russell
    - eliezer-yudkowsky
    - concrete-problems
    - constitutional-ai
    - intelligence-explosion
    - alignment-problem
    - human-compatible
  lastUpdated: 2025-12

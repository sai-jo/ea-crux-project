# Parameter Graph Data
# Defines the nodes and edges for the cause-effect visualization
# Edit this file to update the graph structure

nodes:
  # === ROOT FACTORS (top layer) ===
  # Manual X positions to minimize edge crossings
  # X positions: 0=far left, 1=left-center, 2=center, 3=right-center, 4=far right

  - id: misalignment-potential
    label: Misalignment Potential
    description: Potential for AI to be misaligned.
    type: cause
    order: 0
    href: /knowledge-base/ai-transition-model/factors/misalignment-potential/
    subItems:
      - label: Alignment Robustness
        href: /knowledge-base/ai-transition-model/parameters/alignment-robustness/
      - label: Interpretability Coverage
        href: /knowledge-base/ai-transition-model/parameters/interpretability-coverage/
      - label: Human Oversight Quality
        href: /knowledge-base/ai-transition-model/parameters/human-oversight-quality/
      - label: Safety Capability Gap
        href: /knowledge-base/ai-transition-model/parameters/safety-capability-gap/
      - label: Safety Culture Strength
        href: /knowledge-base/ai-transition-model/parameters/safety-culture-strength/

  - id: ai-capabilities
    label: AI Capabilities
    description: How powerful AI systems become.
    type: cause
    order: 1
    href: /knowledge-base/ai-transition-model/factors/ai-capabilities/
    subItems:
      - label: Speed
      - label: Generality
      - label: Autonomy

  - id: civ-competence
    label: Civilizational Competence
    description: Humanity's ability to respond well.
    type: cause
    order: 2
    href: /knowledge-base/ai-transition-model/factors/civilizational-competence/
    subItems:
      - label: Governance
        href: /knowledge-base/ai-transition-model/parameters/governance/
      - label: Epistemics
        href: /knowledge-base/ai-transition-model/parameters/epistemics/
      - label: Adaptability
        href: /knowledge-base/ai-transition-model/parameters/adaptability/

  - id: transition-turbulence
    label: Transition Turbulence
    description: Background instability during transition.
    type: cause
    order: 3
    href: /knowledge-base/ai-transition-model/factors/transition-turbulence/
    subItems:
      - label: Economic Stability
        href: /knowledge-base/ai-transition-model/parameters/economic-stability/
      - label: Racing Intensity
        href: /knowledge-base/ai-transition-model/parameters/racing-intensity/

  - id: misuse-potential
    label: Misuse Potential
    description: Potential for AI to be misused for harm.
    type: cause
    order: 4
    href: /knowledge-base/ai-transition-model/factors/misuse-potential/
    subItems:
      - label: Biological Threat Exposure
        href: /knowledge-base/ai-transition-model/parameters/biological-threat-exposure/
      - label: Cyber Threat Exposure
        href: /knowledge-base/ai-transition-model/parameters/cyber-threat-exposure/
      - label: AI Control Concentration
        href: /knowledge-base/ai-transition-model/parameters/ai-control-concentration/

  # === ULTIMATE SCENARIOS (middle layer) ===

  - id: ai-takeover
    label: AI Takeover
    description: AI gains decisive control over human affairs.
    type: intermediate
    order: 0
    href: /knowledge-base/ai-transition-model/scenarios/ai-takeover/
    subItems:
      - label: Rapid
        probability: "12%"
        href: /knowledge-base/ai-transition-model/scenarios/ai-takeover/rapid/
      - label: Gradual
        probability: "25%"
        href: /knowledge-base/ai-transition-model/scenarios/ai-takeover/gradual/

  - id: human-catastrophe
    label: Human-Caused Catastrophe
    description: Humans use AI to cause mass harm.
    type: intermediate
    order: 1
    href: /knowledge-base/ai-transition-model/scenarios/human-catastrophe/
    subItems:
      - label: State Actor
        probability: "15%"
        href: /knowledge-base/ai-transition-model/scenarios/human-catastrophe/state-actor/
      - label: Rogue Actor
        probability: "8%"
        href: /knowledge-base/ai-transition-model/scenarios/human-catastrophe/rogue-actor/

  - id: long-term-lockin
    label: Long-term Lock-in
    description: Permanent entrenchment of outcomes.
    type: intermediate
    order: 2
    href: /knowledge-base/ai-transition-model/scenarios/long-term-lockin/
    subItems:
      - label: Values
        href: /knowledge-base/ai-transition-model/scenarios/long-term-lockin/values/
      - label: Power
        href: /knowledge-base/ai-transition-model/scenarios/long-term-lockin/power/
      - label: Epistemics
        href: /knowledge-base/ai-transition-model/scenarios/long-term-lockin/epistemics/

  # === ULTIMATE OUTCOMES (bottom layer) ===

  - id: existential-catastrophe
    label: Existential Catastrophe
    description: Civilization-ending or irreversible harm.
    type: effect
    order: 0
    confidence: 0.20
    confidenceLabel: aggregate probability
    href: /knowledge-base/ai-transition-model/outcomes/existential-catastrophe/

  - id: long-term-trajectory
    label: Long-term Trajectory
    description: Quality of post-transition future.
    type: effect
    order: 1
    confidence: 0.50
    confidenceLabel: high uncertainty
    href: /knowledge-base/ai-transition-model/outcomes/long-term-trajectory/

edges:
  # Root Factors → Ultimate Scenarios

  - id: e-cap-takeover
    source: ai-capabilities
    target: ai-takeover
    strength: strong
    effect: increases

  - id: e-misalign-takeover
    source: misalignment-potential
    target: ai-takeover
    strength: strong
    effect: increases

  - id: e-misuse-human
    source: misuse-potential
    target: human-catastrophe
    strength: strong
    effect: increases

  - id: e-turb-takeover
    source: transition-turbulence
    target: ai-takeover
    strength: medium
    effect: increases

  - id: e-turb-human
    source: transition-turbulence
    target: human-catastrophe
    strength: medium
    effect: increases

  - id: e-civ-takeover
    source: civ-competence
    target: ai-takeover
    strength: medium
    effect: decreases

  - id: e-civ-human
    source: civ-competence
    target: human-catastrophe
    strength: medium
    effect: decreases

  - id: e-civ-lockin
    source: civ-competence
    target: long-term-lockin
    strength: strong

  # Ultimate Scenarios → Ultimate Outcomes

  - id: e-takeover-excat
    source: ai-takeover
    target: existential-catastrophe
    strength: strong
    effect: increases

  - id: e-human-excat
    source: human-catastrophe
    target: existential-catastrophe
    strength: strong
    effect: increases

  - id: e-takeover-traj
    source: ai-takeover
    target: long-term-trajectory
    strength: strong
    effect: increases

  - id: e-lockin-traj
    source: long-term-lockin
    target: long-term-trajectory
    strength: strong
